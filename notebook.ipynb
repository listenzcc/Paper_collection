{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from pdfrw import PdfReader\n",
    "from pdfminer.layout import LTTextBoxHorizontal, LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFTextExtractionNotAllowed\n",
    "from pdfminer.converter import PDFPageAggregator, TextConverter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from io import StringIO\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pdfs(src_path='examples'):\n",
    "    print('=' * 80)\n",
    "    print(src_path)\n",
    "    pdfs = [s for s in os.listdir(src_path) if s .endswith('.pdf')]\n",
    "    print(pdfs)\n",
    "    return [os.path.join(src_path, e) for e in pdfs]\n",
    "\n",
    "def empty_info():\n",
    "    info = dict(\n",
    "        title = '',\n",
    "        keywords = [],\n",
    "        abstract = '',\n",
    "    )\n",
    "    return info\n",
    "\n",
    "def pdf_parser(fp):\n",
    "    # Prepare doc\n",
    "    praser = PDFParser(fp)\n",
    "    doc = PDFDocument()\n",
    "    praser.set_document(doc)\n",
    "    doc.set_parser(praser)\n",
    "    doc.initialize()\n",
    "    \n",
    "    # Rude assertion\n",
    "    assert(doc.is_extractable)\n",
    "    \n",
    "    # Prepare components\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    laparams = LAParams()\n",
    "    \n",
    "    # Bound device and interpreter\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    return doc, interpreter, device\n",
    "\n",
    "def paper_cls(pdf_path):\n",
    "    info = PdfReader(pdf_path).Info\n",
    "    if info['/Creator'] == '(untitled)':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Visual Feature Extraction From Voxel-Weighted Averaging of Stimulus Images in 2 fMRI Studies',\n",
       " 'keywords': ['bayesian estimation',\n",
       "  'component analysis',\n",
       "  'fmri',\n",
       "  'generalized linear models',\n",
       "  'imaging',\n",
       "  'voxel'],\n",
       " 'abstract': 'Multiple studies have provided evidence for distributed object representation in the brain, with several recent experiments leveraging basis function estimates for partial image reconstruction from fMRI data. Using a novel combination of statistical decomposition, generalized linear models, and stimulus averaging on previously examined image sets and Bayesian regression of recorded fMRI activity during presentation of these data sets, we identify a subset of relevant voxels that appear to code for covarying object features. Using a technique we term “voxel-weighted averaging,” we isolate image ﬁlters that these voxels appear to implement. The results, though very cursory, appear to have signiﬁcant implications for hierarchical and deep-learningtype approaches toward the understanding of neural coding and representation.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = 'examples\\ieee_2.pdf'\n",
    "\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf'\n",
    "\n",
    "def parse_paper_ieee(pdf_path):\n",
    "\n",
    "    info = empty_info()\n",
    "\n",
    "    with open(pdf_path, 'rb') as fp:\n",
    "        \n",
    "        doc, interpreter, device = pdf_parser(fp)\n",
    "        \n",
    "        # Read infos\n",
    "        # Only search on first page\n",
    "        page_limit = 1\n",
    "        is_title = False\n",
    "        for j, page in enumerate(doc.get_pages()):\n",
    "            # Break when page_limit is reached\n",
    "            if not(j < page_limit):\n",
    "                break\n",
    "            # Get layout\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            # For each box\n",
    "            for box in layout:\n",
    "                # If not LTTextBoxHorizontal, it should be passed\n",
    "                if not isinstance(box, LTTextBoxHorizontal):\n",
    "                    continue\n",
    "                # Get content\n",
    "                content = box.get_text()\n",
    "                # print('-' * 80)\n",
    "                # print(content)\n",
    "                \n",
    "                if is_title:\n",
    "                    info['title'] = content.replace('\\n', ' ').strip()\n",
    "                    is_title = False\n",
    "                if content.startswith('IEEE'):\n",
    "                    is_title = True\n",
    "                    \n",
    "                # Remove short dash '—'\n",
    "                content = content.replace('—', '')\n",
    "                \n",
    "                # Record abstract\n",
    "                if content.startswith('Abstract'):\n",
    "                    content = content.replace('Abstract', '')\n",
    "                    info['abstract'] = content.replace('\\n', ' ').replace('- ', '').strip()\n",
    "                    \n",
    "                # Record keywords\n",
    "                # Deal with several 'Index Terms' feature strings\n",
    "                content = content.replace('Index Terms', 'IndexTerms')\n",
    "                if content.startswith('IndexTerms'):\n",
    "                    keywords = content.replace('IndexTerms', '').replace('\\n', '').split(',')\n",
    "                    if keywords[-1].endswith('.'):\n",
    "                        keywords[-1] = keywords[-1][:-1]\n",
    "                    info['keywords'] = [e.strip().lower() for e in keywords]\n",
    "    return info\n",
    "\n",
    "parse_paper_ieee(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A meta-analysis of fMRI decoding_ Quantifying influences on human visual population codes',\n",
       " 'keywords': ['decoding',\n",
       "  'mvpa',\n",
       "  'patterns',\n",
       "  'meta-analysis',\n",
       "  'vision',\n",
       "  'objects'],\n",
       " 'abstract': 'Information in the human visual system is encoded in the activity of distributed populations of neurons, which in turn is reﬂected in functional magnetic resonance imaging (fMRI) data. Over the last ﬁfteen years, activity patterns underlying a variety of perceptual features and objects have been decoded from the brains of participants in fMRI scans. Through a novel multi-study meta-analysis, we have analyzed and modeled relations between decoding strength in the visual ventral stream, and stimulus and methodological variables that differ across studies. We report ﬁndings that suggest: (i) several organi- zational principles of the ventral stream, including a gradient of pattern granulation and an increasing abstraction of neural representations as one proceeds anteriorly; (ii) how methodological choices affect decoding strength. The data also show that studies with stronger decoding performance tend to be re- ported in higher-impact journals, by authors with a higher h-index. As well as revealing principles of regional processing, our results and approach can help investigators select from the thousands of design and analysis options in an empirical manner, to optimize future studies of fMRI decoding. & 2016 Elsevier Ltd. All rights reserved.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = 'examples\\elsevier_2.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S1053811916301914-main.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\10.1093@cercor@bhy123.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S0896627306005861-main.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S0028393216300173-main.pdf'\n",
    "\n",
    "def parse_paper_elsevier(pdf_path):\n",
    "    info = empty_info()\n",
    "    info['title'] = PdfReader(pdf_path).Info['/Title'][1:-1]\n",
    "\n",
    "    with open(pdf_path, 'rb') as fp:\n",
    "        \n",
    "        doc, interpreter, device = pdf_parser(fp)\n",
    "\n",
    "        # Read infos\n",
    "        # Only search on first page\n",
    "        page_limit = 2\n",
    "        is_abstract = False\n",
    "        for j, page in enumerate(doc.get_pages()):\n",
    "            # Break when page_limit is reached\n",
    "            if not(j < page_limit):\n",
    "                break\n",
    "            # Get layout\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            # For each box\n",
    "            for box in layout:\n",
    "                # If not LTTextBoxHorizontal, it should be passed\n",
    "                if not isinstance(box, LTTextBoxHorizontal):\n",
    "                    continue\n",
    "                # Get content\n",
    "                content = box.get_text()\n",
    "                # print('-' * 80)\n",
    "                # print(content)\n",
    "                # Record abstract\n",
    "                # If ready to read abstract, read abstract if not match known distractor\n",
    "                if all([is_abstract,\n",
    "                        not content.startswith('Article history'),\n",
    "                        not content.startswith('Keywords'),\n",
    "                        not content.startswith('Introduction'),\n",
    "                        not content.startswith('1.')\n",
    "                       ]):\n",
    "                    info['abstract'] = ''.join(content).replace('\\n', ' ').strip()\n",
    "                    is_abstract = False\n",
    "                # If match abstract feature string, ready to read abstract\n",
    "                if any([content.lower().startswith('a b s t r a c t'),\n",
    "                        content.lower().startswith('abstract'),\n",
    "                        content.lower().startswith('summary')]):\n",
    "                    is_abstract = True\n",
    "                # Record keywords\n",
    "                content = content.replace('Key words', 'Keywords').replace(',', '\\n')\n",
    "                if content.startswith('Keywords'):\n",
    "                    info['keywords'] = [e.strip().lower() for e in content.split('\\n') if e][1:]\n",
    "\n",
    "    return info\n",
    "\n",
    "parse_paper_elsevier(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_info(pdf_path):\n",
    "    info = PdfReader(pdf_path).Info\n",
    "    print(info)\n",
    "    if info['/Creator'] == '(Elsevier)':\n",
    "        return _elsevier(pdf_path)\n",
    "    return _ieee(pdf_path)\n",
    "    return None\n",
    "\n",
    "def _elsevier(pdf_path):\n",
    "    print('[-- It is an elsevier paper. --]')\n",
    "    info = parse_paper_elsevier(pdf_path)\n",
    "    return info\n",
    "\n",
    "def _ieee(pdf_path):\n",
    "    print('[-- It is an ieee paper. --]')\n",
    "    info = parse_paper_ieee(pdf_path)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\n",
      "['! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf', '!10.1093@cercor@bhy123.pdf', '!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf', '!Integrating theoretical models with functional neuroimaging.pdf', '0102181v1.pdf', '07073970.pdf', '07264993.pdf', '07468569.pdf', '08025614.pdf', '08051252.pdf', '08269806.pdf', '08370896.pdf', '1-s2.0-S0010945217303258-main.pdf', '1-s2.0-S0028393216300173-main.pdf', '1-s2.0-S0028393217300593-main.pdf', '1-s2.0-S0042698909004751-main.pdf', '1-s2.0-S0893608016301800-main.pdf', '1-s2.0-S0896627306005861-main.pdf', '1-s2.0-S089662731830477X-main.pdf', '1-s2.0-S0925231215017634-main.pdf', '1-s2.0-S1053810015000355-main.pdf', '1-s2.0-S1053811907001073-main.pdf', '1-s2.0-S1053811911013012-main.pdf', '1-s2.0-S1053811912004429-main.pdf', '1-s2.0-S1053811913002851-main.pdf', '1-s2.0-S1053811914001220-main.pdf', '1-s2.0-S1053811914010325-main.pdf', '1-s2.0-S1053811915005315-main.pdf', '1-s2.0-S1053811915006205-main.pdf', '1-s2.0-S1053811916000124-main.pdf', '1-s2.0-S1053811916001269-main.pdf', '1-s2.0-S1053811916300076-main.pdf', '1-s2.0-S1053811916301914-main.pdf', '1-s2.0-S1053811916306802-main.pdf', '1-s2.0-S1053811917302458-main.pdf', '1-s2.0-S1053811917305906-main.pdf', '1-s2.0-S1053811917306523-main.pdf', '1-s2.0-S1053811917306638-main.pdf', '1-s2.0-S105381191730664X-main.pdf', '1-s2.0-S1053811917307474-main.pdf', '1-s2.0-S1053811917307942-main.pdf', '1-s2.0-S1053811917311023-main.pdf', '1-s2.0-S1053811918300442-main.pdf', '1-s2.0-S1053811918300624-main.pdf', '1-s2.0-S1053811918301411-main.pdf', '1-s2.0-S1053811918301423-main.pdf', '1-s2.0-S1053811918304440-main.pdf', '1-s2.0-S1053811918305226-main.pdf', '1-s2.0-S1053811918305408-main.pdf', '1-s2.0-S1053811918305718-main.pdf', '1-s2.0-S105381191830627X-main.pdf', '1-s2.0-S1053811918306712-main.pdf', '1-s2.0-S1053811918320615-main.pdf', '1-s2.0-S1053811918321207-main.pdf', '1-s2.0-S1053811919301211-main.pdf', '1-s2.0-S1053811919301454-main.pdf', '1-s2.0-S1053811919302058-main.pdf', '1-s2.0-S1053811919302691-main.pdf', '1-s2.0-S1364661317302000-main.pdf', '1-s2.0-S1364661318300433-main.pdf', '1-s2.0-S1364661318302821-main.pdf', '1-s2.0-S1878929317300257-main.pdf', '1-s2.0-S1878929318301178-main.pdf', '1-s2.0-S2352340917302056-main.pdf', '10.1093@cercor@bhy123.pdf', '10792166.pdf', '10827_2010_Article_262.pdf', '1311.full.pdf', '1411.6422.pdf', '1510.06479v2.pdf', '1612.03590.pdf', '1706.01757.pdf', '1803Nature_Image reconstruction by domain-transform manifold learning.pdf', '1812.00725v1.pdf', '1906.02691.pdf', '2012-Lizier-LocalInfoStorage.pdf', '2016-7.pdf', '22547.pdf', '302034.full.pdf', '358036.full.pdf', '4020.full.pdf', '407007.full.pdf', '6069.full.pdf', '6672-unsupervised-image-to-image-translation-networks.pdf', '7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf', '7775-task-driven-convolutional-recurrent-models-of-the-visual-system.pdf', '8702.full.pdf', 'A brain-based account of “basic-level” concepts.pdf', 'A Matran-Fernandez  IEEE TBME17.pdf', 'A Matran-Fernandez  PONE17.pdf', 'A meta-analysis of fMRI decoding Quantifying influences on human visual population codes.pdf', 'A predictive coding account of bistable.pdf', 'A R Marathe IEEE TNSRE14.pdf', 'A R Marathe IEEE TNSRE16.pdf', 'Albers_NIMG2017.pdf', \"Are you thinking what I'm thinking Synchronization of resting fMRI.pdf\", 'Bayesian model reveals latent atrophy factors with dissociable cognitive trajectories in AD.pdf', 'brain.2011.0001.pdf', 'BurianovaEtAl_2013_Final.pdf', 'C M Privitera J Vision10.pdf', 'Can visual information encoded in cortical columns be decoded from MEG.pdf', 'chanAH15ICIP15.pdf', 'Chang_Tsao_2017_The Code for Facial Identity in the Primate Brain.pdf', 'Chen_et_al-2018-Scientific_Reports.pdf', 'Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf', 'Cichy_2016.pdf', 'Congedo et al 2016.pdf', 'CSCTR_07sup_ManMonkeyIT.pdf', 'Cukur2013.pdf', 'D Won IEEE TNSRE18(1).pdf', 'D Won IEEE TNSRE18.pdf', 'DeanAAAI-05-ComputationalModel-CerebralCortex.pdf', 'Decoding Brain Representations by Multimodal Learning.pdf', 'Decoding naturalistic experiences from human brain activity via distributed representations of words.pdf', 'Dinh2015_Article_Real-TimeMEGSourceLocalization.pdf', 'disun_etd_2016.pdf', 'Domain-general and domain-specific neural changes underlying.pdf', 'Dynamics of scene representations in the human brain revealed by MEG.pdf', 'eaag2612.full.pdf', 'ECCV2018_CBAM_ Convolutional Block Attention Module.pdf', 'elife-25784.pdf', 'elife-32816-v2.pdf', 'emss-74424.pdf', 'Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf', 'fncom-12-00004.pdf', 'Forward modelling reveals dynamics of neural orientation.pdf', 'FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf', \"Functional brain connectivity is predictable from anatomic network's.pdf\", 'gk7591_Lotteretal_ICLR2017.pdf', 'H Cecotti IEEE TBME16(1).pdf', 'H Cecotti IEEE TBME16.pdf', 'H Cecotti IEEE TNNLS14.pdf', 'H Cecotti Int J Psychophysiol17.pdf', 'Hallucinations in Charles Bonnet Syndrome Induced.pdf', 'HsiehChia-ObjectDetectionWithPartialOcclusion.pdf', 'HybridVAE-Improving Deep Generative Models using Partial Observations.pdf', 'ICML18_JointGAN_ Multi-Domain Joint Distribution Learning with.pdf', 'Information Theoretic Evidence for Predictive Coding.pdf', 'Interactions Between Large-Scale Functional Brain Networks HMM.pdf', 'jin%2F2017%2F16-3%2Fjin-16-3-jin016%2Fjin-16-jin016.pdf', 'jn.00338.2011.pdf', 'journal.pone.0206107.pdf', 'kellman_yin_shipley_1998.pdf', 'KokDeLange_2015_Predictive_Coding_in_Sensory_Cortex.pdf', 'Koles1990_Article_SpatialPatternsUnderlyingPopul.pdf', 'kriegeskorte_RSA_frontiersSN20081.pdf', 'Large Scale Organization of Shape Processing in the ventral and dorsal pathways.pdf', 'Learning to Associate Orientation with Color in Early Visual Areas by Associative Decoded fMRI Neurofeedback.pdf', 'Le_Chang_VALSE_2018_faceRecognition.pdf', 'manual.pdf', 'Mapping between fMRI responses to movies and their natural language annotations.pdf', 'Mean first-passage time for maximal-entropy random walks in complex networks.pdf', 'Mechanisms of evoked and induced responses.pdf', 'mmc2.pdf', 'Modeling Task fMRI Data via Deep Convolutional Autoencoder.pdf', 'Multi-modal Latent Factor Exploration  in Typical Late-Onset Alzheimer’s Disease.pdf', 'Multi-subject hierarchical inverse covariance modelling improves estimation of functional brain networks.pdf', 'Multi-task connectivity reveals flexible hubs for Adptivie Control.pdf', 'Multivariate pattern analysis of MEG and EEG A comparison of.pdf', 'Multiview-3D-DPM.pdf', 'NeuroImage2017_FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf', 'NeuroImage2018_Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf', 'NeuroImage2018_Pattern component modeling_ A flexible approach for understanding the representational structure of brain activity patterns.pdf', 'nihms-536994.pdf', 'nihms-645980.pdf', 'nihms122940.pdf', 'nihms234413.pdf', 'nihms678626.pdf', 'nihms829712.pdf', 'NIPS2018_IntroVAE_ Introspective Variational Autoencoders for Photographic Image Synthesis.pdf', 'NIPS2018_Multimodal Generative Models for Scalable Weakly-Supervised Learning.pdf', 'nn0199_79.pdf', 'On_the_interpretation_of_weight_vectors_of_linear_.pdf', 'Optimal information networks Application for data-driven integrated health in populations.pdf', 'Optimizing deep video representation to match brain activity.pdf', 'Ou2015_Article_CharacterizingAndDifferentiati.pdf', 'Predictive.pdf', 'R T Schirrmeister HBM17.pdf', 'Recognition of Occluded Objects.pdf', 'Representational similarity encoding for fMRI Pattern-based synthesis to.pdf', 'Rivet2009a.pdf', 's41467-018-03657-3.pdf', 's41593-018-0200-7.pdf', 's41598-018-22160-9.pdf', 's41598-018-28865-1.pdf', 'Scene complexity modulates degree of feedback activity during object detection in natural scenes.pdf', 'Serre_etal_PBR07.pdf', 'similarity based fusion MEG fMRI.pdf', 'Spatial attention enhances cortical tracking of quasi-rhythmic visual stimuli.pdf', 'Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs.pdf', 'Stack Sparse AutoEncoder Detector for Automatic Identification Epilepsy.pdf', 'Stimulus-Driven Population Activity Patterns in Macaque Primary Visual Cortex.pdf', 'Task-specific vision models explain task-specific areas of visual cortex (1).pdf', 'Task-specific vision models explain task-specific areas of visual cortex.pdf', 'theory of cortical function.pdf', 'Top-down effects in the brain.pdf', 'Toward Universal Lingustic Encoding.pdf', 'TowardIntegrationDNN-Neuroscience.pdf', 'Transfer learning of deep neural network representations for fMRI decoding.pdf', 'Visual pathways from the perspective of cost functions and multi-task deep neural networks (1).pdf', 'Visual pathways from the perspective of cost functions and multi-task deep neural networks.pdf', 'Wen et al_CC_2016_Neural Encoding and Decoding with Deep Learning for Dynamic Natural Vision.pdf', 'What is Changing when Decoding visual information movies iEEG (1).pdf', 'What is Changing when Decoding visual information movies iEEG (2).pdf', 'What When Where Visual Word Recog-TICS2014.pdf', 'zeilerECCV2014.pdf', 'zpq10607.pdf', '！A primer on encoding models in sensory neuroscience.pdf', '！NeuroEncodingandDecodingwithDL-DynamicNaturalVision.pdf', '！Zweig_InterpoNet_a_Brain_CVPR_2017_paper.pdf']\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf\n",
      "{'/CreationDate': \"(D:20131010150611+05'30')\", '/Title': '(untitled)', '/Producer': '(Acrobat Distiller 7.0.5 \\\\(Windows\\\\))', '/ModDate': \"(D:20131016094958-04')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Multiple studies have provided evidence for distributed object '\n",
      "             'representation in the brain, with several recent experiments '\n",
      "             'leveraging basis function estimates for partial image '\n",
      "             'reconstruction from fMRI data. Using a novel combination of '\n",
      "             'statistical decomposition, generalized linear models, and '\n",
      "             'stimulus averaging on previously examined image sets and '\n",
      "             'Bayesian regression of recorded fMRI activity during '\n",
      "             'presentation of these data sets, we identify a subset of '\n",
      "             'relevant voxels that appear to code for covarying object '\n",
      "             'features. Using a technique we term “voxel-weighted averaging,” '\n",
      "             'we isolate image ﬁlters that these voxels appear to implement. '\n",
      "             'The results, though very cursory, appear to have signiﬁcant '\n",
      "             'implications for hierarchical and deep-learningtype approaches '\n",
      "             'toward the understanding of neural coding and representation.',\n",
      " 'keywords': ['bayesian estimation',\n",
      "              'component analysis',\n",
      "              'fmri',\n",
      "              'generalized linear models',\n",
      "              'imaging',\n",
      "              'voxel'],\n",
      " 'title': 'Visual Feature Extraction From Voxel-Weighted Averaging of Stimulus '\n",
      "          'Images in 2 fMRI Studies'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!10.1093@cercor@bhy123.pdf\n",
      "{'/Title': '(oup_cercor_bhy123 1..19 ++)', '/Creator': '(Arbortext Advanced Print Publisher 10.0.1465/W Unicode)', '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\); modified using iTextSharp 4.1.6 by 1T3XT)', '/CreationDate': \"(D:20180604185931+05'30')\", '/ModDate': \"(D:20180608220929+00'00')\"}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf\n",
      "{'/Author': '(Amanda F. Mejia)', '/CreationDate': \"(D:20180414203338+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20190116174106+08'00')\", '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 172 \\\\(2018\\\\) 478-491. doi:10.1016/j.neuroimage.2018.01.029)', '/Title': '(Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage)', '/doi': '(10.1016/j.neuroimage.2018.01.029)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Reliability of subject-level resting-state functional '\n",
      "             'connectivity (FC) is determined in part by the statistical '\n",
      "             'techniques employed in its estimation. Methods that pool '\n",
      "             'information across subjects to inform estimation of '\n",
      "             'subject-level effects (e.g., Bayesian approaches) have been '\n",
      "             'shown to enhance reliability of subject-level FC. However, fully '\n",
      "             'Bayesian approaches are computationally demanding, while '\n",
      "             'empirical Bayesian approaches typically rely on using repeated '\n",
      "             'measures to estimate the variance components in the model. Here, '\n",
      "             'we avoid the need for repeated measures by proposing a novel '\n",
      "             'measurement error model for FC describing the different sources '\n",
      "             'of variance and error, which we use to perform empirical Bayes '\n",
      "             'shrinkage of subject-level FC towards the group average. In '\n",
      "             'addition, since the traditional intra-class correlation '\n",
      "             'coefﬁcient (ICC) is inappropriate for biased es- timates, we '\n",
      "             'propose a new reliability measure denoted the mean squared error '\n",
      "             'intra-class correlation coefﬁcient (ICCMSE) to properly assess '\n",
      "             'the reliability of the resulting (biased) estimates. We apply '\n",
      "             'the proposed techniques to test-retest resting-state fMRI data '\n",
      "             'on 461 subjects from the Human Connectome Project to estimate '\n",
      "             'connectivity between 100 regions identiﬁed through independent '\n",
      "             'components analysis (ICA). We consider both correlation and '\n",
      "             'partial correlation as the measure of FC and assess the beneﬁt '\n",
      "             'of shrinkage for each measure, as well as the effects of scan '\n",
      "             'duration. We ﬁnd that shrinkage estimates of subject-level FC '\n",
      "             'exhibit substantially greater reli- ability than traditional '\n",
      "             'estimates across various scan durations, even for the most '\n",
      "             'reliable connections and regardless of connectivity measure. '\n",
      "             'Additionally, we ﬁnd partial correlation reliability to be '\n",
      "             'highly sensitive to the choice of penalty term, and to be '\n",
      "             'generally worse than that of full correlations except for '\n",
      "             'certain connections and a narrow range of penalty values. This '\n",
      "             'suggests that the penalty needs to be chosen carefully when '\n",
      "             'using partial correlations.',\n",
      " 'keywords': ['functional connectivity',\n",
      "              'connectome',\n",
      "              'partial correlation',\n",
      "              'reliability',\n",
      "              'bayesian statistics',\n",
      "              'shrinkage',\n",
      "              'measurement error',\n",
      "              'resting-state fmri'],\n",
      " 'title': 'Improved estimation of subject-level functional connectivity using '\n",
      "          'full and partial correlation with empirical Bayes shrinkage'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!Integrating theoretical models with functional neuroimaging.pdf\n",
      "{'/Author': '(Michael S. Pratte)', '/CreationDate': \"(D:20160723113540+05'30')\", '/Creator': '(Elsevier)', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20170219143127+08'00')\", '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.1415926-1.40.10-2.2 \\\\(TeX Live 2009/Debian\\\\) kpathsea version 5.0.0)', '/Producer': '(pdfTeX-1.40.3)', '/Subject': '(Journal of Mathematical Psychology, Corrected proof. doi:10.1016/j.jmp.2016.06.008)', '/Title': '(Integrating theoretical models with functional neuroimaging)', '/Trapped': '/False', '/doi': '(10.1016/j.jmp.2016.06.008)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The development of mathematical models to characterize '\n",
      "             'perceptual and cognitive processes dates back almost to the '\n",
      "             'inception of the field of psychology. Since the 1990s, human '\n",
      "             'functional neuroimaging has provided for rapid empirical and '\n",
      "             'theoretical advances across a variety of domains in cognitive '\n",
      "             'neuroscience. In more recent work, formal modeling and '\n",
      "             'neuroimaging approaches are being successfully combined, often '\n",
      "             'producing models with a level of specificity and rigor that '\n",
      "             'would not have been possible by studying behavior alone. In this '\n",
      "             'review, we highlight examples of recent studies that utilize '\n",
      "             'this combined approach to provide novel insights into the '\n",
      "             'mechanisms underlying human cognition. The studies described '\n",
      "             'here span domains of perception, attention, memory, '\n",
      "             'categorization, and cognitive control, employing a variety of '\n",
      "             'analytic and model-inspired approaches. Across these diverse '\n",
      "             'studies, a common theme is that individually tailored, creative '\n",
      "             'solutions are often needed to establish compelling links between '\n",
      "             'multi-parameter models and complex sets of neural data. We '\n",
      "             'conclude that future developments in model-based cognitive '\n",
      "             'neuroscience will have great potential to advance our '\n",
      "             'theoretical understanding and ability to model both low-level '\n",
      "             'and high-level cognitive processes. © 2016 Elsevier Inc. All '\n",
      "             'rights reserved.',\n",
      " 'keywords': [],\n",
      " 'title': 'Integrating theoretical models with functional neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\0102181v1.pdf\n",
      "{'/Producer': '(GPL Ghostscript SVN PRE-RELEASE 8.62)', '/CreationDate': \"(D:20080201103549-05'00')\", '/ModDate': \"(D:20080201103549-05'00')\", '/Creator': '(dvips\\\\(k\\\\) 5.86 Copyright 1999 Radical Eye Software)', '/Title': '(arXiv:cond-mat/0102181v1  [cond-mat.stat-mech]  9 Feb 2001)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07073970.pdf\n",
      "{'/IEEE Issue ID': '(7069645)', '/Creator': '(TeX)', '/Producer': '(Appligent StampPDF Batch, version 5.1; modified using iText® 7.1.1 ©2000-2018 iText Group NV \\\\(AGPL-version\\\\))', '/IEEE Article ID': '(7073970)', '/Title': '(Theoretical analysis of xDAWN algorithm: Application to an efficient sensor selection in a p300 BCI)', '/IEEE Publication ID': '(7069644)', '/Appligent': '(StampPDF Batch 5.1 Jan 18 2010, 9.0.1)', '/Meeting Ending Date': '(2 Sept. 2011)', '/Meeting Starting Date': '(29 Aug. 2011)', '/Subject': '(2011 19th European Signal Processing Conference;2011; ; ; )', '/ModDate': \"(D:20181125133854-05'00')\", '/CreationDate': '(D:20110228103021Z)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07264993.pdf\n",
      "{'/CreationDate': \"(D:20151215140345+05'30')\", '/Title': '(untitled)', '/ModDate': \"(D:20151218062801-05'00')\", '/Producer': '(Acrobat Distiller 10.1.10 \\\\(Windows\\\\))'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Goal: The detection of brain responses corresponding to the '\n",
      "             'presentation of a particular class of images is a challenge in '\n",
      "             'brain–machine interface. Current systems based on the detection '\n",
      "             'of brain responses during rapid serial visual presentation '\n",
      "             '(RSVP) tasks possess advantages for both healthy and disabled '\n",
      "             'people, as they are gaze independent and can offer a high '\n",
      "             'throughput. Methods: We propose a novel paradigm based on a '\n",
      "             'dual-RSVP task that assumes a low target probability. Two '\n",
      "             'streams of images are presented simultaneously on the screen, '\n",
      "             'the second stream is identical to the ﬁrst one, but delayed in '\n",
      "             'time. Participants were asked to detect images containing a '\n",
      "             'person. They follow the ﬁrst stream until they see a target '\n",
      "             'image, then change their attention to the second stream until '\n",
      "             'the target image reappears, ﬁnally they change their attention '\n",
      "             'back to the ﬁrst stream. Results: The performance of '\n",
      "             'single-trial detection was evaluated on both streams and their '\n",
      "             'combination of the decisions with signal recorded with '\n",
      "             'magnetoencephalography (MEG) during the dual-RSVP task. We '\n",
      "             'compare classi ﬁcation performance across different sets of '\n",
      "             'channels (magnetometers, gradiometers) with a BLDA classi ﬁer '\n",
      "             'with inputs obtained after spatial ﬁltering. Conclusion: The '\n",
      "             'results suggest that single-trial detection can be obtained with '\n",
      "             'an area under the ROC curve superior to 0.95, and that an almost '\n",
      "             'perfect accuracy can be obtained with some subjects thanks to '\n",
      "             'the combination of the decisions from two trials, without '\n",
      "             'doubling the duration of the experiment. Signiﬁcance: The '\n",
      "             'present results show that a reliable accuracy can be obtained '\n",
      "             'with the MEG for target detection during a dual-RSVP task.',\n",
      " 'keywords': ['event-related ﬁelds',\n",
      "              'magnetoencephalography(meg)',\n",
      "              'rapid serial visual presentation',\n",
      "              'single-trial detection'],\n",
      " 'title': 'Single-Trial Detection With Magnetoencephalography During a '\n",
      "          'Dual-Rapid Serial Visual Presentation Task'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07468569.pdf\n",
      "{'/CreationDate': \"(D:20160629071855+05'30')\", '/Title': '(untitled)', '/ModDate': \"(D:20160629071920+05'30')\", '/Producer': '(Acrobat Distiller 10.1.10 \\\\(Windows\\\\))'}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='RMTMIB'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='MTSYN'>, 4\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='MTSYN'>, 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Linear Gaussian state-space models are ubiquitous in signal '\n",
      "             'processing, and an important procedure is that of estimating '\n",
      "             'system parameters from observed data. Rather than making a '\n",
      "             'single point estimate, it is often desirable to conduct Bayesian '\n",
      "             'learning, in which the entire posterior distribution of the '\n",
      "             'unknown parameters is sought. This can be achieved using Markov '\n",
      "             'chain Monte Carlo. On some occasions it is possible to deduce '\n",
      "             'the form of the unknown system matrices in terms of a small '\n",
      "             'number of scalar parameters, by considering the underlying '\n",
      "             'physical processes involved. Here we study the case where this '\n",
      "             'is not possible, and the entire matrices must be treated as '\n",
      "             'unknowns. An efﬁcient Gibbs sampling algorithm exists for the '\n",
      "             'basic formulation of linear model. We extend this to the more '\n",
      "             'challenging situation where the transition model is possibly '\n",
      "             'degenerate, i.e., the transition covariance matrix is singular. '\n",
      "             'Appropriate Markov kernels are devised and demonstrated with '\n",
      "             'simulations.',\n",
      " 'keywords': ['covariance matrices',\n",
      "              'linear systems',\n",
      "              'markov pro-cesses',\n",
      "              'monte carlo methods',\n",
      "              'parameter estimation',\n",
      "              'time seriesanalysis'],\n",
      " 'title': 'Bayesian Learning of Degenerate Linear Gaussian State Space Models '\n",
      "          'Using Markov Chain Monte Carlo'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08025614.pdf\n",
      "{'/ModDate': \"(D:20180201082517-05'00')\", '/Title': '(untitled)', '/Producer': '(Aspose.Pdf for .NET 8.3.0)', '/Creator': '(Aspose Ltd.)', '/CreationDate': \"(D:20180131214858+05'30')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Principal component analysis (PCA) is an exploratory tool widely '\n",
      "             'used in data analysis to uncover the dominant patterns of '\n",
      "             'variability within a population. Despite its ability to '\n",
      "             'represent a data set in a low-dimensional space, PCA ’s '\n",
      "             'interpretability remai ns limited. Indeed, the components '\n",
      "             'produced by PCA are often noisy or exhibit no visually '\n",
      "             'meaningful patterns. Furthermore, the fact that the components '\n",
      "             'are usually non-sparse may also impede interpretation, unless '\n",
      "             'arbitrary thresholding is applied. However, in neuroimaging, it '\n",
      "             'is essential to uncover clinically interpretable phenotypic '\n",
      "             'markers that would account for the main variability in the brain '\n",
      "             'images of a population. Recently, some alternatives to the '\n",
      "             'standard PCA approach, such as sparse PCA (SPCA), have been '\n",
      "             'proposed, their aim being to limit the density of the '\n",
      "             'components. Nonetheless, sparsity alone does not entirely solve '\n",
      "             'the interpretability problem in neuroimaging, since it may yield '\n",
      "             'scattered and unstable components. We hypothesized that the '\n",
      "             'incorporation of prior information regarding the structure of '\n",
      "             'the data may lead to improved relevance and interpretability of '\n",
      "             'brain patterns. We therefore present a simple extension of the '\n",
      "             'popular PCA framework that adds structured sparsity penalties on '\n",
      "             'the loading vectors in order to identify the few stable regions '\n",
      "             'in the brain images that capture most of the variability. Such '\n",
      "             'structured sparsity can be obtained by combining, e.g., (cid:2)1 '\n",
      "             'and total variation (TV) penalties, where the TV regularization '\n",
      "             'encodes information on the underlying structure of the data. '\n",
      "             'This paper presents the structured SPCA (denoted SPCA-TV) '\n",
      "             'optimization framework and its resolution. We demonstrate '\n",
      "             'SPCA-TV ’s effectiveness and versatility on three different data '\n",
      "             'sets. It can be applied to any kind of structured data, such as, '\n",
      "             'e.g., N-dimensional array images or meshes of cortical surfaces. '\n",
      "             'The gains of SPCA-TV over unstructured approaches (such as SPCA '\n",
      "             'and ElasticNet PCA) or structured approach (such as GraphNet '\n",
      "             'PCA) are signi ﬁcant, since SPCA-TV reveals the variability',\n",
      " 'keywords': ['mri', 'unsupervised machine learning', 'pca', 'total variation'],\n",
      " 'title': 'Structured Sparse Principal Components Analysis With the TV-Elastic '\n",
      "          'Net Penalty'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08051252.pdf\n",
      "{'/IEEE Issue ID': '(8440865)', '/Producer': '(Acrobat Distiller 10.1.16 \\\\(Windows\\\\); modified using iText® 7.1.1 ©2000-2018 iText Group NV \\\\(AGPL-version\\\\))', '/IEEE Article ID': '(8051252)', '/Title': '(Deep Learning of Constrained Autoencoders for Enhanced Understanding of Data)', '/IEEE Publication ID': '(5962385)', '/Meeting Ending Date': '( )', '/Meeting Starting Date': '( )', '/Subject': '(IEEE Transactions on Neural Networks and Learning Systems;2018;29;9;10.1109/TNNLS.2017.2747861)', '/ModDate': \"(D:20180820023541-04'00')\", '/CreationDate': \"(D:20180816032527+05'30')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Unsupervised feature extractors are known to perform an efﬁcient '\n",
      "             'and discriminative representation of data. Insight into the '\n",
      "             'mappings they perform and human ability to understand them, '\n",
      "             'however, remain very limited. This is especially prominent when '\n",
      "             'multilayer deep learning architectures are used. This paper '\n",
      "             'demonstrates how to remove these bottlenecks within the '\n",
      "             'architecture of non-negativity constrained autoencoder. It is '\n",
      "             'shown that using both L1 and L2 regularizations that induce '\n",
      "             'non-negativity of weights, most of the weights in the network '\n",
      "             'become constrained to be non-negative, thereby resulting into a '\n",
      "             'more understandable structure with minute deterioration in '\n",
      "             'classi ﬁcation accuracy. Also, this proposed approach extracts '\n",
      "             'features that are more sparse and produces additional output '\n",
      "             'layer sparsi ﬁcation. The method is analyzed for accuracy and '\n",
      "             'feature interpretation on the MNIST data, the NORB normalized '\n",
      "             'uniform object data, and the Reuters text categorization data '\n",
      "             'set. Index Terms Deep learning (DL), part-based representation, '\n",
      "             'receptive ﬁeld, sparse autoencoder (SAE), white-box model.',\n",
      " 'keywords': [],\n",
      " 'title': '3969'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08269806.pdf\n",
      "{'/Appligent': '(AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0)', '/CreationDate': \"(D:20180125061539-05'00')\", '/Creator': '(Appligent AppendPDF Pro 5.5)', '/ModDate': \"(D:20180125061539-05'00')\", '/Producer': '(pdfTeX-1.40.14)', '/Title': '(tpami-2798607-pp.pdf)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Our experience of the world is multimodal we see objects, hear '\n",
      "             'sounds, feel texture, smell odors, and taste ﬂavors. Modality '\n",
      "             'refers to the way in which something happens or is experienced '\n",
      "             'and a research problem is characterized as multimodal when it '\n",
      "             'includes multiple such modalities. In order for Ar tiﬁcial '\n",
      "             'Intelligence to make progress in understanding the world around '\n",
      "             'us, it needs to be able to interpret such multimodal signals '\n",
      "             'together. Multimodal machine learning aims to build models that '\n",
      "             'can process and relate information from multiple modalities. It '\n",
      "             'is a vibrant multi-disciplinary ﬁeld of increasing impor tance '\n",
      "             'and with extraordinary potential. Instead of focusing on speciﬁc '\n",
      "             'multimodal applications, this paper surveys the recent advances '\n",
      "             'in multimodal machine learning itself and presents them in a '\n",
      "             'common taxonomy. We go beyond the typical early and late fusion '\n",
      "             'categorization and identify broader challenges that are faced by '\n",
      "             'multimodal machine learning, namely: representation, '\n",
      "             'translation, alignment, fusion, and co-learning. This new '\n",
      "             'taxonomy will enable researchers to better understand the state '\n",
      "             'of the ﬁeld and identify directions for future research.',\n",
      " 'keywords': ['multimodal', 'machine learning', 'introductory', 'survey'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08370896.pdf\n",
      "{'/IEEE Issue ID': '(4359286)', '/Creator': '(Appligent AppendPDF Pro 5.5)', '/Producer': '(MiKTeX pdfTeX-1.40.11; modified using iText® 7.1.1 ©2000-2018 iText Group NV \\\\(AGPL-version\\\\))', '/IEEE Article ID': '(8370896)', '/Title': '(Feedback Convolutional Neural Network for Visual Localization and Segmentation)', '/IEEE Publication ID': '(34)', '/Appligent': '(AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0)', '/Meeting Ending Date': '( )', '/Meeting Starting Date': '( )', '/Subject': '(IEEE Transactions on Pattern Analysis and Machine Intelligence; ;PP;99;10.1109/TPAMI.2018.2843329)', '/ModDate': \"(D:20180823142422-04'00')\", '/CreationDate': \"(D:20180601141536-04'00')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Feedback is a fundamental mechanism existing in the human visual '\n",
      "             'system, but has not been explored deeply in designing computer '\n",
      "             'vision algorithms. In this paper, we claim that feedback plays a '\n",
      "             'critical role in understanding convolutional neural networks '\n",
      "             '(CNNs), e.g., how a neuron in CNN describes an object’s pattern, '\n",
      "             'and how a collection of neurons form comprehensive perception to '\n",
      "             'an object. To model the feedback in CNNs, we propose a novel '\n",
      "             'model named Feedback CNN and develop two new processing '\n",
      "             'algorithms, i.e., neural pathway pruning and pattern recovering. '\n",
      "             'We have mathematically proven that the proposed method can reach '\n",
      "             'local optimum. Note that Feedback CNN belongs to weakly '\n",
      "             'supervised methods and can be trained only using category-level '\n",
      "             'labels. But it possesses powerful capability to accurately '\n",
      "             'localize and segment category-speciﬁc objects. We conduct '\n",
      "             'extensive visualization analysis, and the results reveal the '\n",
      "             'close relationship between neurons and object par ts in Feedback '\n",
      "             'CNN. Finally, we evaluate the proposed Feedback CNN over the '\n",
      "             'tasks of weakly supervised object localization and segmentation, '\n",
      "             'and the experimental results on ImageNet and Pascal VOC show '\n",
      "             'that our method remarkably outperforms the state-of-the-ar t '\n",
      "             'ones.',\n",
      " 'keywords': ['feedback',\n",
      "              'convolutional neural networks (cnns)',\n",
      "              'weakly supervised',\n",
      "              'object localization',\n",
      "              'object segmentation'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0010945217303258-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': '(11th January 2018)', '/Subject': '(CORTEX, 98 \\\\(2018\\\\) 249-261. doi:10.1016/j.cortex.2017.09.019)', '/Author': '(H. Steven Scholte)', '/CreationDate--Text': '(11th January 2018)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180111144045+05'30')\", '/doi': '(10.1016/j.cortex.2017.09.019)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Visual pathways from the perspective of cost functions and multi-task deep neural networks)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Vision research has been shaped by the seminal insight that we '\n",
      "             'can understand the higher-tier visual cortex from the '\n",
      "             'perspective of multiple functional pathways with different '\n",
      "             'goals. In this paper, we try to give a computational account of '\n",
      "             'the functional organization of this system by reasoning from the '\n",
      "             'perspective of multi-task deep neural networks. Machine learning '\n",
      "             'has shown that tasks become easier to solve when they are '\n",
      "             'decomposed into subtasks with their own cost function. We '\n",
      "             'hypothesize that the visual system optimizes multiple cost '\n",
      "             'functions of unrelated tasks and this causes the emergence of a '\n",
      "             'ventral pathway dedicated to vision for perception, and a dorsal '\n",
      "             'pathway dedicated to vision for action. To evaluate the '\n",
      "             'functional organization in multi-task deep neural networks, we '\n",
      "             'propose a method that measures the contribution of a unit '\n",
      "             'towards each task, applying it to two networks that have been '\n",
      "             'trained on either two related or two unrelated tasks, using an '\n",
      "             'identical stimulus set. Results show that the network trained on '\n",
      "             'the unrelated tasks shows a decreasing degree of feature '\n",
      "             'representation sharing towards higher-tier layers while the '\n",
      "             'network trained on related tasks uniformly shows high degree of '\n",
      "             'sharing. We conjecture that the method we propose can be used to '\n",
      "             'analyze the anatomical and functional organization of the visual '\n",
      "             'system and beyond. We predict that the degree to which tasks are '\n",
      "             'related is a good descriptor of the degree to which they share '\n",
      "             'downstream cortical-units.',\n",
      " 'keywords': ['dual-pathway',\n",
      "              'deep learning',\n",
      "              'cost functions',\n",
      "              'representations',\n",
      "              'visual processing'],\n",
      " 'title': 'Visual pathways from the perspective of cost functions and '\n",
      "          'multi-task deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0028393216300173-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(sciencedirect.com)', '/CreationDate': \"(D:20160202072944+05'30')\", '/CrossmarkMajorVersionDate': '(2010-04-23)', '/Subject': '(Neuropsychologia, 82 + \\\\(2016\\\\) 134-141. doi:10.1016/j.neuropsychologia.2016.01.018)', '/Author': '(Marc N. Coutanche)', '/Creator': '(Elsevier)', '/Keywords': '(Decoding; MVPA; Patterns; Meta-analysis; Vision; Objects)', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20160202072944+05'30')\", '/doi': '(10.1016/j.neuropsychologia.2016.01.018)', '/CrossMarkDomains[1]': '(elsevier.com)', '/Title': '(A meta-analysis of fMRI decoding_ Quantifying influences on human visual population codes)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Information in the human visual system is encoded in the '\n",
      "             'activity of distributed populations of neurons, which in turn is '\n",
      "             'reﬂected in functional magnetic resonance imaging (fMRI) data. '\n",
      "             'Over the last ﬁfteen years, activity patterns underlying a '\n",
      "             'variety of perceptual features and objects have been decoded '\n",
      "             'from the brains of participants in fMRI scans. Through a novel '\n",
      "             'multi-study meta-analysis, we have analyzed and modeled '\n",
      "             'relations between decoding strength in the visual ventral '\n",
      "             'stream, and stimulus and methodological variables that differ '\n",
      "             'across studies. We report ﬁndings that suggest: (i) several '\n",
      "             'organi- zational principles of the ventral stream, including a '\n",
      "             'gradient of pattern granulation and an increasing abstraction of '\n",
      "             'neural representations as one proceeds anteriorly; (ii) how '\n",
      "             'methodological choices affect decoding strength. The data also '\n",
      "             'show that studies with stronger decoding performance tend to be '\n",
      "             're- ported in higher-impact journals, by authors with a higher '\n",
      "             'h-index. As well as revealing principles of regional processing, '\n",
      "             'our results and approach can help investigators select from the '\n",
      "             'thousands of design and analysis options in an empirical manner, '\n",
      "             'to optimize future studies of fMRI decoding. & 2016 Elsevier '\n",
      "             'Ltd. All rights reserved.',\n",
      " 'keywords': ['decoding',\n",
      "              'mvpa',\n",
      "              'patterns',\n",
      "              'meta-analysis',\n",
      "              'vision',\n",
      "              'objects'],\n",
      " 'title': 'A meta-analysis of fMRI decoding_ Quantifying influences on human '\n",
      "          'visual population codes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0028393217300593-main.pdf\n",
      "{'/Author': '(Erika W. Contini)', '/CreationDate': \"(D:20171027160550+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(MEG; EEG; MVPA; Time-series decoding; Object recognition; Object categorisation)', '/ModDate': \"(D:20171027160550+05'30')\", '/Subject': '(Neuropsychologia, 105 \\\\(2017\\\\) 165-176. doi:10.1016/j.neuropsychologia.2017.02.013)', '/Title': '(Decoding the time-course of object recognition in the human brain_ From visual features to categorical decisions)', '/doi': '(10.1016/j.neuropsychologia.2017.02.013)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual object recognition is a complex, dynamic process. '\n",
      "             'Multivariate pattern analysis methods, such as decoding, have '\n",
      "             'begun to reveal how the brain processes complex visual '\n",
      "             'information. Recently, temporal decoding methods for EEG and MEG '\n",
      "             'have oﬀered the potential to evaluate the temporal dynamics of '\n",
      "             'object recognition. Here we review the contribution of M/EEG '\n",
      "             'time-series decoding methods to understanding visual object '\n",
      "             'recognition in the human brain. Consistent with the current '\n",
      "             'understanding of the visual processing hierarchy, low-level '\n",
      "             'visual features dominate decodable object representations early '\n",
      "             'in the time-course, with more abstract representations related '\n",
      "             'to object category emerging later. A key ﬁnding is that the '\n",
      "             'time-course of object processing is highly dynamic and rapidly '\n",
      "             'evolving, with limited temporal generalisation of decodable '\n",
      "             'information. Several studies have examined the emergence of '\n",
      "             'object category structure, and we consider to what degree '\n",
      "             'category decoding can be explained by sensitivity to low-level '\n",
      "             'visual features. Finally, we evaluate recent work attempting to '\n",
      "             'link human behaviour to the neural time-course of object '\n",
      "             'processing.',\n",
      " 'keywords': ['meg',\n",
      "              'eeg',\n",
      "              'mvpa',\n",
      "              'time-series decoding',\n",
      "              'object recognition',\n",
      "              'object categorisation'],\n",
      " 'title': 'Decoding the time-course of object recognition in the human brain_ '\n",
      "          'From visual features to categorical decisions'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0042698909004751-main.pdf\n",
      "{'/CreationDate': \"(D:20100125070450+05'30')\", '/Author': '(\"Donald J. Kalar; Patrick Garrigan; Thomas D. Wickens; James D. Hilger; Philip J. Kellman\")', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.0.0 \\\\(Windows\\\\))', '/AuthoritativeDomain[1]': '(sciencedirect.com)', '/AuthoritativeDomain[2]': '(elsevier.com)', '/ModDate': \"(D:20100125070819+05'30')\", '/Title': '(A unified model of illusory and occluded contour interpolation)', '/Trapped': '/False'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Models of contour interpolation have been proposed for illusory '\n",
      "             'contour interpolation but seldom for interpolation of occluded '\n",
      "             'contours. The identity hypothesis (Kellman & Loukides, 1987; '\n",
      "             'Kellman & Ship- ley, 1991) posits that an early interpolation '\n",
      "             'mechanism is shared by interpolated contours that are ulti- '\n",
      "             'mately perceived as either illusory or occluded. Here we propose '\n",
      "             'a model of such a uniﬁed interpolation mechanism for illusory '\n",
      "             'and occluded contours, building on the framework established in '\n",
      "             'Heitger, von der Heydt, Peterhans, Rosenthaler, and Kubler '\n",
      "             '(1998). We show that a single, neurally plausible mechanism that '\n",
      "             'is consistent with the identity hypothesis also generates '\n",
      "             'contour interpolations in agreement with perception for cases of '\n",
      "             'transparency, self-splitting objects, interpolation with mixed '\n",
      "             'boundary assign- ment, and ‘‘quasimodal” interpolations. '\n",
      "             'Limiting cases for this local, feed-forward approach are pre- '\n",
      "             'sented, demonstrating that both early, local interpolation '\n",
      "             'mechanisms and non-local scene constraints are necessary for '\n",
      "             'describing the perception of interpolated contours. Ó 2009 '\n",
      "             'Elsevier Ltd. All rights reserved.',\n",
      " 'keywords': ['illusory contours',\n",
      "              'occluded contours',\n",
      "              'identity hypothesis',\n",
      "              'contour interpolation',\n",
      "              'computational modeling'],\n",
      " 'title': 'A unified model of illusory and occluded contour interpolation'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0893608016301800-main.pdf\n",
      "{'/CreationDate': \"(D:20170217112543+05'30')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20170217112543+05'30')\", '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.1415926-1.40.10-2.2 \\\\(TeX Live 2009/Debian\\\\) kpathsea version 5.0.0)', '/Producer': '(pdfTeX-1.40.3)', '/Title': '(Towards solving the hard problem of consciousness: The varieties of brain resonances and the conscious experiences that they support)', '/Trapped': '/False'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The hard problem of consciousness is the problem of explaining '\n",
      "             'how we experience qualia or phenome- nal experiences, such as '\n",
      "             'seeing, hearing, and feeling, and knowing what they are. To '\n",
      "             'solve this problem, a theory of consciousness needs to link '\n",
      "             'brain to mind by modeling how emergent properties of several '\n",
      "             'brain mechanisms interacting together embody detailed properties '\n",
      "             'of individual conscious psychologi- cal experiences. This '\n",
      "             'article summarizes evidence that Adaptive Resonance Theory, or '\n",
      "             'ART, accomplishes this goal. ART is a cognitive and neural '\n",
      "             'theory of how advanced brains autonomously learn to attend, rec- '\n",
      "             'ognize, and predict objects and events in a changing world. ART '\n",
      "             'has predicted that ‘‘all conscious states are resonant states’’ '\n",
      "             'as part of its specification of mechanistic links between '\n",
      "             'processes of consciousness, learning, expectation, attention, '\n",
      "             'resonance, and synchrony. It hereby provides functional and '\n",
      "             'mechanistic explanations of data ranging from individual spikes '\n",
      "             'and their synchronization to the dynamics of con- scious '\n",
      "             'perceptual, cognitive, and cognitive–emotional experiences. ART '\n",
      "             'has reached sufficient maturity to begin classifying the brain '\n",
      "             'resonances that support conscious experiences of seeing, '\n",
      "             'hearing, feeling, and knowing. Psychological and neurobiological '\n",
      "             'data in both normal individuals and clinical patients are '\n",
      "             'clarified by this classification. This analysis also explains '\n",
      "             'why not all resonances become conscious, and why not all brain '\n",
      "             'dynamics are resonant. The global organization of the brain into '\n",
      "             'computationally com- plementary cortical processing streams '\n",
      "             '(complementary computing), and the organization of the cerebral '\n",
      "             'cortex into characteristic layers of cells (laminar computing), '\n",
      "             'figure prominently in these explanations of conscious and '\n",
      "             'unconscious processes. Alternative models of consciousness are '\n",
      "             'also discussed. © 2016 The Author. Published by Elsevier Ltd. '\n",
      "             'This is an open access article under the CC BY-NC-ND license '\n",
      "             '(http://creativecommons.org/licenses/by- nc- nd/4.0/).',\n",
      " 'keywords': ['consciousness',\n",
      "              'adaptive resonance',\n",
      "              'attention',\n",
      "              'vision',\n",
      "              'audition',\n",
      "              'emotion'],\n",
      " 'title': 'Towards solving the hard problem of consciousness: The varieties of '\n",
      "          'brain resonances and the conscious experiences that they support'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0896627306005861-main.pdf\n",
      "{'/ModDate': \"(D:20060831043103+05'30')\", '/CreationDate': '(D:00000101000000Z)', '/Title': '(doi:10.1016/j.neuron.2006.07.021)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 6.0.1 \\\\(Windows\\\\))', '/Author': '()', '/Subject': '()', '/Keywords': '()', '/CreationDate--Text': '()'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'It is generally assumed that sensitivity to different stimulus '\n",
      "             'orientations is mapped in a globally equiva- lent fashion across '\n",
      "             'primate visual cortex, at a spatial scale larger than that of '\n",
      "             'orientation columns. However, some evidence predicts instead '\n",
      "             'that radial orientations should produce higher activity than '\n",
      "             'other orientations, throughout visual cortex. Here, this radial '\n",
      "             'orientation bias was robustly conﬁrmed using (1) human psycho- '\n",
      "             'physics, plus fMRI in (2) humans and (3) behaving mon- keys. In '\n",
      "             'visual cortex, fMRI activity was at least 20% higher in the '\n",
      "             'retinotopic representations of polar angle which corresponded to '\n",
      "             'the radial stimulus orientations (relative to tangential). In a '\n",
      "             'global demonstration of this, we activated complementary '\n",
      "             'retinotopic quad- rants of visual cortex by simply changing '\n",
      "             'stimulus orientation, without changing stimulus location in the '\n",
      "             'visual ﬁeld. This evidence reveals a neural link between '\n",
      "             'orientation sensitivity and the cortical retinotopy, which have '\n",
      "             'previously been considered independent.',\n",
      " 'keywords': [],\n",
      " 'title': 'doi:10.1016/j.neuron.2006.07.021'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S089662731830477X-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180720062821+05'30')\", '/Subject': '(Neuron, 99 \\\\(2018\\\\) 257-273. doi:10.1016/j.neuron.2018.06.009)', '/Author': '(Philip A. Kragel)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180720062910+05'30')\", '/doi': '(10.1016/j.neuron.2018.06.009)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Representation, Pattern Information, and Brain Signatures: From Neurons to Neuroimaging)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Representation, Pattern Information, and Brain Signatures: From '\n",
      "          'Neurons to Neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0925231215017634-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(sciencedirect.com)', '/CreationDate': \"(D:20160301203454+05'30')\", '/CrossmarkMajorVersionDate': '(2010-04-23)', '/Subject': '(Neurocomputing, 187 + \\\\(2016\\\\) 27-48. doi:10.1016/j.neucom.2015.09.116)', '/Author': '(Yanming Guo)', '/Creator': '(Elsevier)', '/Keywords': '(Deep learning; Computer vision; Developments; Applications; Trends; Challenges)', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20160301203454+05'30')\", '/doi': '(10.1016/j.neucom.2015.09.116)', '/CrossMarkDomains[1]': '(elsevier.com)', '/Title': '(Deep learning for visual understanding_ A review)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Deep learning algorithms are a subset of the machine learning '\n",
      "             'algorithms, which aim at discovering multiple levels of '\n",
      "             'distributed representations. Recently, numerous deep learning '\n",
      "             'algorithms have been proposed to solve traditional artiﬁcial '\n",
      "             'intelligence problems. This work aims to review the '\n",
      "             'state-of-the- art in deep learning algorithms in computer vision '\n",
      "             'by highlighting the contributions and challenges from over 210 '\n",
      "             'recent research papers. It ﬁrst gives an overview of various '\n",
      "             'deep learning approaches and their recent developments, and then '\n",
      "             'brieﬂy describes their applications in diverse vision tasks, '\n",
      "             'such as image classiﬁcation, object detection, image retrieval, '\n",
      "             'semantic segmentation and human pose estimation. Finally, the '\n",
      "             'paper summarizes the future trends and challenges in designing '\n",
      "             'and training deep neural networks.',\n",
      " 'keywords': ['deep learning',\n",
      "              'computer vision',\n",
      "              'developments',\n",
      "              'applications',\n",
      "              'trends',\n",
      "              'challenges'],\n",
      " 'title': 'Deep learning for visual understanding_ A review'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053810015000355-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20150606161020+05'30')\", '/Subject': '(Consciousness and Cognition, 35 \\\\(2015\\\\) 330-341. doi:10.1016/j.concog.2015.02.006)', '/Author': '(Corrado Corradi-Dellâ\\xa0\\x92Acqua)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.0.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.4)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20150606161451+05'30')\", '/doi': '(10.1016/j.concog.2015.02.006)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Selecting category specific visual information: Top-down and bottom-up control of object based attention)', '/Trapped': '/False'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The ability to select, within the complexity of sensory input, '\n",
      "             'the information most relevant for our purposes is inﬂuenced by '\n",
      "             'both internal settings (i.e., top-down control) and salient '\n",
      "             'features of external stimuli (i.e., bottom-up control). We here '\n",
      "             'investigated using fMRI the neural underpinning of the '\n",
      "             'interaction of top-down and bottom-up processes, as well as '\n",
      "             'their effects on extrastriate areas processing visual stimuli in '\n",
      "             'a category-selective fashion. We presented photos of bodies or '\n",
      "             'buildings embedded into frequency-matched visual noise to the '\n",
      "             'subjects. Stimulus saliency changed gradually due to an altered '\n",
      "             'degree to which photos stood-out in relation to the surrounding '\n",
      "             'noise (hence generating stronger bottom-up control signals). '\n",
      "             'Top-down settings were manipulated via instruction: par- '\n",
      "             'ticipants were asked to attend one stimulus category (i.e., ‘‘is '\n",
      "             'there a body?’’ or ‘‘is there a building?’’). Highly salient '\n",
      "             'stimuli that were inconsistent with participants’ attentional '\n",
      "             'top-down template activated the inferior frontal junction and '\n",
      "             'dorsal parietal regions bilat- erally. Stimuli consistent with '\n",
      "             'participants’ current attentional set additionally activated '\n",
      "             'insular cortex and the parietal operculum. Furthermore, the '\n",
      "             'extrastriate body area (EBA) exhibited increased neural activity '\n",
      "             'when attention was directed to bodies. However, the latter '\n",
      "             'effect was found only when stimuli were presented at '\n",
      "             'intermediate saliency levels, thus suggesting a top-down '\n",
      "             'modulation of this region only in the presence of weak bot- '\n",
      "             'tom-up signals. Taken together, our results highlight the role '\n",
      "             'of the inferior frontal junction and posterior parietal regions '\n",
      "             'in integrating bottom-up and top-down attentional control '\n",
      "             'signals.',\n",
      " 'keywords': ['object attention', 'fmri', 'top-down', 'bottom-up'],\n",
      " 'title': 'Selecting category specific visual information: Top-down and '\n",
      "          'bottom-up control of object based attention'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811907001073-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20070424164238+08'00')\", '/Subject': '(Human Brain Mapping Journal, 36 \\\\(2007\\\\) 88-99. doi:10.1016/j.neuroimage.2007.02.020)', '/Author': '(Janaina MourÃ£o-Miranda)', '/Creator': '(Elsevier)', '/Keywords': '(Machine learning methods; Support vector machine; Classifiers; Functional magnetic resonance imaging data analysis; Dynamic analysis)', '/Producer': '(Acrobat Distiller 7.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.4)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20141009035733+05'30')\", '/doi': '(10.1016/j.neuroimage.2007.02.020)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Dynamic discrimination analysis: A spatialâ\\xa0\\x8dtemporal SVM)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'keywords': ['functional magnetic resonance imaging data analysis; dynamic '\n",
      "              'analysis'],\n",
      " 'title': 'Dynamic discrimination analysis: A spatialâ\\xa0\\x8dtemporal SVM'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811911013012-main.pdf\n",
      "{'/Author': '(Camilo Lamus)', '/CreationDate': \"(D:20120908073116+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.2)', '/Keywords': '(MEG/EEG;  Source localization;  Inverse problem;  Dynamic spatiotemporal modeling)', '/ModDate': \"(D:20140423184139+08'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 63 \\\\(2012\\\\) 894-909. doi:10.1016/j.neuroimage.2011.11.020)', '/Title': '(A spatiotemporal dynamic distributed solution to the MEG inverse problem)', '/doi': '(10.1016/j.neuroimage.2011.11.020)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'MEG/EEG are non-invasive imaging techniques that record brain '\n",
      "             'activity with high temporal resolution. However, estimation of '\n",
      "             'brain source currents from surface recordings requires solving '\n",
      "             'an ill-conditioned in- verse problem. Converging lines of '\n",
      "             'evidence in neuroscience, from neuronal network models to '\n",
      "             'resting-state imaging and neurophysiology, suggest that cortical '\n",
      "             'activation is a distributed spatiotemporal dynamic process, '\n",
      "             'supported by both local and long-distance neuroanatomic '\n",
      "             'connections. Because spatiotemporal dy- namics of this kind are '\n",
      "             'central to brain physiology, inverse solutions could be improved '\n",
      "             'by incorporating models of these dynamics. In this article, we '\n",
      "             'present a model for cortical activity based on nearest- neighbor '\n",
      "             'autoregression that incorporates local spatiotemporal '\n",
      "             'interactions between distributed sources in a manner consistent '\n",
      "             'with neurophysiology and neuroanatomy. We develop a dynamic '\n",
      "             'Maximum a Posteriori Expectation-Maximization (dMAP-EM) source '\n",
      "             'localization algorithm for estimation of cortical sources and '\n",
      "             'model parameters based on the Kalman Filter, the Fixed Interval '\n",
      "             'Smoother, and the EM algorithms. We apply the dMAP-EM algorithm '\n",
      "             'to simulated experiments as well as to human experimental data. '\n",
      "             'Further- more, we derive expressions to relate our dynamic '\n",
      "             'estimation formulas to those of standard static models, and show '\n",
      "             'how dynamic methods optimally assimilate past and future data. '\n",
      "             'Our results establish the feasibil- ity of spatiotemporal '\n",
      "             'dynamic estimation in large-scale distributed source spaces with '\n",
      "             'several thousand source locations and hundreds of sensors, with '\n",
      "             'resulting inverse solutions that provide substantial perfor- '\n",
      "             'mance improvements over static methods.',\n",
      " 'keywords': ['meg/eeg',\n",
      "              'source localization',\n",
      "              'inverse problem',\n",
      "              'dynamic spatiotemporal modeling'],\n",
      " 'title': 'A spatiotemporal dynamic distributed solution to the MEG inverse '\n",
      "          'problem'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811912004429-main.pdf\n",
      "{'/Author': '(H. Luckhoo)', '/CreationDate': \"(D:20120614180251+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.2)', '/Keywords': '(MEG; Working memory; Independent component analysis; General linear model; Hippocampus; Neural oscillations)', '/ModDate': \"(D:20140906132648+05'30')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 62 \\\\(2012\\\\) 530-541. doi:10.1016/j.neuroimage.2012.04.046)', '/Title': '(Inferring task-related networks using independent component analysis in magnetoencephalography)', '/doi': '(10.1016/j.neuroimage.2012.04.046)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'A novel framework for analysing task-positive data in '\n",
      "             'magnetoencephalography (MEG) is presented that can identify '\n",
      "             'task-related networks. Techniques that combine beamforming, the '\n",
      "             'Hilbert transform and temporal independent component analysis '\n",
      "             '(ICA) have recently been applied to resting-state MEG data and '\n",
      "             'have been shown to extract resting-state networks similar to '\n",
      "             'those found in fMRI. Here we extend this approach in two ways. '\n",
      "             'First, we systematically investigate optimisation of '\n",
      "             'time-frequency windows for connectivity measurement. This is '\n",
      "             'achieved by estimating the distribution of functional '\n",
      "             'connectivity scores between nodes of known resting-state '\n",
      "             'networks and contrasting it with a distribution of artefactual '\n",
      "             'scores that are en- tirely due to spatial leakage caused by the '\n",
      "             'inverse problem. We ﬁnd that functional connectivity, both in '\n",
      "             'the resting-state and during a cognitive task, is best estimated '\n",
      "             'via correlations in the oscillatory envelope in the 8–20 Hz '\n",
      "             'frequency range, temporally down-sampled with windows of 1–4 s. '\n",
      "             'Second, we combine ICA with the general linear model (GLM) to '\n",
      "             'incorporate knowledge of task structure into our connectivity '\n",
      "             'analysis. The combination of ICA with the GLM helps overcome '\n",
      "             'problems of these techniques when used independent- ly: namely, '\n",
      "             'the interpretation and separation of interesting independent '\n",
      "             'components from those that repre- sent noise in ICA and the '\n",
      "             'correction for multiple comparisons when applying the GLM. We '\n",
      "             'demonstrate the approach on a 2-back working memory task and '\n",
      "             'show that this novel analysis framework is able to elucidate the '\n",
      "             'functional networks involved in the task beyond that which is '\n",
      "             'achieved using the GLM alone. We ﬁnd ev- idence of localised '\n",
      "             'task-related activity in the area of the hippocampus, which is '\n",
      "             'difﬁcult to detect reliably using standard methods. '\n",
      "             'Task-positive ICA, coupled with the GLM, has the potential to be '\n",
      "             'a powerful tool in the analysis of MEG data.',\n",
      " 'keywords': ['meg',\n",
      "              'working memory',\n",
      "              'independent component analysis',\n",
      "              'general linear model',\n",
      "              'hippocampus',\n",
      "              'neural oscillations'],\n",
      " 'title': 'Inferring task-related networks using independent component '\n",
      "          'analysis in magnetoencephalography'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811913002851-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20130507221352+08'00')\", '/Subject': '(NeuroImage, 77 \\\\(2013\\\\) 77-92. doi:10.1016/j.neuroimage.2013.03.036)', '/Author': '(Mark W. Woolrich)', '/Creator': '(Elsevier)', '/Keywords': '(Magnetoencephalography; MEG; EEG; Source reconstruction; Microstates; Connectivity; Hidden Markov Model)', '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.2)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20140823115442+05'30')\", '/doi': '(10.1016/j.neuroimage.2013.03.036)', '/CrossMarkDomains[1]': '(elsevier.com)', '/Title': '(Dynamic state allocation for MEG source reconstruction)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.layout:Too many boxes (102) to group, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Fractional occupancy kð Þ ¼ 1 T',\n",
      " 'keywords': ['magnetoencephalography',\n",
      "              'meg',\n",
      "              'eeg',\n",
      "              'source reconstruction',\n",
      "              'microstates',\n",
      "              'connectivity',\n",
      "              'hidden markov model'],\n",
      " 'title': 'Dynamic state allocation for MEG source reconstruction'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811914001220-main.pdf\n",
      "{'/CreationDate': \"(D:20140411223942+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20140411223947Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '<feff00460075006e006300740069006f006e0061006c002000730069007a00650020006f0066002000680075006d0061006e002000760069007300750061006c00200061007200650061002000560031003a002000410020006e0065007500720061006c00200063006f007200720065006c0061007400650020006f006600200074006f007020130064006f0077006e00200061007400740065006e00740069006f006e>'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': \"Heavy demands are placed on the brain's attentional capacity \"\n",
      "             'when selecting a target item in a cluttered visual scene, or '\n",
      "             'when reading. It is widely accepted that such attentional '\n",
      "             'selection is mediated by top–down signals from higher cortical '\n",
      "             'areas to early visual areas such as the primary visual cortex '\n",
      "             '(V1). Further, it has also been reported that there is '\n",
      "             'considerable variation in the surface area of V1. This variation '\n",
      "             'may impact on either the number or speciﬁcity of attentional '\n",
      "             'feedback signals and, thereby, the efﬁciency of attentional '\n",
      "             'mechanisms. In this study, we investigated whether individual '\n",
      "             'differences between humans performing attention-demanding tasks '\n",
      "             'can be related to the functional area of V1. We found that those '\n",
      "             'with a larger representation in V1 of the central 12° of the '\n",
      "             'visual ﬁeld as measured using BOLD signals from fMRI were able '\n",
      "             'to perform a serial search task at a faster rate. In line with '\n",
      "             'recent suggestions of the vital role of visuo-spatial attention '\n",
      "             'in reading, the speed of reading showed a strong positive '\n",
      "             'correlation with the speed of visual search, although it showed '\n",
      "             'little correlation with the size of V1. The results support the '\n",
      "             'idea that the functional size of the primary visual cortex is an '\n",
      "             'important determinant of the efﬁciency of selective spatial '\n",
      "             'attention for simple tasks, and that the attentional processing '\n",
      "             'required for complex tasks like reading are to a large extent '\n",
      "             'determined by other brain areas and inter-areal connections.',\n",
      " 'keywords': ['visual attention',\n",
      "              'primary visual cortex',\n",
      "              'fmri',\n",
      "              'reading',\n",
      "              'visual search'],\n",
      " 'title': 'feff00460075006e006300740069006f006e0061006c002000730069007a00650020006f0066002000680075006d0061006e002000760069007300750061006c00200061007200650061002000560031003a002000410020006e0065007500720061006c00200063006f007200720065006c0061007400650020006f006600200074006f007020130064006f0077006e00200061007400740065006e00740069006f006e'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811914010325-main.pdf\n",
      "{'/CreationDate': \"(D:20150130061349+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20150205124502Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Magnetoencephalography and electroencephalography (M/EEG) '\n",
      "             'measure non-invasively the weak electromag- netic ﬁelds induced '\n",
      "             'by post-synaptic neural currents. The estimation of the spatial '\n",
      "             'covariance of the signals re- corded on M/EEG sensors is a '\n",
      "             'building block of modern data analysis pipelines. Such '\n",
      "             'covariance estimates are used in brain–computer interfaces (BCI) '\n",
      "             'systems, in nearly all source localization methods for spatial '\n",
      "             'whitening as well as for data covariance estimation in '\n",
      "             'beamformers. The rationale for such models is that the signals '\n",
      "             'can be modeled by a zero mean Gaussian distribution. While '\n",
      "             'maximizing the Gaussian likelihood seems natural, it leads to a '\n",
      "             'covariance estimate known as empirical covariance (EC). It turns '\n",
      "             'out that the EC is a poor estimate of the true covariance when '\n",
      "             'the number of samples is small. To address this issue the '\n",
      "             'estimation needs to be regularized. The most common approach '\n",
      "             'downweights off-diagonal coefﬁcients, while more advanced '\n",
      "             'regularization methods are based on shrinkage techniques or '\n",
      "             'generative models with low rank assumptions: probabilistic PCA '\n",
      "             '(PPCA) and factor analysis (FA). Using cross-validation all of '\n",
      "             'these models can be tuned and compared based on Gaussian '\n",
      "             'likelihood computed on unseen data. We investigated these models '\n",
      "             'on simulations, one electroencephalography (EEG) dataset as well '\n",
      "             'as magnetoen- cephalography (MEG) datasets from the most common '\n",
      "             'MEG systems. First, our results demonstrate that different '\n",
      "             'models can be the best, depending on the number of samples, '\n",
      "             'heterogeneity of sensor types and noise properties. Second, we '\n",
      "             'show that the models tuned by cross-validation are superior to '\n",
      "             'models with hand-selected regular- ization. Hence, we propose an '\n",
      "             'automated solution to the often overlooked problem of covariance '\n",
      "             'estimation of M/EEG signals. The relevance of the procedure is '\n",
      "             'demonstrated here for spatial whitening and source localization '\n",
      "             'of MEG signals.',\n",
      " 'keywords': ['electroencephalography (eeg)',\n",
      "              'magnetoencephalography (meg)',\n",
      "              'neuroimaging',\n",
      "              'principal component analysis (pca)',\n",
      "              'factor analysis (fa)',\n",
      "              'covariance estimation',\n",
      "              'whitening',\n",
      "              'model selection',\n",
      "              'statistical learning'],\n",
      " 'title': 'Automated model selection in covariance estimation and spatial '\n",
      "          'whitening of MEG and EEG signals'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811915005315-main.pdf\n",
      "{'/CreationDate': \"(D:20150801085206+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20150825173935Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Parallel processing of somatosensory information: Evidence from dynamic causal modeling of MEG data)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'The advent of methods to investigate network dynamics has led to '\n",
      "             'discussion of whether somatosensory inputs are processed in '\n",
      "             'serial or in parallel. Both hypotheses are supported by DCM '\n",
      "             'analyses of fMRI studies. In the present study, we revisited '\n",
      "             'this controversy using DCM on magnetoencephalographic (MEG) data '\n",
      "             'during so- matosensory stimulation. Bayesian model comparison '\n",
      "             'was used to allow for direct inference on the processing stream. '\n",
      "             'Additionally we varied the duration of the time-window of '\n",
      "             'analyzed data after the somatosensory stim- ulus. This approach '\n",
      "             'allowed us to explore time dependent changes in the processing '\n",
      "             'stream of somatosensory information and to evaluate the '\n",
      "             'consistency of results. We found that models favoring a parallel '\n",
      "             'processing route best describe neural activities elicited by '\n",
      "             'somatosensory stimuli. This result was consistent for different '\n",
      "             'time-windows. Although it is assumed that the majority of '\n",
      "             'somatosensory information is delivered to the SI, the current '\n",
      "             'results indicate that at least a small part of somatosensory '\n",
      "             'information is delivered in parallel to the SII. These ﬁndings '\n",
      "             'emphasize the importance of data analysis with high temporal '\n",
      "             'resolution. © 2015 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['meg',\n",
      "              'dcm',\n",
      "              'somatosensory cortex',\n",
      "              'effective connectivity',\n",
      "              'perception'],\n",
      " 'title': 'Parallel processing of somatosensory information: Evidence from '\n",
      "          'dynamic causal modeling of MEG data'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811915006205-main.pdf\n",
      "{'/Author': '(Radoslaw Martin Cichy)', '/CreationDate': \"(D:20151001161305+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.4)', '/Keywords': '(Orientation encoding;  Magnetoencephalography;  Multivariate pattern analysis;  Cortical columns)', '/ModDate': \"(D:20180709152822+08'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 121 \\\\(2015\\\\) 193-204. doi:10.1016/j.neuroimage.2015.07.011)', '/Title': '(Can visual information encoded in cortical columns be decoded from magnetoencephalography data in humans?)', '/doi': '(10.1016/j.neuroimage.2015.07.011)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'It is a principal open question whether noninvasive imaging '\n",
      "             'methods in humans can decode information encoded at a spatial '\n",
      "             'scale as ﬁne as the basic functional unit of cortex: cortical '\n",
      "             'columns. We addressed this question in ﬁve '\n",
      "             'magnetoencephalography (MEG) experiments by investigating a '\n",
      "             'columnar-level encoded visual feature: contrast edge '\n",
      "             'orientation. We found that MEG signals contained '\n",
      "             'orientation-speciﬁc information as early as approximately 50 ms '\n",
      "             'after stimulus onset even when controlling for confounds, such '\n",
      "             'as overrepresentation of particular orientations, stimulus edge '\n",
      "             'interactions, and global form-related signals. Theoretical '\n",
      "             'modeling con- ﬁrmed the plausibility of this empirical result. '\n",
      "             'An essential consequence of our results is that information '\n",
      "             'encoded in the human brain at the level of cortical columns '\n",
      "             'should in general be accessible by multivariate anal- ysis of '\n",
      "             'electrophysiological signals.',\n",
      " 'keywords': ['orientation encoding',\n",
      "              'magnetoencephalography',\n",
      "              'multivariate pattern analysis',\n",
      "              'cortical columns'],\n",
      " 'title': 'Can visual information encoded in cortical columns be decoded from '\n",
      "          'magnetoencephalography data in humans?'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916000124-main.pdf\n",
      "{'/CreationDate': \"(D:20160214210728+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20160217142348Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Representational dynamics of object recognition: Feedforward and feedback information flows)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Object perception involves a range of visual and cognitive '\n",
      "             'processes, and is known to include both a feedfoward ﬂow of '\n",
      "             'information from early visual cortical areas to higher cortical '\n",
      "             'areas, along with feedback from areas such as prefrontal cortex. '\n",
      "             'Previous studies have found that low and high spatial frequency '\n",
      "             'information regarding ob- ject identity may be processed over '\n",
      "             'different timescales. Here we used the high temporal resolution '\n",
      "             'of magneto- encephalography (MEG) combined with multivariate '\n",
      "             'pattern analysis to measure information speciﬁcally related to '\n",
      "             'object identity in peri-frontal and peri-occipital areas. Using '\n",
      "             'stimuli closely matched in their low- level visual content, we '\n",
      "             'found that activity in peri-occipital cortex could be used to '\n",
      "             'decode object identity from ~ 80 ms post stimulus onset, and '\n",
      "             'activity in peri-frontal cortex could also be used to decode '\n",
      "             'object identity from a later time (~ 265 ms post stimulus '\n",
      "             'onset). Low spatial frequency information related to object '\n",
      "             'identity was present in the MEG signal at an earlier time than '\n",
      "             'high spatial frequency information for peri-occipital cortex, '\n",
      "             'but not for peri-frontal cortex. We additionally used Granger '\n",
      "             'causality analysis to compare feedforward and feed- back '\n",
      "             'inﬂuences on representational content, and found evidence of '\n",
      "             'both an early feedfoward ﬂow and later feed- back ﬂow of '\n",
      "             'information related to object identity. We discuss our ﬁndings '\n",
      "             'in relation to existing theories of object processing and '\n",
      "             'propose how the methods we use here could be used to address '\n",
      "             'further questions of the neural substrates underlying object '\n",
      "             'perception.',\n",
      " 'keywords': ['magnetoencephalography',\n",
      "              'pattern classiﬁer analysis',\n",
      "              'feedback',\n",
      "              'coarse-to-ﬁne',\n",
      "              'granger causality',\n",
      "              'visual perception'],\n",
      " 'title': 'Representational dynamics of object recognition: Feedforward and '\n",
      "          'feedback information flows'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916001269-main.pdf\n",
      "{'/CreationDate': \"(D:20160228144101+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20160427091921Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Perceptual similarity of visual patterns predicts dynamic neural activation patterns measured with MEG)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Perceptual similarity is a cognitive judgment that represents '\n",
      "             'the end-stage of a complex cascade of hierarchical processing '\n",
      "             'throughout visual cortex. Previous studies have shown a '\n",
      "             'correspondence between the similarity of coarse-scale fMRI '\n",
      "             'activation patterns and the perceived similarity of visual '\n",
      "             'stimuli, suggesting that visual objects that appear similar also '\n",
      "             'share similar underlying patterns of neural activation. Here we '\n",
      "             \"explore the temporal re- lationship between the human brain's \"\n",
      "             'time-varying representation of visual patterns and behavioral '\n",
      "             'judgments of perceptual similarity. The visual stimuli were '\n",
      "             'abstract patterns constructed from identical perceptual units '\n",
      "             '(oriented Gabor patches) so that each pattern had a unique '\n",
      "             'global form or perceptual ‘Gestalt’. The visual stimuli were '\n",
      "             'decodable from evoked neural activation patterns measured with '\n",
      "             'magnetoencephalography (MEG), how- ever, stimuli differed in the '\n",
      "             'similarity of their neural representation as estimated by '\n",
      "             'differences in decodability. Early after stimulus onset (from 50 '\n",
      "             'ms), a model based on retinotopic organization predicted the '\n",
      "             'representation- al similarity of the visual stimuli. Following '\n",
      "             'the peak correlation between the retinotopic model and neural '\n",
      "             'data at 80 ms, the neural representations quickly evolved so '\n",
      "             'that retinotopy no longer provided a sufﬁcient account of the '\n",
      "             \"brain's time-varying representation of the stimuli. Overall the \"\n",
      "             \"strongest predictor of the brain's representa- tion was a model \"\n",
      "             'based on human judgments of perceptual similarity, which reached '\n",
      "             'the limits of the maximum correlation with the neural data '\n",
      "             'deﬁned by the ‘noise ceiling’. Our results show that large-scale '\n",
      "             'brain activation patterns contain a neural signature for the '\n",
      "             'perceptual Gestalt of composite visual features, and demonstrate '\n",
      "             'a strong correspondence between perception and complex patterns '\n",
      "             'of brain activity. © 2016 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['magnetoencephalography (meg)',\n",
      "              'representational similarity analysis',\n",
      "              'perceptual similarity',\n",
      "              'representational geometry',\n",
      "              'decoding',\n",
      "              'gestalt perception'],\n",
      " 'title': 'Perceptual similarity of visual patterns predicts dynamic neural '\n",
      "          'activation patterns measured with MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916300076-main.pdf\n",
      "{'/Author': '(Radoslaw Martin Cichy)', '/CreationDate': \"(D:20170524223408+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(Scene perception; Spatial layout; Magnetoencephalography; Deep neural network; Representational similarity analysis)', '/ModDate': \"(D:20170524223408+05'30')\", '/Subject': '(NeuroImage, 153 \\\\(2017\\\\) 346-358. doi:10.1016/j.neuroimage.2016.03.063)', '/Title': '(Dynamics of scene representations in the human brain revealed by magnetoencephalography and deep neural networks)', '/doi': '(10.1016/j.neuroimage.2016.03.063)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Human scene recognition is a rapid multistep process evolving '\n",
      "             'over time from single scene image to spatial layout processing. '\n",
      "             'We used multivariate pattern analyses on magnetoencephalography '\n",
      "             '(MEG) data to unravel the time course of this cortical process. '\n",
      "             'Following an early signal for lower-level visual analysis of '\n",
      "             'single scenes at ~100 ms, we found a marker of real-world scene '\n",
      "             'size, i.e. spatial layout processing, at ~250 ms indexing neural '\n",
      "             'representations robust to changes in unrelated scene properties '\n",
      "             'and viewing conditions. For a quantitative model of how scene '\n",
      "             'size representations may arise in the brain, we compared MEG '\n",
      "             'data to a deep neural network model trained on scene '\n",
      "             'classiﬁcation. Representations of scene size emerged '\n",
      "             'intrinsically in the model, and resolved emerging neural scene '\n",
      "             'size representation. Together our data provide a ﬁrst '\n",
      "             'description of an electrophysiological signal for layout '\n",
      "             'processing in humans, and suggest that deep neural networks are '\n",
      "             'a promising framework to investigate how spatial layout '\n",
      "             'representations emerge in the human brain.',\n",
      " 'keywords': ['scene perception',\n",
      "              'spatial layout',\n",
      "              'magnetoencephalography',\n",
      "              'deep neural network',\n",
      "              'representational similarity analysis'],\n",
      " 'title': 'Dynamics of scene representations in the human brain revealed by '\n",
      "          'magnetoencephalography and deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916301914-main.pdf\n",
      "{'/Author': '(G.L. Colclough)', '/CreationDate': \"(D:20160625062025+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(MEG;  Source leakage;  Magnetic field spread;  Functional connectivity;  Network analysis;  Connectome)', '/ModDate': \"(D:20160625172651+08'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 138 \\\\(2016\\\\) 284-293. doi:10.1016/j.neuroimage.2016.05.070)', '/Title': '(How reliable are MEG resting-state connectivity metrics?)', '/doi': '(10.1016/j.neuroimage.2016.05.070)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'MEG offers dynamic and spectral resolution for resting-state '\n",
      "             'connectivity which is unavailable in fMRI. However, there are a '\n",
      "             'wide range of available network estimation methods for MEG, and '\n",
      "             'little in the way of existing guid- ance on which ones to '\n",
      "             'employ. In this technical note, we investigate the extent to '\n",
      "             'which many popular measures of stationary connectivity are '\n",
      "             'suitable for use in resting-state MEG, localising magnetic '\n",
      "             'sources with a scalar beamformer. We use as empirical criteria '\n",
      "             'that network measures for individual subjects should be '\n",
      "             'repeatable, and that group-level connectivity estimation shows '\n",
      "             'good reproducibility. Using publically-available data from the '\n",
      "             'Human Connectome Project, we test the reliability of 12 network '\n",
      "             'estimation techniques against these criteria. We ﬁnd that the '\n",
      "             'impact of magnetic ﬁeld spread or spatial leakage artefact is '\n",
      "             'profound, creates a major confound for many connectivity '\n",
      "             'measures, and can artiﬁcially inﬂate measures of consistency. '\n",
      "             'Among those robust to this effect, we ﬁnd poor test-retest '\n",
      "             'reliability in phase- or coherence-based metrics such as the '\n",
      "             'phase lag index or the imaginary part of coherency. The most '\n",
      "             'consistent methods for stationary connectivity estimation over '\n",
      "             'all of our tests are simple amplitude envelope correlation and '\n",
      "             'partial correlation measures. © 2016 The Authors. Published by '\n",
      "             'Elsevier Inc. This is an open access article under the CC BY '\n",
      "             'license (http://creativecommons.org/licenses/by/4.0/).',\n",
      " 'keywords': ['meg',\n",
      "              'source leakage',\n",
      "              'magnetic ﬁeld spread',\n",
      "              'functional connectivity',\n",
      "              'network analysis',\n",
      "              'connectome'],\n",
      " 'title': 'How reliable are MEG resting-state connectivity metrics?'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916306802-main.pdf\n",
      "{'/Author': '(Lucrezia Liuzzi)', '/CreationDate': \"(D:20170630192212+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(Functional connectivity; Networks; Magnetoencephalography; MEG; Resting state; Beamformer)', '/ModDate': \"(D:20170630192212+05'30')\", '/Subject': '(NeuroImage, 155 \\\\(2017\\\\) 565-576. doi:10.1016/j.neuroimage.2016.11.064)', '/Title': '(Optimising experimental design for MEG resting state functional connectivity measurement)', '/doi': '(10.1016/j.neuroimage.2016.11.064)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n",
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n",
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'The study of functional connectivity using '\n",
      "             'magnetoencephalography (MEG) is an expanding area of '\n",
      "             'neuroimaging, and adds an extra dimension to the more common '\n",
      "             'assessments made using fMRI. The importance of such metrics is '\n",
      "             'growing, with recent demonstrations of their utility in clinical '\n",
      "             'research, however previous reports suggest that whilst group '\n",
      "             'level resting state connectivity is robust, single session '\n",
      "             'recordings lack repeatability. Such robustness is critical if '\n",
      "             'MEG measures in individual subjects are to prove clinically '\n",
      "             'valuable. In the present paper, we test how practical aspects of '\n",
      "             'experimental design aﬀect the intra-subject repeatability of MEG '\n",
      "             'ﬁndings; speciﬁcally we assess the eﬀect of co-registration '\n",
      "             'method and data recording duration. We show that the use of a '\n",
      "             'foam head-cast, which is known to improve co-registration '\n",
      "             'accuracy, increased signiﬁcantly the between session '\n",
      "             'repeatability of both beamformer reconstruction and connectivity '\n",
      "             'estimation. We also show that recording duration is a critical '\n",
      "             'parameter, with large improvements in repeatability apparent '\n",
      "             'when using ten minute, compared to ﬁve minute recordings. '\n",
      "             'Further analyses suggest that the origin of this latter eﬀect is '\n",
      "             'not underpinned by technical aspects of source reconstruction, '\n",
      "             'but rather by a genuine eﬀect of brain state; short recordings '\n",
      "             'are simply ineﬃcient at capturing the canonical MEG network in a '\n",
      "             'single subject. Our results provide important insights on '\n",
      "             'experimental design and will prove valuable for future MEG '\n",
      "             'connectivity studies.',\n",
      " 'keywords': ['functional connectivity',\n",
      "              'networks',\n",
      "              'magnetoencephalography',\n",
      "              'meg',\n",
      "              'resting state',\n",
      "              'beamformer'],\n",
      " 'title': 'Optimising experimental design for MEG resting state functional '\n",
      "          'connectivity measurement'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917302458-main.pdf\n",
      "{'/Author': '(Manoj Kumar)', '/CreationDate': \"(D:20170629162653+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(Natural scenes; Semantics; Pictures; Words; MVPA; fMRI)', '/ModDate': \"(D:20170629162653+05'30')\", '/Subject': '(NeuroImage, 155 \\\\(2017\\\\) 422-436. doi:10.1016/j.neuroimage.2017.03.037)', '/Title': '(Evidence for similar patterns of neural activity elicited by picture- and word-based representations of natural scenes)', '/doi': '(10.1016/j.neuroimage.2017.03.037)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'A long-standing core question in cognitive science is whether '\n",
      "             'diﬀerent modalities and representation types (pictures, words, '\n",
      "             'sounds, etc.) access a common store of semantic information. '\n",
      "             'Although diﬀerent input types have been shown to activate a '\n",
      "             'shared network of brain regions, this does not necessitate that '\n",
      "             'there is a common representation, as the neurons in these '\n",
      "             'regions could still diﬀerentially process the diﬀerent '\n",
      "             'modalities. However, multi-voxel pattern analysis can be used to '\n",
      "             'assess whether, e.g., pictures and words evoke a similar pattern '\n",
      "             'of activity, such that the patterns that separate categories in '\n",
      "             'one modality transfer to the other. Prior work using this method '\n",
      "             'has found support for a common code, but has two limitations: '\n",
      "             'they have either only examined disparate categories (e.g. '\n",
      "             'animals vs. tools) that are known to activate diﬀerent brain '\n",
      "             'regions, raising the possibility that the pattern separation and '\n",
      "             'inferred similarity reﬂects only large scale diﬀerences between '\n",
      "             'the categories or they have been limited to individual object '\n",
      "             'representations. By using natural scene categories, we not only '\n",
      "             'extend the current literature on cross-modal representations '\n",
      "             'beyond objects, but also, because natural scene categories '\n",
      "             'activate a common set of brain regions, we identify a more '\n",
      "             'ﬁne-grained (i.e. higher spatial resolution) common '\n",
      "             'representation. Speciﬁcally, we studied picture- and word-based '\n",
      "             'representations of natural scene stimuli from four diﬀerent '\n",
      "             'categories: beaches, cities, highways, and mountains. '\n",
      "             'Participants passively viewed blocks of either phrases (e.g. '\n",
      "             '\"sandy beach\") describing scenes or photographs from those same '\n",
      "             'scene categories. To determine whether the phrases and pictures '\n",
      "             'evoke a common code, we asked whether a classiﬁer trained on one '\n",
      "             'stimulus type (e.g. phrase stimuli) would transfer (i.e. '\n",
      "             'cross-decode) to the other stimulus type (e.g. picture stimuli). '\n",
      "             'The analysis revealed cross-decoding in the occipitotemporal, '\n",
      "             'posterior parietal and frontal cortices. This similarity of '\n",
      "             'neural activity patterns across the two input types, for '\n",
      "             'categories that co- activate local brain regions, provides '\n",
      "             'strong evidence of a common semantic code for pictures and words '\n",
      "             'in the brain.',\n",
      " 'keywords': ['natural scenes',\n",
      "              'semantics',\n",
      "              'pictures',\n",
      "              'words',\n",
      "              'mvpa',\n",
      "              'fmri'],\n",
      " 'title': 'Evidence for similar patterns of neural activity elicited by '\n",
      "          'picture- and word-based representations of natural scenes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917305906-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180831013512+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 267-279. doi:10.1016/j.neuroimage.2017.07.022)', '/Author': '(Dimitrios Pantazis)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180831013558+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.07.022)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Decoding the orientation of contrast edges from MEG evoked and induced responses)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual gamma oscillations have been proposed to subserve '\n",
      "             'perceptual binding, but their strong modulation by diverse '\n",
      "             'stimulus features confounds interpretations of their precise '\n",
      "             'functional role. Overcoming this challenge necessitates a '\n",
      "             'comprehensive account of the relationship between gamma '\n",
      "             'responses and stimulus features. Here we used multivariate '\n",
      "             'pattern analyses on human MEG data to characterize the '\n",
      "             'relationships between gamma responses and one basic stimulus '\n",
      "             'feature, the orientation of contrast edges. Our ﬁndings conﬁrmed '\n",
      "             'we could decode orientation information from induced responses '\n",
      "             'in two dominant frequency bands at 24–32 Hz and 50–58 Hz. '\n",
      "             'Decoding was higher for cardinal than oblique orientations, with '\n",
      "             'similar results also obtained for evoked MEG responses. In '\n",
      "             'contrast to multivariate analyses, orientation information was '\n",
      "             'mostly absent in uni- variate signals: evoked and induced '\n",
      "             'responses in early visual cortex were similar in all '\n",
      "             'orientations, with only exception an inverse oblique effect '\n",
      "             'observed in induced responses, such that cardinal orientations '\n",
      "             'produced weaker oscillatory signals than oblique orientations. '\n",
      "             'Taken together, our results showed multivariate methods are well '\n",
      "             'suited for the analysis of gamma oscillations, with multivariate '\n",
      "             'patterns robustly encoding orientation in- formation and '\n",
      "             'predominantly discriminating cardinal from oblique stimuli.',\n",
      " 'keywords': ['orientation',\n",
      "              'gratings',\n",
      "              'gamma oscillations',\n",
      "              'oblique effect',\n",
      "              'meg',\n",
      "              'multivariate analysis',\n",
      "              'pattern classiﬁcation',\n",
      "              'representational similarity analysis',\n",
      "              'feature binding'],\n",
      " 'title': 'Decoding the orientation of contrast edges from MEG evoked and '\n",
      "          'induced responses'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917306523-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180830232532+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 4-18. doi:10.1016/j.neuroimage.2017.08.005)', '/Author': '(Martin N. Hebart)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180830232618+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.08.005)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Deconstructing multivariate decoding for the study of brain function)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate decoding methods were developed originally as tools '\n",
      "             'to enable accurate predictions in real-world applications. The '\n",
      "             'realization that these methods can also be employed to study '\n",
      "             'brain function has led to their widespread adoption in the '\n",
      "             'neurosciences. However, prior to the rise of multivariate '\n",
      "             'decoding, the study of brain function was ﬁrmly embedded in a '\n",
      "             'statistical philosophy grounded on univariate methods of data '\n",
      "             'analysis. In this way, multivariate decoding for brain '\n",
      "             'interpretation grew out of two established frameworks: '\n",
      "             'multivariate decoding for predictions in real-world '\n",
      "             'applications, and classical univariate analysis based on the '\n",
      "             'study and interpretation of brain activation. We argue that this '\n",
      "             'led to two confusions, one reﬂecting a mixture of multi- variate '\n",
      "             'decoding for prediction or interpretation, and the other a '\n",
      "             'mixture of the conceptual and statistical phi- losophies '\n",
      "             'underlying multivariate decoding and classical univariate '\n",
      "             'analysis. Here we attempt to systematically disambiguate '\n",
      "             'multivariate decoding for the study of brain function from the '\n",
      "             'frameworks it grew out of. After elaborating these confusions '\n",
      "             'and their consequences, we describe six, often unappreciated, '\n",
      "             'differences between classical univariate analysis and '\n",
      "             'multivariate decoding. We then focus on how the common '\n",
      "             'interpretation of what is signal and noise changes in '\n",
      "             'multivariate decoding. Finally, we use four examples to '\n",
      "             'illustrate where these confusions may impact the interpretation '\n",
      "             'of neuroimaging data. We conclude with a discussion of potential '\n",
      "             'strategies to help resolve these confusions in interpreting '\n",
      "             'multivariate decoding results, including the potential departure '\n",
      "             'from multivariate decoding methods for the study of brain '\n",
      "             'function.',\n",
      " 'keywords': ['multivariate decoding',\n",
      "              'multivariate analysis',\n",
      "              'multivariate pattern analysis',\n",
      "              'encoding',\n",
      "              'decoding',\n",
      "              'fmri',\n",
      "              'prediction'],\n",
      " 'title': 'Deconstructing multivariate decoding for the study of brain '\n",
      "          'function'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917306638-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180831031226+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 101-109. doi:10.1016/j.neuroimage.2017.08.016)', '/Author': '(Kendrick N. Kay)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180831031300+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.08.016)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Principles for models of neural information processing)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The goal of cognitive neuroscience is to understand how mental '\n",
      "             'operations are performed by the brain. Given the complexity of '\n",
      "             'the brain, this is a challenging endeavor that requires the '\n",
      "             'development of formal models. Here, I provide a perspective on '\n",
      "             'models of neural information processing in cognitive '\n",
      "             'neuroscience. I deﬁne what these models are, explain why they '\n",
      "             'are useful, and specify criteria for evaluating models. I also '\n",
      "             'highlight the difference between functional and mechanistic '\n",
      "             'models, and call attention to the value that neuroanatomy has '\n",
      "             'for understanding brain function. Based on the principles I '\n",
      "             'propose, I proceed to evaluate the merit of recently touted deep '\n",
      "             'neural network models. I contend that these models are '\n",
      "             'promising, but substantial work is necessary (i) to clarify what '\n",
      "             'type of explanation these models provide, (ii) to determine what '\n",
      "             'speciﬁc effects they accurately explain, and (iii) to improve '\n",
      "             'our understanding of how they work.',\n",
      " 'keywords': [],\n",
      " 'title': 'Principles for models of neural information processing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S105381191730664X-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180831020231+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 232-242. doi:10.1016/j.neuroimage.2017.08.017)', '/Author': '(Satoshi Nishida)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180831020313+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.08.017)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Decoding naturalistic experiences from human brain activity via distributed representations of words)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Natural visual scenes induce rich perceptual experiences that '\n",
      "             'are highly diverse from scene to scene and from person to '\n",
      "             'person. Here, we propose a new framework for decoding such '\n",
      "             'experiences using a distributed repre- sentation of words. We '\n",
      "             'used functional magnetic resonance imaging (fMRI) to measure '\n",
      "             'brain activity evoked by natural movie scenes. Then, we '\n",
      "             'constructed a high-dimensional feature space of perceptual '\n",
      "             'experiences using skip-gram, a state-of-the-art distributed word '\n",
      "             'embedding model. We built a decoder that associates brain '\n",
      "             'activity with perceptual experiences via the distributed word '\n",
      "             'representation. The decoder successfully estimated perceptual '\n",
      "             'contents consistent with the scene descriptions by multiple '\n",
      "             'annotators. Our results illustrate three advantages of our '\n",
      "             'decoding framework: (1) three types of perceptual contents could '\n",
      "             'be decoded in the form of nouns (objects), verbs (actions), and '\n",
      "             'adjectives (impressions) contained in 10,000 vocabulary words; '\n",
      "             '(2) despite using such a large vocabulary, we could decode novel '\n",
      "             'words that were absent in the datasets to train the decoder; and '\n",
      "             '(3) the inter-individual variability of the decoded contents '\n",
      "             'co-varied with that of the contents of scene de- scriptions. '\n",
      "             'These ﬁndings suggest that our decoding framework can recover '\n",
      "             'diverse aspects of perceptual expe- riences in naturalistic '\n",
      "             'situations and could be useful in various scientiﬁc and '\n",
      "             'practical applications.',\n",
      " 'keywords': ['decoding',\n",
      "              'semantic perception',\n",
      "              'natural language processing',\n",
      "              'humans',\n",
      "              'fmri',\n",
      "              'natural vision'],\n",
      " 'title': 'Decoding naturalistic experiences from human brain activity via '\n",
      "          'distributed representations of words'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917307474-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180312075024+05'30')\", '/Subject': '(NeuroImage, 169 \\\\(2018\\\\) 23-45. doi:10.1016/j.neuroimage.2017.09.009)', '/Author': '(Seyedeh-Rezvan Farahibozorg)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180312075137+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.09.009)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Adaptive cortical parcellations for source reconstructed EEG/MEG connectomes)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'There is growing interest in the rich temporal and spectral '\n",
      "             'properties of the functional connectome of the brain that are '\n",
      "             'provided by Electro- and Magnetoencephalography (EEG/MEG). '\n",
      "             'However, the problem of leakage be- tween brain sources that '\n",
      "             'arises when reconstructing brain activity from EEG/MEG '\n",
      "             'recordings outside the head makes it difﬁcult to distinguish '\n",
      "             'true connections from spurious connections, even when '\n",
      "             'connections are based on measures that ignore zero-lag '\n",
      "             'dependencies. In particular, standard anatomical parcellations '\n",
      "             'for potential cortical sources tend to over- or under-sample the '\n",
      "             'real spatial resolution of EEG/MEG. By using information from '\n",
      "             'cross- talk functions (CTFs) that objectively describe leakage '\n",
      "             'for a given sensor conﬁguration and distributed source '\n",
      "             'reconstruction method, we introduce methods for optimising the '\n",
      "             'number of parcels while simultaneously mini- mising the leakage '\n",
      "             'between them. More speciﬁcally, we compare two image '\n",
      "             'segmentation algorithms: 1) a split- and-merge (SaM) algorithm '\n",
      "             'based on standard anatomical parcellations and 2) a region '\n",
      "             'growing (RG) algorithm based on all the brain vertices with no '\n",
      "             'prior parcellation. Interestingly, when applied to minimum-norm '\n",
      "             're- constructions for EEG/MEG conﬁgurations from real data, both '\n",
      "             'algorithms yielded approximately 70 parcels despite their '\n",
      "             'different starting points, suggesting that this reﬂects the '\n",
      "             'resolution limit of this particular sensor conﬁguration and '\n",
      "             'reconstruction method. Importantly, when compared against '\n",
      "             'standard anatomical parcella- tions, resolution matrices of '\n",
      "             'adaptive parcellations showed notably higher sensitivity and '\n",
      "             'distinguishability of parcels. Furthermore, extensive '\n",
      "             'simulations of realistic networks revealed signiﬁcant '\n",
      "             'improvements in network reconstruction accuracies, particularly '\n",
      "             'in reducing false leakage-induced connections. Adaptive '\n",
      "             'parcellations therefore allow a more accurate reconstruction of '\n",
      "             'functional EEG/MEG connectomes.',\n",
      " 'keywords': ['adaptive parcellation',\n",
      "              'functional connectome',\n",
      "              'meg/eeg',\n",
      "              'cross-talk functions',\n",
      "              'source reconstruction',\n",
      "              'whole-brain connectivity'],\n",
      " 'title': 'Adaptive cortical parcellations for source reconstructed EEG/MEG '\n",
      "          'connectomes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917307942-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180830235317+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 31-40. doi:10.1016/j.neuroimage.2017.09.046)', '/Author': '(Anke Marit Albers)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180830235351+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.09.046)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Decoupling of BOLD amplitude and pattern classification of orientation-selective activity in human visual cortex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) of fMRI data has allowed '\n",
      "             'the investigation of neural representations of stimuli on the '\n",
      "             'basis of distributed patterns of activity within a brain region, '\n",
      "             'independently from overall brain activity. For instance, several '\n",
      "             'studies on early visual cortex have reported reliable MVPA '\n",
      "             'decoding of the identity of a stimulus representation that was '\n",
      "             'kept in working memory or internally generated, despite the fact '\n",
      "             'that the overall BOLD response was low or even at baseline '\n",
      "             'levels. Here we ask how it is possible that reliable stimulus '\n",
      "             'information can be decoded from early visual cortex even when '\n",
      "             'the overall BOLD signal remains low. We reanalyzed a data set in '\n",
      "             'which human participants (N ¼ 24) imagined or kept in working '\n",
      "             'memory an oriented visual grating. We divided voxels from V1, '\n",
      "             'V2, and V3 into groups based on orientation preference, and '\n",
      "             'compared the time course of mean BOLD responses to preferred and '\n",
      "             'non-preferred orientations with the time course of the '\n",
      "             'multivariate decoding performance. Decoding accuracy related to '\n",
      "             'a numerically small, but reliable univariate difference in the '\n",
      "             'mean BOLD response to preferred and non-preferred stimuli. The '\n",
      "             'time course of the difference in BOLD responses to preferred and '\n",
      "             'non- preferred orientations was highly similar to the time '\n",
      "             'course of the multivariate pattern classiﬁcation accuracy. The '\n",
      "             'reliability of the classiﬁcation strongly correlated with the '\n",
      "             'magnitude of differences in BOLD signal between preferred and '\n",
      "             'non-preferred stimuli. These activity differences were small '\n",
      "             'compared to the large overall BOLD modulations. This suggests '\n",
      "             'that a substantial part of the task-related BOLD response to '\n",
      "             'visual stimulation might not be stimulus-speciﬁc. Rather, '\n",
      "             'stimulus-evoked BOLD signals in early visual cortex during a '\n",
      "             'task context may be an amalgam of small stimulus-speciﬁc '\n",
      "             'responses and large task-related but non-stimulus-speciﬁc '\n",
      "             'responses. The latter are not evident during the maintenance or '\n",
      "             'internal generation of stimulus representations, but provide an '\n",
      "             'explanation of how reliable stimulus information can be decoded '\n",
      "             'from early visual cortex even though its overall BOLD signal '\n",
      "             'remains low.',\n",
      " 'keywords': ['bold activity',\n",
      "              'mvpa decoding',\n",
      "              'early visual cortex',\n",
      "              'orientation speciﬁcity'],\n",
      " 'title': 'Decoupling of BOLD amplitude and pattern classification of '\n",
      "          'orientation-selective activity in human visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917311023-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180831001238+05'30')\", '/Subject': '(NeuroImage, 180 \\\\(2018\\\\) 117-118. doi:10.1016/j.neuroimage.2017.12.078)', '/Author': '(Brandon M. Turner)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180831001303+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.12.078)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Outlook on deep neural networks in computational cognitive neuroscience)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Outlook on deep neural networks in computational cognitive '\n",
      "          'neuroscience'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918300442-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180509001955+05'30')\", '/Subject': '(NeuroImage, 174 \\\\(2018\\\\) 352-363. doi:10.1016/j.neuroimage.2018.01.044)', '/Author': '(Forooz Shahbazi Avarvand)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180509002039+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.01.044)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Localizing bicoherence from EEG and MEG)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'We propose a new method for the localization of nonlinear '\n",
      "             'cross-frequency coupling in EEG and MEG data analysis, based on '\n",
      "             'the estimation of bicoherences at the source level. While for '\n",
      "             'the analysis of rhythmic brain activity, source directions are '\n",
      "             'commonly chosen to maximize power, we suggest to maximize '\n",
      "             'bicoherence instead. The resulting nonlinear cost function can '\n",
      "             'be minimized effectively using a gradient approach. We argue, '\n",
      "             'that bicoherence is also a generally useful tool to analyze '\n",
      "             'phase-amplitude coupling (PAC), by deriving formal relations '\n",
      "             'between PAC and bispectra. This is illustrated in simulated and '\n",
      "             'empirical LFP data. The localization method is applied to EEG '\n",
      "             'resting state data, where the most prominent bicoherence '\n",
      "             'signatures originate from the occipital alpha rhythm and the mu '\n",
      "             'rhythm. While the latter is hardly visible using power analysis, '\n",
      "             'we observe clear bicoherence peaks in the high alpha range of '\n",
      "             'sensorymotor areas. We additionally apply our method to '\n",
      "             'resting-state data of subjects with schizophrenia and healthy '\n",
      "             'controls and observe signiﬁcant bicoherence differences in motor '\n",
      "             'areas which could not be found from analyzing power differences.',\n",
      " 'keywords': [],\n",
      " 'title': 'Localizing bicoherence from EEG and MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918300624-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180414182122+05'30')\", '/Subject': '(NeuroImage, 172 \\\\(2018\\\\) 228-238. doi:10.1016/j.neuroimage.2018.01.062)', '/Author': '(Jane E. Herron)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180414182206+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.01.062)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Direct electrophysiological evidence for the maintenance of retrieval orientations and the role of cognitive control)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Retrieval orientations are memory states that bias retrieval '\n",
      "             'towards speciﬁc memory contents. Many neuro- imaging studies '\n",
      "             'have examined the inﬂuence of retrieval orientations on stimulus '\n",
      "             'processing, but very little direct evidence exists regarding the '\n",
      "             'ongoing maintenance of orientations themselves. Participants '\n",
      "             'completed two memory tasks with different retrieval goals. ERPs '\n",
      "             'were time-locked to a pre-stimulus ﬁxation asterisk and con- '\n",
      "             'trasted according to retrieval goals. Pre-stimulus ERPs elicited '\n",
      "             'during the two retrieval tasks diverged at frontal electrode '\n",
      "             'sites. These differences onset early and were sustained '\n",
      "             'throughout the ﬁxation-stimulus interval. The functional and '\n",
      "             'spatiotemporal characteristics of this ERP effect comprise the '\n",
      "             'ﬁrst direct electrophysiological evidence of the ongoing '\n",
      "             'maintenance of retrieval orientations throughout a task. '\n",
      "             'Moreover, this effect was eliminated in participants who '\n",
      "             'performed a stroop task prior to the memory tests, indicating '\n",
      "             'that reserves of cognitive control play an important role in the '\n",
      "             'maintenance of retrieval orientations throughout memory tasks.',\n",
      " 'keywords': ['retrieval orientation',\n",
      "              'episodic memory',\n",
      "              'cognitive control',\n",
      "              'post-retrieval processing',\n",
      "              'event-related potential',\n",
      "              'electrophysiology'],\n",
      " 'title': 'Direct electrophysiological evidence for the maintenance of '\n",
      "          'retrieval orientations and the role of cognitive control'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918301411-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180415144156+05'30')\", '/Subject': '(NeuroImage, 173 \\\\(2018\\\\) 434-447. doi:10.1016/j.neuroimage.2018.02.044)', '/Author': '(Matthias Guggenmos)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180415144235+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.02.044)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Multivariate pattern analysis for MEG: A comparison of dissimilarity measures)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) methods such as decoding '\n",
      "             'and representational similarity analysis (RSA) are growing '\n",
      "             'rapidly in popularity for the analysis of magnetoencephalography '\n",
      "             '(MEG) data. However, little is known about the relative '\n",
      "             'performance and characteristics of the speciﬁc dissimilarity '\n",
      "             'measures used to describe differ- ences between evoked '\n",
      "             'activation patterns. Here we used a multisession MEG data set to '\n",
      "             'qualitatively characterize a range of dissimilarity measures and '\n",
      "             'to quantitatively compare them with respect to decoding accuracy '\n",
      "             '(for decoding) and between-session reliability of '\n",
      "             'representational dissimilarity matrices (for RSA). We tested '\n",
      "             'dissimilarity measures from a range of classiﬁers (Linear '\n",
      "             'Discriminant Analysis – LDA, Support Vector Machine – SVM, '\n",
      "             'Weighted Robust Distance – WeiRD, Gaussian Naïve Bayes – GNB) '\n",
      "             'and distances (Euclidean distance, Pearson correlation). In '\n",
      "             'addition, we evaluated three key processing choices: 1) '\n",
      "             'preprocessing (noise normal- isation, removal of the pattern '\n",
      "             'mean), 2) weighting decoding accuracies by decision values, and '\n",
      "             '3) computing distances in three different partitioning schemes '\n",
      "             '(non-cross-validated, cross-validated, within-class-corrected). '\n",
      "             'Four main conclusions emerged from our results. First, '\n",
      "             'appropriate multivariate noise normalization substantially '\n",
      "             'improved decoding accuracies and the reliability of '\n",
      "             'dissimilarity measures. Second, LDA, SVM and WeiRD yielded high '\n",
      "             'peak decoding accuracies and nearly identical time courses. '\n",
      "             'Third, while using decoding accuracies for RSA was markedly less '\n",
      "             'reliable than continuous distances, this disadvantage was '\n",
      "             'ameliorated by decision-value- weighting of decoding accuracies. '\n",
      "             'Fourth, the cross-validated Euclidean distance provided unbiased '\n",
      "             'distance estimates and highly replicable representational '\n",
      "             'dissimilarity matrices. Overall, we strongly advise the use of '\n",
      "             'multivariate noise normalisation as a general preprocessing '\n",
      "             'step, recommend LDA, SVM and WeiRD as classiﬁers for decoding '\n",
      "             'and highlight the cross-validated Euclidean distance as a '\n",
      "             'reliable and unbiased default choice for RSA.',\n",
      " 'keywords': ['meg',\n",
      "              'eeg',\n",
      "              'multi-voxel pattern analysis',\n",
      "              'decoding',\n",
      "              'representational similarity analysis',\n",
      "              'cross-validation',\n",
      "              'noise normalisation',\n",
      "              'machine learning'],\n",
      " 'title': 'Multivariate pattern analysis for MEG: A comparison of '\n",
      "          'dissimilarity measures'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918301423-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180415140538+05'30')\", '/Subject': '(NeuroImage, 173 \\\\(2018\\\\) 361-369. doi:10.1016/j.neuroimage.2018.02.045)', '/Author': '(Kaisu Lankinen)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180415140617+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.02.045)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Consistency and similarity of MEG- and fMRI-signal time courses during movie viewing)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Movie viewing allows human perception and cognition to be '\n",
      "             'studied in complex, real-life-like situations in a brain-imaging '\n",
      "             'laboratory. Previous studies with functional magnetic resonance '\n",
      "             'imaging (fMRI) and with magneto- and electroencephalography (MEG '\n",
      "             'and EEG) have demonstrated consistent temporal dynamics of brain '\n",
      "             'activity across movie viewers. However, little is known about '\n",
      "             'the similarities and differences of fMRI and MEG or EEG dynamics '\n",
      "             'during such naturalistic situations. We thus compared MEG and '\n",
      "             'fMRI responses to the same 15-min black-and-white movie in the '\n",
      "             'same eight subjects who watched the movie twice during both MEG '\n",
      "             'and fMRI recordings. We analyzed intra- and intersubject '\n",
      "             'voxel-wise correlations within each imaging modality as well as '\n",
      "             'the correlation of the MEG envelopes and fMRI signals. The fMRI '\n",
      "             'signals showed voxel-wise within- and between-subjects '\n",
      "             'correlations up to r ¼ 0.66 and r ¼ 0.37, respectively, whereas '\n",
      "             'these correlations were clearly weaker for the envelopes of '\n",
      "             'band-pass ﬁltered (7 frequency bands below 100 Hz) MEG signals '\n",
      "             '(within-subjects correlation r < 0.14 and between-subjects r < '\n",
      "             '0.05). Direct MEG–fMRI voxel-wise correlations were unreliable. '\n",
      "             'Notably, applying a spatial-ﬁltering approach to the MEG data '\n",
      "             'uncovered consistent canonical variates that showed considerably '\n",
      "             'stronger (up to r ¼ 0.25) between- subjects correlations than '\n",
      "             'the univariate voxel-wise analysis. Furthermore, the envelopes '\n",
      "             'of the time courses of these variates up to about 10 Hz showed '\n",
      "             'association with fMRI signals in a general linear model. '\n",
      "             'Similarities between envelopes of MEG canonical variates and '\n",
      "             'fMRI voxel time-courses were seen mostly in occipital, but also '\n",
      "             'in temporal and frontal brain regions, whereas intra- and '\n",
      "             'intersubject correlations for MEG and fMRI separately were '\n",
      "             'strongest only in the occipital areas. In contrast to the '\n",
      "             'conventional univariate analysis, the spatial-ﬁltering approach '\n",
      "             'was able to uncover associ- ations between the MEG envelopes and '\n",
      "             'fMRI time courses, shedding light on the similarities of '\n",
      "             'hemodynamic and electromagnetic brain activities during movie '\n",
      "             'viewing.',\n",
      " 'keywords': ['magnetoencephalography',\n",
      "              'functional magnetic resonance imaging',\n",
      "              'naturalistic stimulation',\n",
      "              'movie',\n",
      "              'intersubject correlation',\n",
      "              'canonical correlation analysis'],\n",
      " 'title': 'Consistency and similarity of MEG- and fMRI-signal time courses '\n",
      "          'during movie viewing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918304440-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180710232203+05'30')\", '/Subject': '(NeuroImage, 178 \\\\(2018\\\\) 172-182. doi:10.1016/j.neuroimage.2018.05.037)', '/Author': '(B.B. Bankson)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180710232245+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.05.037)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(The temporal evolution of conceptual object representations revealed through models of behavior, semantics and deep neural networks)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual object representations are commonly thought to emerge '\n",
      "             'rapidly, yet it has remained unclear to what extent early brain '\n",
      "             'responses reﬂect purely low-level visual features of these '\n",
      "             'objects and how strongly those features contribute to later '\n",
      "             'categorical or conceptual representations. Here, we aimed to '\n",
      "             'estimate a lower temporal bound for the emergence of conceptual '\n",
      "             'representations by deﬁning two criteria that characterize such '\n",
      "             'representations: 1) conceptual object representations should '\n",
      "             'generalize across different exemplars of the same object, and 2) '\n",
      "             'these representations should reﬂect high-level behavioral '\n",
      "             'judgments. To test these criteria, we compared '\n",
      "             'magnetoencephalography (MEG) recordings between two groups of '\n",
      "             'participants (n ¼ 16 per group) exposed to different exemplar '\n",
      "             'images of the same object concepts. Further, we disentangled '\n",
      "             'low-level from high-level MEG responses by estimating the unique '\n",
      "             'and shared contribution of models of behavioral judgments, '\n",
      "             'semantics, and different layers of deep neural networks of '\n",
      "             'visual object processing. We ﬁnd that 1) both generalization '\n",
      "             'across exemplars as well as generalization of object-related '\n",
      "             'signals across time increase after 150 ms, peaking around 230 '\n",
      "             'ms; 2) representations speciﬁc to behavioral judgments emerged '\n",
      "             'rapidly, peaking around 160 ms. Collectively, these results '\n",
      "             'suggest a lower bound for the emergence of conceptual object '\n",
      "             'representations around 150 ms following stimulus onset.',\n",
      " 'keywords': [],\n",
      " 'title': 'The temporal evolution of conceptual object representations '\n",
      "          'revealed through models of behavior, semantics and deep neural '\n",
      "          'networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305226-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180712012253+05'30')\", '/Subject': '(NeuroImage, 179 \\\\(2018\\\\) 51-62. doi:10.1016/j.neuroimage.2018.06.015)', '/Author': '(Christiane Ahlheim)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180712012333+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.06.015)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Estimating the functional dimensionality of neural representations)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Recent advances in multivariate fMRI analysis stress the '\n",
      "             'importance of information inherent to voxel patterns. Key to '\n",
      "             'interpreting these patterns is estimating the underlying '\n",
      "             'dimensionality of neural representations. Dimensions may '\n",
      "             'correspond to psychological dimensions, such as length and '\n",
      "             'orientation, or involve other coding schemes. Unfortunately, the '\n",
      "             'noise structure of fMRI data inﬂates dimensionality estimates '\n",
      "             'and thus makes it difﬁcult to assess the true underlying '\n",
      "             'dimensionality of a pattern. To address this challenge, we '\n",
      "             'developed a novel approach to identify brain regions that carry '\n",
      "             'reliable task-modulated signal and to derive an estimate of the '\n",
      "             \"signal's functional dimensionality. We combined singular value \"\n",
      "             'decomposition with cross-validation to ﬁnd the best low- '\n",
      "             'dimensional projection of a pattern of voxel-responses at a '\n",
      "             'single-subject level. Goodness of the low-dimensional '\n",
      "             'reconstruction is measured as Pearson correlation with a test '\n",
      "             'set, which allows to test for signiﬁcance of the low- '\n",
      "             'dimensional reconstruction across participants. Using '\n",
      "             'hierarchical Bayesian modeling, we derive the best estimate and '\n",
      "             'associated uncertainty of underlying dimensionality across '\n",
      "             'participants. We validated our method on simu- lated data of '\n",
      "             'varying underlying dimensionality, showing that recovered '\n",
      "             'dimensionalities match closely true dimensionalities. We then '\n",
      "             'applied our method to three published fMRI data sets all '\n",
      "             'involving processing of visual stimuli. The results highlight '\n",
      "             'three possible applications of estimating the functional '\n",
      "             'dimensionality of neural data. Firstly, it can aid evaluation of '\n",
      "             'model-based analyses by revealing which areas express reliable, '\n",
      "             'task- modulated signal that could be missed by speciﬁc models. '\n",
      "             'Secondly, it can reveal functional differences across brain '\n",
      "             'regions. Thirdly, knowing the functional dimensionality allows '\n",
      "             'assessing task-related differences in the complexity of neural '\n",
      "             'patterns.',\n",
      " 'keywords': ['neural representations',\n",
      "              'dimensionality reduction',\n",
      "              'multivariate analysis'],\n",
      " 'title': 'Estimating the functional dimensionality of neural representations'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305408-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180711220916+05'30')\", '/Subject': '(NeuroImage, 179 \\\\(2018\\\\) 102-116. doi:10.1016/j.neuroimage.2018.06.033)', '/Author': '(Diana C. Dima)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180711221026+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.06.033)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Spatial frequency supports the emergence of categorical representations in visual cortex during natural scene perception)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In navigating our environment, we rapidly process and extract '\n",
      "             'meaning from visual cues. However, the rela- tionship between '\n",
      "             'visual features and categorical representations in natural scene '\n",
      "             'perception is still not well un- derstood. Here, we used natural '\n",
      "             'scene stimuli from different categories and ﬁltered at different '\n",
      "             'spatial frequencies to address this question in a passive '\n",
      "             'viewing paradigm. Using representational similarity analysis '\n",
      "             '(RSA) and cross- decoding of magnetoencephalography (MEG) data, '\n",
      "             'we show that categorical representations emerge in human visual '\n",
      "             'cortex at ~180 ms and are linked to spatial frequency '\n",
      "             'processing. Furthermore, dorsal and ventral stream areas reveal '\n",
      "             'temporally and spatially overlapping representations of low and '\n",
      "             'high-level layer activations extracted from a feedforward neural '\n",
      "             'network. Our results suggest that neural patterns from '\n",
      "             'extrastriate visual cortex switch from low-level to categorical '\n",
      "             'representations within 200 ms, highlighting the rapid cascade of '\n",
      "             'processing stages essential in human visual perception.',\n",
      " 'keywords': ['multivariate pattern analysis (mvpa)',\n",
      "              'representational similarity analysis (rsa)',\n",
      "              'magnetoencephalography (meg)',\n",
      "              'convolutional neural network (cnn)',\n",
      "              'scene categorization'],\n",
      " 'title': 'Spatial frequency supports the emergence of categorical '\n",
      "          'representations in visual cortex during natural scene perception'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305718-main.pdf\n",
      "{'/CreationDate': \"(D:20180702132100+05'30')\", '/Subject': '(NeuroImage, Corrected proof. doi:10.1016/j.neuroimage.2018.06.064)', '/Author': '(Chris I. Baker)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/robots': '(noindex)', '/ModDate': \"(D:20180702132124+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.06.064)', '/Title': '(New advances in encoding and decoding of brain signals)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'New advances in encoding and decoding of brain signals'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S105381191830627X-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180910235500+05'30')\", '/Subject': '(NeuroImage, 181 \\\\(2018\\\\) 263-278. doi:10.1016/j.neuroimage.2018.07.015)', '/Author': '(Ixavier A. Higgins)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180910235547+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.07.015)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Integrative Bayesian analysis of brain functional networks incorporating anatomical knowledge)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Unknown operator: '\\x00'\n",
      "WARNING:root:Unknown operator: '\\x00'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Recently, there has been increased interest in fusing multimodal '\n",
      "             'imaging to better understand brain organization by integrating '\n",
      "             'information on both brain structure and function. In particular, '\n",
      "             'incorporating anatomical knowl- edge leads to desirable outcomes '\n",
      "             'such as increased accuracy in brain network estimates and '\n",
      "             'greater reproduc- ibility of topological features across '\n",
      "             'scanning sessions. Despite the clear advantages, major '\n",
      "             'challenges persist in integrative analyses including an '\n",
      "             'incomplete understanding of the structure-function relationship '\n",
      "             'and inaccura- cies in mapping anatomical structures due to '\n",
      "             'inherent deﬁciencies in existing imaging technology. This calls '\n",
      "             'for the development of advanced network modeling tools that '\n",
      "             'appropriately incorporate anatomical structure in constructing '\n",
      "             'brain functional networks. We propose a hierarchical Bayesian '\n",
      "             'Gaussian graphical modeling approach which models the brain '\n",
      "             'functional networks via sparse precision matrices whose degree '\n",
      "             'of edge speciﬁc shrinkage is a random variable that is modeled '\n",
      "             'using both anatomical structure and an independent baseline '\n",
      "             'component. The proposed approach adaptively shrinks functional '\n",
      "             'connections and ﬂexibly identiﬁes functional connections '\n",
      "             'supported by structural connectivity knowledge. This enables '\n",
      "             'robust brain network estimation even in the presence of '\n",
      "             'misspeciﬁed anatomical knowledge, while accommodating '\n",
      "             'heterogeneity in the structure- function relationship. We '\n",
      "             'implement the approach via an efﬁcient optimization algorithm '\n",
      "             'which yields maximum a posteriori estimates. Extensive numerical '\n",
      "             'studies involving multiple functional network structures reveal '\n",
      "             'the clear advantages of the proposed approach over competing '\n",
      "             'methods in accurately estimating brain functional connectivity, '\n",
      "             'even when the anatomical knowledge is misspeciﬁed up to a '\n",
      "             'certain degree. An appli- cation of the approach to data from '\n",
      "             'the Philadelphia Neurodevelopmental Cohort (PNC) study reveals '\n",
      "             'gender based connectivity differences across multiple age '\n",
      "             'groups, and higher reproducibility in the estimation of network '\n",
      "             'metrics compared to alternative methods.',\n",
      " 'keywords': ['adaptive shrinkage',\n",
      "              'brain networks',\n",
      "              'gaussian graphical models',\n",
      "              'multimodal imaging',\n",
      "              'philadelphia neurodevelopmental cohort',\n",
      "              'reproducibility'],\n",
      " 'title': 'Integrative Bayesian analysis of brain functional networks '\n",
      "          'incorporating anatomical knowledge'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918306712-main.pdf\n",
      "{'/CreationDate': '(D:20180727084234Z)', '/Subject': '(NeuroImage, Accepted manuscript. doi:10.1016/j.neuroimage.2018.07.056)', '/Author': '(Chang Cai)', '/Creator': '(Elsevier)', '/Producer': '(itext-paulo-155 \\\\(itextpdf.sf.net-lowagie.com\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20180727142203+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.07.056)', '/Title': '(Hierarchical multiscale Bayesian algorithm for robust MEG/EEG source reconstruction)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In this paper, we present a novel hierarchical multiscale '\n",
      "             'Bayesian algorithm for electromagnetic brain imaging using '\n",
      "             'magnetoencephalography (MEG) and electroencephalography (EEG). '\n",
      "             'In particular, we present a solution to the source '\n",
      "             'reconstruction problem for sources that vary in spatial extent. '\n",
      "             'We deﬁne sensor data measurements using a generative '\n",
      "             'probabilistic graphical model that is hier- archical across '\n",
      "             'spatial scales of brain regions and voxels. We then derive a '\n",
      "             'novel Bayesian algorithm for probabilistic inference with this '\n",
      "             'graphical model. This algorithm enables robust reconstruction of '\n",
      "             'sources that have diﬀerent spatial extent, from spatially '\n",
      "             'contiguous clusters of dipoles to isolated dipolar sources. We '\n",
      "             'test new algorithms with several representative benchmarks on '\n",
      "             'both simu- lated and real brain activities. The source locations '\n",
      "             'and the correct estimation of source time courses used for the '\n",
      "             'simulated data are chosen to test the per- formance on '\n",
      "             'challenging source conﬁgurations. In simulations, performance of '\n",
      "             'the novel algorithm shows superiority to several existing '\n",
      "             'benchmark algorithms. We also demonstrate that the new algorithm '\n",
      "             'is more robust to correlated brain activity present in real MEG '\n",
      "             'and EEG data and is able to resolve distinct and functionally '\n",
      "             'relevant brain areas with real MEG and EEG datasets.',\n",
      " 'keywords': ['brain mapping',\n",
      "              'magnetoencephalography',\n",
      "              'electroencephalography',\n",
      "              'bayesian.'],\n",
      " 'title': 'Hierarchical multiscale Bayesian algorithm for robust MEG/EEG '\n",
      "          'source reconstruction'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918320615-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': '(28th January 2019)', '/Subject': '(NeuroImage, 186 \\\\(2019\\\\) 369-381. doi:10.1016/j.neuroimage.2018.10.080)', '/Author': '(Giancarlo Valente)', '/CreationDate--Text': '(28th January 2019)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20190128123750+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.10.080)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Optimizing fMRI experimental design for MVPA-based BCI control: Combining the strengths of block and event-related designs)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Functional Magnetic Resonance Imaging (fMRI) has been '\n",
      "             'successfully used for Brain Computer Interfacing (BCI) to '\n",
      "             'classify (imagined) movements of different limbs. However, '\n",
      "             'reliable classiﬁcation of more subtle signals originating from '\n",
      "             'co-localized neural networks in the sensorimotor cortex, e.g. '\n",
      "             'individual movements of ﬁngers of the same hand, has proved to '\n",
      "             'be more challenging, especially when taking into account the '\n",
      "             'requirement for high single trial reliability in the BCI '\n",
      "             'context. In recent years, Multi Voxel Pattern Analysis (MVPA) '\n",
      "             'has gained momentum as a suitable method to disclose such weak, '\n",
      "             'distributed activation patterns. Much attention has been devoted '\n",
      "             'to developing and validating data analysis strategies, but '\n",
      "             'relatively little guidance is available on the choice of '\n",
      "             'experimental design, even less so in the context of BCI-MVPA. '\n",
      "             'When applicable, block designs are considered the safest choice, '\n",
      "             'but the expectations, strategies and adaptation induced by '\n",
      "             'blocking of similar trials can make it a sub-optimal strategy. '\n",
      "             'Fast event-related designs, in contrast, require a more '\n",
      "             'complicated analysis and show stronger dependence on linearity '\n",
      "             'assumptions but allow for randomly alternating trials. However, '\n",
      "             'they lack resting intervals that enable the BCI participant to '\n",
      "             'process feedback. In this proof-of-concept paper a hybrid '\n",
      "             'blocked fast-event related design is introduced that is novel in '\n",
      "             'the context of MVPA and BCI experiments, and that might overcome '\n",
      "             'these issues by combining the rest periods of the block design '\n",
      "             'with the shorter and randomly alternating trial characteristics '\n",
      "             'of a rapid event-related design. A well-established button-press '\n",
      "             'experiment was used to perform a within-subject comparison of '\n",
      "             'the proposed design with a block and a slow event-related '\n",
      "             'design. The proposed hybrid blocked fast-event related design '\n",
      "             'showed a decoding accuracy that was close to that of the block '\n",
      "             'design, which showed highest accuracy. It allowed for '\n",
      "             'across-design decoding, i.e. reliable prediction of examples '\n",
      "             'obtained with another design. Finally, it also showed the most '\n",
      "             'stable incremental decoding results, obtaining good performance '\n",
      "             'with relatively few blocks. Our ﬁndings suggest that the blocked '\n",
      "             'fast event-related design could be a viable alternative to block '\n",
      "             'designs in the context of BCI-MVPA, when expectations, '\n",
      "             'strategies and adaptation make blocking of trials of the same '\n",
      "             'type a sub-optimal strategy. Additionally, the blocked fast '\n",
      "             'event-related design is also suitable for applications in which '\n",
      "             'fast incremental decoding is desired, and enables the use of a '\n",
      "             'slow or block design during the test phase.',\n",
      " 'keywords': [],\n",
      " 'title': 'Optimizing fMRI experimental design for MVPA-based BCI control: '\n",
      "          'Combining the strengths of block and event-related designs'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918321207-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20190112044846+05'30')\", '/Subject': '(NeuroImage, 186 \\\\(2019\\\\) 570-576. doi:10.1016/j.neuroimage.2018.11.039)', '/Author': '(Marc N. Coutanche)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20190112044922+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.11.039)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Neural activity in human visual cortex is transformed by learning real world size)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The way that our brain processes visual information is directly '\n",
      "             'affected by our experience. Repeated exposure to a visual '\n",
      "             'stimulus triggers experience-dependent plasticity in the visual '\n",
      "             'cortex of many species. Humans also have the unique ability to '\n",
      "             'acquire visual knowledge through instruction. We introduced '\n",
      "             'human participants to the real- world size of previously '\n",
      "             'unfamiliar species, and to the functional motion of novel tools, '\n",
      "             'during a functional magnetic resonance imaging scan. Using '\n",
      "             'machine learning, we compared activity patterns evoked by images '\n",
      "             'of the new items, before and after participants learned the '\n",
      "             \"animals' real-world size or tools' motion. We found that, after \"\n",
      "             \"acquiring size information, participants' visual activity \"\n",
      "             'patterns for the new animals became more confusable with '\n",
      "             'activity patterns evoked by similar-sized known animals in early '\n",
      "             'visual cortex, but not in ventral temporal cortex, reﬂecting an '\n",
      "             'inﬂuence of new size knowledge on posterior, but not anterior, '\n",
      "             'components of the ventral stream. In contrast, learning the '\n",
      "             'functional motion of new tools did not lead to an equivalent '\n",
      "             'change in recorded activity. Finally, the time-points marked by '\n",
      "             'evidence of new size information in early visual cortex were '\n",
      "             'more likely to show size information and greater activation in '\n",
      "             'the right angular gyrus, a key hub of semantic knowledge and '\n",
      "             'spatial cognition. Overall, these ﬁndings suggest that learning '\n",
      "             \"an item's real-world size by instruction in- ﬂuences subsequent \"\n",
      "             'activity in visual cortex and in a region that is central to '\n",
      "             'semantic and spatial brain systems.',\n",
      " 'keywords': ['size', 'learning', 'vision', 'concepts', 'animacy', 'memory'],\n",
      " 'title': 'Neural activity in human visual cortex is transformed by learning '\n",
      "          'real world size'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919301211-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20190321215032+05'30')\", '/Subject': '(NeuroImage, 191 \\\\(2019\\\\) 225-233. doi:10.1016/j.neuroimage.2019.02.027)', '/Author': '(Yasuki Noguchi)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20190321215125+05'30')\", '/doi': '(10.1016/j.neuroimage.2019.02.027)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Desynchronizing to be faster? Perceptual- and attentional-modulation of brain rhythms at the sub-millisecond scale)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Neural oscillatory signals has been associated with many '\n",
      "             'high-level functions (e.g. attention and working memory), '\n",
      "             'because they reﬂect correlated behaviors of neural population '\n",
      "             'that would facilitate the information transfer in the brain. On '\n",
      "             'the other hand, a decreased power of oscillation (event-related '\n",
      "             'desynchronization, ERD) has been associated with an irregular '\n",
      "             'state in which many neurons behave in an uncorrelated manner. In '\n",
      "             'contrast to this view, here we show that the human ERD is linked '\n",
      "             'to the increased regularity of oscillatory signals. Using '\n",
      "             'magnetoencephalography, we found that presenting a visual '\n",
      "             'stimulus not only induced a decrease in power of alpha (8–12 Hz) '\n",
      "             'to beta (13–30 Hz) rhythms in the contralateral visual cortex '\n",
      "             'but also reduced the mean and variance of their inter-peak '\n",
      "             'intervals (IPIs). This indicates that the suppressed alpha/beta '\n",
      "             'rhythms became faster (reduced mean) and more regular (reduced '\n",
      "             'variance) during visual stimulation. The same changes in IPIs, '\n",
      "             'especially those of beta rhythm, were observed when subjects '\n",
      "             'allocated their attention to a contralateral visual ﬁeld. Those '\n",
      "             'results revealed a new role of the event-related decrease in '\n",
      "             'alpha/beta power and further suggested that our brain regulates '\n",
      "             'and accelerates a clock for neural computations by actively '\n",
      "             'suppressing the oscillation amplitude in task-relevant regions.',\n",
      " 'keywords': ['event-related desynchronization (erd)',\n",
      "              'neural periodicity',\n",
      "              'posner spatial cuing task',\n",
      "              'inhibitory control',\n",
      "              'alpha blocking'],\n",
      " 'title': 'Desynchronizing to be faster? Perceptual- and '\n",
      "          'attentional-modulation of brain rhythms at the sub-millisecond '\n",
      "          'scale'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919301454-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20190321231109+05'30')\", '/Subject': '(NeuroImage, 191 \\\\(2019\\\\) 503-517. doi:10.1016/j.neuroimage.2019.02.049)', '/Author': '(Greta Vilidaite)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20190321231306+05'30')\", '/doi': '(10.1016/j.neuroimage.2019.02.049)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Internal noise in contrast discrimination propagates forwards from early visual cortex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Human contrast discrimination performance is limited by '\n",
      "             'transduction nonlinearities and variability of the neural '\n",
      "             'representation (noise). Whereas the nonlinearities have been '\n",
      "             'well-characterised, there is less agreement about the speciﬁcs '\n",
      "             'of internal noise. Psychophysical models assume that it impacts '\n",
      "             'late in sensory processing, whereas neuroimaging and '\n",
      "             'intracranial electrophysiology studies suggest that the noise is '\n",
      "             'much earlier. We investigated whether perceptually-relevant '\n",
      "             'internal noise arises in early visual areas or later decision '\n",
      "             'making areas. We recorded EEG and MEG during a '\n",
      "             'two-interval-forced-choice contrast discrimination task and used '\n",
      "             'multivariate pattern analysis to decode target/non-target and '\n",
      "             'selected/non-selected intervals from evoked responses. We found '\n",
      "             'that perceptual decisions could be decoded from both EEG and MEG '\n",
      "             'signals, even when the stimuli in both intervals were physically '\n",
      "             'identical. Above-chance decision classiﬁcation started <100 ms '\n",
      "             'after stimulus onset, suggesting that neural noise affects '\n",
      "             'sensory signals early in the visual pathway. Classiﬁcation '\n",
      "             'accuracy increased over time, peaking at >500 ms. Applying '\n",
      "             'multivariate analysis to separate anatomically-deﬁned brain '\n",
      "             'regions in MEG source space, we found that occipital regions '\n",
      "             'were informative early on but then information spreads for- '\n",
      "             'wards across parietal and frontal regions. This is consistent '\n",
      "             'with neural noise affecting sensory processing at multiple '\n",
      "             'stages of perceptual decision making. We suggest how early '\n",
      "             \"sensory noise might be resolved with Birdsall's linearisation, \"\n",
      "             'in which a dominant noise source obscures subsequent '\n",
      "             'nonlinearities, to allow the visual system to preserve the wide '\n",
      "             'dynamic range of early areas whilst still beneﬁtting from '\n",
      "             'contrast-invariance at later stages. A preprint of this work is '\n",
      "             'available at: https://doi.org/10.1101/364612.',\n",
      " 'keywords': ['contrast discrimination',\n",
      "              'eeg',\n",
      "              'meg',\n",
      "              'source space',\n",
      "              'pattern classiﬁcation',\n",
      "              'internal noise'],\n",
      " 'title': 'Internal noise in contrast discrimination propagates forwards from '\n",
      "          'early visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919302058-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20190321164212+05'30')\", '/Subject': '(NeuroImage, 193 \\\\(2019\\\\) 167-177. doi:10.1016/j.neuroimage.2019.03.028)', '/Author': '(Daria Proklova)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20190321164307+05'30')\", '/doi': '(10.1016/j.neuroimage.2019.03.028)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(MEG sensor patterns reflect perceptual but not categorical similarity of animate and inanimate objects)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Human high-level visual cortex shows a distinction between '\n",
      "             'animate and inanimate objects, as revealed by fMRI. Recent '\n",
      "             'studies have shown that object animacy can similarly be decoded '\n",
      "             'from MEG sensor patterns. Which object properties drive this '\n",
      "             'decoding? Here, we disentangled the inﬂuence of perceptual and '\n",
      "             'categorical object properties by presenting perceptually matched '\n",
      "             'objects (e.g., snake and rope) that were nonetheless easily '\n",
      "             'recognizable as being animate or inanimate. In a series of '\n",
      "             'behavioral experiments, three aspects of perceptual '\n",
      "             'dissimilarity of these objects were quantiﬁed: overall '\n",
      "             'dissimilarity, outline dissimilarity, and texture dissimilarity. '\n",
      "             'Neural dissimilarity of MEG sensor patterns was modeled using '\n",
      "             'regression analysis, in which perceptual dissimilarity (from the '\n",
      "             'behavioral experiments) and cate- gorical dissimilarity served '\n",
      "             'as predictors of neural dissimilarity. We found that perceptual '\n",
      "             'dissimilarity was strongly reﬂected in MEG sensor patterns from '\n",
      "             '80 ms after stimulus onset, with separable contributions of '\n",
      "             'outline and texture dissimilarity. Surprisingly, when '\n",
      "             'controlling for perceptual dissimilarity, MEG patterns did not '\n",
      "             'carry information about object category (animate vs inanimate) '\n",
      "             'at any time point. Nearly identical results were found in a '\n",
      "             'second MEG experiment that required basic-level object '\n",
      "             'recognition. This is in contrast to results observed in fMRI '\n",
      "             'using the same stimuli, task, and analysis approach: fMRI voxel '\n",
      "             'patterns in object-selective cortex showed a highly reliable '\n",
      "             'categorical distinction even when controlling for perceptual '\n",
      "             'dissimilarity. These results suggest that MEG sensor patterns do '\n",
      "             'not capture object animacy independently of perceptual '\n",
      "             'differences between animate and inanimate objects.',\n",
      " 'keywords': [],\n",
      " 'title': 'MEG sensor patterns reflect perceptual but not categorical '\n",
      "          'similarity of animate and inanimate objects'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919302691-main.pdf\n",
      "{'/CreationDate': '(D:20190402214652Z)', '/Subject': '(NeuroImage, Accepted manuscript. doi:10.1016/j.neuroimage.2019.03.069)', '/Author': '(Silvan C. Quax)', '/Creator': '(Elsevier)', '/Producer': '(itext-paulo-155 \\\\(itextpdf.sf.net-lowagie.com\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20190403031720+05'30')\", '/doi': '(10.1016/j.neuroimage.2019.03.069)', '/Title': '(Eye movements explain decodability during perception and cued attention in MEG)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Eye movements are an integral part of human perception, but can '\n",
      "             'induce artifacts in many magneto- encephalography (MEG) and '\n",
      "             'electroencephalography (EEG) studies. For this reason, '\n",
      "             'investigators try to minimize eye movements and remove these '\n",
      "             'artifacts from their data using diﬀerent techniques. When these '\n",
      "             'artifacts are not purely random, but consistent regarding '\n",
      "             'certain stimuli or conditions, the possibility arises that eye '\n",
      "             'movements are actually inducing eﬀects in the MEG signal. It '\n",
      "             'remains unclear how much of an inﬂuence eye movements can have '\n",
      "             'on observed eﬀects in MEG, since most MEG studies lack a control '\n",
      "             'analysis to verify whether an eﬀect found in the MEG signal is '\n",
      "             'induced by eye movements. Here, we ﬁnd that we can decode '\n",
      "             'stimulus location from eye movements in two diﬀerent stages of a '\n",
      "             'working memory match-to-sample task that encompass diﬀerent '\n",
      "             'areas of research typically done with MEG. This means that the '\n",
      "             'observed MEG eﬀect might be (partly) due to eye movements '\n",
      "             'instead of any true neural correlate. We suggest how to check '\n",
      "             'for eye movement eﬀects in the data and make suggestions on how '\n",
      "             'to minimize eye movement artifacts from occurring in the ﬁrst '\n",
      "             'place.',\n",
      " 'keywords': ['decoding', 'eye movements'],\n",
      " 'title': 'Eye movements explain decodability during perception and cued '\n",
      "          'attention in MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661317302000-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20171209222229+05'30')\", '/Subject': '(Trends in Cognitive Sciences, 22 \\\\(2018\\\\) 64-78. doi:10.1016/j.tics.2017.09.012)', '/Author': '(Saket Navlakha)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20171209222229+05'30')\", '/doi': '(10.1016/j.tics.2017.09.012)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': '(Network Design and the Brain)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': 'Network Design and the Brain'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661318300433-main.pdf\n",
      "{'/Author': '(Carlos Crivelli)', '/CreationDate': \"(D:20180404121312+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(behavioral ecology; facial displays; social influence; diversity; emotion)', '/ModDate': \"(D:20180410184532+05'30')\", '/Producer': '(Acrobat Distiller 9.0.0 \\\\(Windows\\\\))', '/Subject': '(Trends in Cognitive Sciences, 22 \\\\(2018\\\\) 365-367. doi:10.1016/j.tics.2018.02.008)', '/Title': '(Facial Displays Are Tools for Social Influence)', '/doi': '(10.1016/j.tics.2018.02.008)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Facial Displays Are Tools for Social Influence'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661318302821-main.pdf\n",
      "{'/Author': '(Philip R. Corlett)', '/CreationDate': \"(D:20190103143316+05'30')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20190112140646+05'30')\", '/Producer': '(iText 2.1.7 by 1T3XT)', '/Subject': '(Trends in Cognitive Sciences, 23 \\\\(2019\\\\) 114-127. doi:10.1016/j.tics.2018.12.001)', '/Title': '(Hallucinations and Strong Priors)', '/doi': '(10.1016/j.tics.2018.12.001)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': 'Hallucinations and Strong Priors'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1878929317300257-main.pdf\n",
      "{'/Author': '(Wei He)', '/CreationDate': '(D:20180508214835Z)', '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(MEG; Face recognition; Repetition; DCM; M250; M170)', '/ModDate': '(D:20180508214835Z)', '/Subject': '(Developmental Cognitive Neuroscience, 30 \\\\(2018\\\\) 13-22. doi:10.1016/j.dcn.2017.11.010)', '/Title': '(Development of face recognition_ Dynamic causal modelling of MEG data)', '/doi': '(10.1016/j.dcn.2017.11.010)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Electrophysiological studies of adults indicate that brain '\n",
      "             'activity is enhanced during viewing of repeated faces, at a '\n",
      "             'latency of about 250 ms after the onset of the face (M250/N250). '\n",
      "             'The present study aimed to determine if this eﬀect was also '\n",
      "             'present in preschool-aged children, whose brain activity was '\n",
      "             'measured in a custom-sized pe- diatric MEG system. The results '\n",
      "             'showed that, unlike adults, face repetition did not show any '\n",
      "             'signiﬁcant mod- ulation of M250 amplitude in children; however '\n",
      "             'children’s M250 latencies were signiﬁcantly faster for repeated '\n",
      "             'than non-repeated faces. Dynamic causal modelling (DCM) of the '\n",
      "             'M250 in both age groups tested the eﬀects of face repetition '\n",
      "             'within the core face network including the occipital face area '\n",
      "             '(OFA), the fusiform face area (FFA), and the superior temporal '\n",
      "             'sulcus (STS). DCM revealed that repetition of identical faces '\n",
      "             'altered both forward and backward connections in children and '\n",
      "             'adults; however the modulations involved inputs to both FFA and '\n",
      "             'OFA in adults but only to OFA in children. These ﬁndings suggest '\n",
      "             'that the amplitude-insensitivity of the immature M250 may be due '\n",
      "             'to a weaker connection between the FFA and lower visual areas.',\n",
      " 'keywords': ['meg', 'face recognition', 'repetition', 'dcm', 'm250', 'm170'],\n",
      " 'title': 'Development of face recognition_ Dynamic causal modelling of MEG '\n",
      "          'data'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1878929318301178-main.pdf\n",
      "{'/Author': '(Tamara Vanderwal)', '/CreationDate': '(D:20190311052554Z)', '/Creator': '(Elsevier)', '/ElsevierWebPDFSpecifications': '(6.5)', '/Keywords': '(Naturalistic viewing; Movies; Resting state; Intersubject correlations; Head motion; Children; )', '/ModDate': '(D:20190311052554Z)', '/Subject': '(Developmental Cognitive Neuroscience, Corrected Proof, 100600. doi:10.1016/j.dcn.2018.10.004)', '/Title': '(Movies in the magnet_ Naturalistic paradigms in developmental functional neuroimaging)', '/doi': '(10.1016/j.dcn.2018.10.004)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The use of movie-watching as an acquisition state for functional '\n",
      "             'connectivity (FC) MRI has recently enabled multiple groups to '\n",
      "             'obtain rich data sets in younger children with both substantial '\n",
      "             'sample sizes and scan dura- tions. Using naturalistic paradigms '\n",
      "             'such as movies has also provided analytic flexibility for these '\n",
      "             'developmental studies that extends beyond conventional resting '\n",
      "             'state approaches. This review highlights the advantages and '\n",
      "             'challenges of using movies for developmental neuroimaging and '\n",
      "             'explores some of the methodological issues involved in designing '\n",
      "             'pediatric studies with movies. Emerging themes from '\n",
      "             'movie-watching studies are dis- cussed, including an emphasis on '\n",
      "             'intersubject correlations, developmental changes in network '\n",
      "             'interactions under complex naturalistic conditions, and dynamic '\n",
      "             'age-related changes in both sensory and higher-order network FC '\n",
      "             'even in narrow age ranges. Converging evidence suggests an '\n",
      "             'enhanced ability to identify brain- behavior correlations in '\n",
      "             'children when using movie-watching data relative to both resting '\n",
      "             'state and conven- tional tasks. Future directions and cautionary '\n",
      "             'notes highlight the potential and the limitations of using '\n",
      "             'movies to study FC in pediatric populations.',\n",
      " 'keywords': ['naturalistic viewing',\n",
      "              'movies',\n",
      "              'resting state',\n",
      "              'intersubject correlations',\n",
      "              'head motion',\n",
      "              'children'],\n",
      " 'title': 'Movies in the magnet_ Naturalistic paradigms in developmental '\n",
      "          'functional neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S2352340917302056-main.pdf\n",
      "{'/CrossMarkDomains[2]': '(sciencedirect.com)', '/CreationDate': \"(D:20170603114655+05'30')\", '/CrossmarkMajorVersionDate': '(2010-04-23)', '/Subject': '(Data in Brief, 13 \\\\(2017\\\\) 219-222. doi:10.1016/j.dib.2017.05.014)', '/Author': '(Ayan Sengupta)', '/Creator': '(Elsevier)', '/Keywords': '()', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20170603114655+05'30')\", '/doi': '(10.1016/j.dib.2017.05.014)', '/CrossMarkDomains[1]': '(elsevier.com)', '/Title': '(Ultra high-field \\\\(7T\\\\) multi-resolution fMRI data for orientation decoding in visual cortex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern classiﬁcation methods have been '\n",
      "             'successfully applied to decode orientation of visual grating '\n",
      "             'stimuli from BOLD fMRI activity recorded in human visual cortex '\n",
      "             '(Kamitani and Tong, 2005; Haynes and Rees, 2005) [12,10]. Though '\n",
      "             'there has been extensive research investigating the true spatial '\n",
      "             'scale of the orientation speciﬁc signals (Op de Beeck, 2010; '\n",
      "             'Swisher et al., 2010; Alink et al., 2013; Freeman et al., 2011, '\n",
      "             '2013) [2,15,1,4,5], it remained inconclusive what spatial '\n",
      "             'acquisition resolution is required, or is optimal, for decoding '\n",
      "             'analyses. The research article entitled “The effect of '\n",
      "             'acquisition resolution on orientation decoding from V1 BOLD fMRI '\n",
      "             'at 7 T” Sengupta et al. (2017) [14] studied the effect of '\n",
      "             'spatial acquisition resolution and also ana- lyzed the strength '\n",
      "             'and spatial scale of orientation discriminating signals. In this '\n",
      "             'article, for the ﬁrst time, we present empirical ultra high-ﬁeld '\n",
      "             'fMRI data, obtained as a part of the aforementioned study, which '\n",
      "             'were recorded at four spatial resolutions (0.8 mm, 1.4 mm, 2 mm, '\n",
      "             'and 3 mm isotropic voxel size) for orientation',\n",
      " 'keywords': [],\n",
      " 'title': 'Ultra high-field \\\\(7T\\\\) multi-resolution fMRI data for '\n",
      "          'orientation decoding in visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10.1093@cercor@bhy123.pdf\n",
      "{'/Title': '(oup_cercor_bhy123 1..19 ++)', '/Creator': '(Arbortext Advanced Print Publisher 10.0.1465/W Unicode)', '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\); modified using iTextSharp 4.1.6 by 1T3XT)', '/CreationDate': \"(D:20180604185931+05'30')\", '/ModDate': \"(D:20180608220929+00'00')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10792166.pdf\n",
      "{'/Author': '(amiley@purdue.edu)', '/CreationDate': '(D:20180417183123Z)', '/Creator': '(Microsoft Word)', '/ModDate': \"(D:20180605095800-04'00')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10827_2010_Article_262.pdf\n",
      "{'/CreationDate': \"(D:20110202075523+08'00')\", '/Subject': '()', '/Author': '()', '/Creator': '(Springer)', '/Keywords': '()', '/Producer': '(Acrobat Distiller 7.0 \\\\(Windows\\\\))', '/ModDate': \"(D:20110204075600+08'00')\", '/Title': '()', '/rgid': '(PB:45641250_AS:99358636773384@1400700353429)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1311.full.pdf\n",
      "{'/CreationDate': '(D:20061116182357Z)', '/Creator': '(3B2 Total Publishing System 8.07e/W Unicode )', '/ModDate': \"(D:20190124004702-08'00')\", '/Producer': '(Acrobat Distiller 5.0 \\\\(Windows\\\\))', '/Title': '(1304 1311..1314)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1411.6422.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20141125020020Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': '(D:20141125020020Z)', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.1415926-2.3-1.40.12 \\\\(TeX Live 2011\\\\) kpathsea version 6.0.1)', '/Producer': '(pdfTeX-1.40.12)', '/Subject': '()', '/Title': '()', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1510.06479v2.pdf\n",
      "{'/Title': (3129, 0), '/Author': (3131, 0), '/Producer': (3130, 0), '/Creator': (3132, 0), '/CreationDate': (3133, 0), '/ModDate': (3133, 0)}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1612.03590.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20180713085110Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': '(D:20180713085110Z)', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.1415926-2.3-1.40.12 \\\\(TeX Live 2011\\\\) kpathsea version 6.0.1)', '/Producer': '(pdfTeX-1.40.12)', '/Subject': '()', '/Title': '()', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1706.01757.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20170919013621Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': '(D:20170919013621Z)', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.14159265-2.6-1.40.17 \\\\(TeX Live 2016\\\\) kpathsea version 6.2.2)', '/Producer': '(pdfTeX-1.40.17)', '/Subject': '()', '/Title': '()', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1803Nature_Image reconstruction by domain-transform manifold learning.pdf\n",
      "{'/Author': '(Bo Zhu)', '/CreationDate': \"(D:20180314153229+05'30')\", '/Creator': '(Adobe InDesign CS6 \\\\(Windows\\\\))', '/ModDate': \"(D:20180704144705+08'00')\", '/Producer': '(Adobe PDF Library 10.0.1)', '/Subject': '(Nature 555, 487 \\\\(2018\\\\). doi:10.1038/nature25988)', '/Title': '(Image reconstruction by domain-transform manifold learning)'}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1812.00725v1.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20181204021329Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': '(D:20181204021329Z)', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.14159265-2.6-1.40.17 \\\\(TeX Live 2016\\\\) kpathsea version 6.2.2)', '/Producer': '(pdfTeX-1.40.17)', '/Subject': '()', '/Title': '()', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1906.02691.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20190607004522Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': '(D:20190607004522Z)', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.14159265-2.6-1.40.17 \\\\(TeX Live 2016\\\\) kpathsea version 6.2.2)', '/Producer': '(pdfTeX-1.40.17)', '/Subject': '()', '/Title': '()', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\2012-Lizier-LocalInfoStorage.pdf\n",
      "{'/Author': '(Joseph T. Lizier, Mikhail Prokopenko, Albert Y. Zomaya)', '/Title': '(Local measures of information storage in complex distributed computation)', '/Subject': '(Version 2.2, svn 55)', '/Creator': '(LaTeX with hyperref package)', '/Producer': '(pdftex)', '/Keywords': '(information storage, intrinsic computation, complex systems, information theory, cellular automata, particles)', '/CreationDate': \"(D:20120312172015+01'00')\", '/ModDate': \"(D:20120312172015+01'00')\", '/Trapped': '/False', '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009/Debian) kpathsea version 5.0.0)'}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\2016-7.pdf\n",
      "{'/Author': '(Fang Wang)', '/CreationDate': \"(D:20151003201144+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.4)', '/Keywords': '(Event-related potentials;  Perceptual learning;  C1;  Higher-order cortical processing;  Primary visual cortex)', '/ModDate': \"(D:20151004054038+08'00')\", '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, Corrected proof. doi:10.1016/j.neuroimage.2015.09.024)', '/Title': '(Predicting perceptual learning from higher-order cortical processing)', '/doi': '(10.1016/j.neuroimage.2015.09.024)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unknown operator: 'qBX'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Editor: Cindy A. Lustig',\n",
      " 'keywords': ['event-related potentials',\n",
      "              'perceptual learning',\n",
      "              'c1',\n",
      "              'higher-order cortical processing',\n",
      "              'primary visual cortex'],\n",
      " 'title': 'Predicting perceptual learning from higher-order cortical '\n",
      "          'processing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\22547.pdf\n",
      "{'/CreationDate': '(D:19990714140130)', '/Producer': '(\\\\376\\\\377\\\\000A\\\\000c\\\\000r\\\\000o\\\\000b\\\\000a\\\\000t\\\\000 \\\\000D\\\\000i\\\\000s\\\\000t\\\\000\\\\\\ri\\\\000l\\\\000l\\\\000e\\\\000r\\\\000 \\\\0003\\\\000.\\\\0000\\\\0001\\\\000 \\\\000f\\\\000o\\\\000r\\\\000 \\\\000\\\\\\rW\\\\000i\\\\000n\\\\000d\\\\000o\\\\000w\\\\000s)', '/Author': '(Mark J Humphreys)', '/Creator': '(3B2 Total Publishing 6.03d/W)', '/Title': '(J400_22d 364..367)', '/ModDate': '(D:19990715114925)'}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unknown operator: 'H\\x89b``dd'\n",
      "WARNING:root:Unknown operator: '\\xa0'\n",
      "WARNING:root:Type mismatch: None != 'a'\n",
      "WARNING:root:Unknown operator: '\\x01'\n",
      "WARNING:root:Unknown operator: '\\x1e'\n",
      "WARNING:pdfminer.pdfinterp:Malformed inline image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\302034.full.pdf\n",
      "{'/Author': '(WIN 7)', '/CreationDate': \"(D:20180416120158+04'30')\", '/Creator': '(PScript5.dll Version 5.2.2)', '/ModDate': \"(D:20190213221719-08'00')\", '/Producer': '(Acrobat Distiller 11.0 \\\\(Windows\\\\))', '/Title': '(Beyond Core Object Recognition: Recurrent processes account for object recognition under occlusion)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\358036.full.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20180628094725Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': \"(D:20190219223210-08'00')\", '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.14159265-2.6-1.40.18 \\\\(TeX Live 2017\\\\) kpathsea version 6.2.3)', '/Producer': '(pdfTeX-1.40.18)', '/Subject': '()', '/Title': '(Modelling the brain response to arbitrary visual stimulation patterns for a flexible high-speed BCI)', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\4020.full.pdf\n",
      "{'/Creator': '(XPP)', '/Title': '(Visual Mismatch and Predictive Coding: A Computational Single-Trial ERP Study)', '/Author': '()', '/Producer': '(Adobe LiveCycle PDF Generator)', '/Keywords': '()', '/Subject': '()', '/ModDate': \"(D:20180410132856-04'00')\", '/CreationDate': \"(D:20180410131259Z00'00')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\407007.full.pdf\n",
      "{'/Author': '()', '/CreationDate': '(D:20180904154918Z)', '/Creator': '(LaTeX with hyperref package)', '/Keywords': '()', '/ModDate': \"(D:20190118013942-08'00')\", '/PTEX.Fullbanner': '(This is pdfTeX, Version 3.14159265-2.6-1.40.17 \\\\(TeX Live 2016/Debian\\\\) kpathsea version 6.2.2)', '/Producer': '(pdfTeX-1.40.17)', '/Subject': '()', '/Title': '(Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?)', '/Trapped': '/False'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\6069.full.pdf\n",
      "{'/Creator': '(XPP)', '/Title': '(Reconstructing Perceived and Retrieved Faces from Activity Patterns in Lateral Parietal Cortex)', '/Author': '()', '/Producer': '()', '/Keywords': '()', '/Subject': '()', '/ModDate': \"(D:20160524122916Z00'00')\", '/CreationDate': \"(D:20160524122916Z00'00')\"}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\6672-unsupervised-image-to-image-translation-networks.pdf\n",
      "{'/Subject': '(Neural Information Processing Systems http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057)', '/Publisher': '(Curran Associates\\\\054 Inc\\\\056)', '/Language': '(en\\\\055US)', '/Created': '(2017)', '/EventType': '(Poster)', '/Description-Abstract': '(Unsupervised image\\\\055to\\\\055image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains\\\\056 Since there exists an infinite set of joint distributions that can arrive the given marginal distributions\\\\054 one could infer nothing about the joint distribution from the marginal distributions without additional assumptions\\\\056 To address the problem\\\\054 we make a shared\\\\055latent space assumption and propose an unsupervised image\\\\055to\\\\055image translation framework based on Coupled GANs\\\\056 We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks\\\\054 including street scene image translation\\\\054 animal image translation\\\\054 and face image translation\\\\056 We also apply the proposed framework to domain adaptation and achieve state\\\\055of\\\\055the\\\\055art performance on benchmark datasets\\\\056 Code and additional results are available in https\\\\072\\\\057\\\\057github\\\\056com\\\\057mingyuliutw\\\\057unit\\\\056)', '/Producer': '(PyPDF2)', '/Title': '(Unsupervised Image\\\\055to\\\\055Image Translation Networks)', '/Date': '(2017)', '/ModDate': '(D\\\\07220171126011439\\\\05508\\\\04700\\\\047)', '/Published': '(2017)', '/Type': '(Conference Proceedings)', '/firstpage': '(700)', '/Book': '(Advances in Neural Information Processing Systems 30)', '/Description': '(Paper accepted and presented at the Neural Information Processing Systems Conference \\\\050http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057\\\\051)', '/Editors': '(I\\\\056 Guyon and U\\\\056V\\\\056 Luxburg and S\\\\056 Bengio and H\\\\056 Wallach and R\\\\056 Fergus and S\\\\056 Vishwanathan and R\\\\056 Garnett)', '/Author': '(Ming\\\\055Yu Liu\\\\054 Thomas Breuel\\\\054 Jan Kautz)', '/lastpage': '(708)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf\n",
      "{'/Subject': '(Neural Information Processing Systems http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057)', '/Publisher': '(Curran Associates\\\\054 Inc\\\\056)', '/Language': '(en\\\\055US)', '/Created': '(2017)', '/EventType': '(Poster)', '/Description-Abstract': '(Variational autoencoders \\\\050VAEs\\\\051 learn representations of data by jointly training a probabilistic encoder and decoder network\\\\056 Typically these models encode all features of the data into a single variable\\\\056 Here we are interested in learning disentangled representations that encode distinct aspects of the data into separate variables\\\\056 We propose to learn such representations using model architectures that generalise from standard VAEs\\\\054 employing a general graphical model structure in the encoder and decoder\\\\056 This allows us to train partially\\\\055specified models that make relatively strong assumptions about a subset of interpretable variables and rely on the flexibility of neural networks to learn representations for the remaining variables\\\\056 We further define a general objective for semi\\\\055supervised learning in this model class\\\\054 which can be approximated using an importance sampling procedure\\\\056 We evaluate our framework\\\\047s ability to learn disentangled representations\\\\054 both by qualitative exploration of its generative capacity\\\\054 and quantitative evaluation of its discriminative ability on a variety of models and datasets\\\\056)', '/Producer': '(PyPDF2)', '/Title': '(Learning Disentangled Representations with Semi\\\\055Supervised Deep Generative Models)', '/Date': '(2017)', '/ModDate': '(D\\\\07220171125203931\\\\05508\\\\04700\\\\047)', '/Published': '(2017)', '/Type': '(Conference Proceedings)', '/firstpage': '(5927)', '/Book': '(Advances in Neural Information Processing Systems 30)', '/Description': '(Paper accepted and presented at the Neural Information Processing Systems Conference \\\\050http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057\\\\051)', '/Editors': '(I\\\\056 Guyon and U\\\\056V\\\\056 Luxburg and S\\\\056 Bengio and H\\\\056 Wallach and R\\\\056 Fergus and S\\\\056 Vishwanathan and R\\\\056 Garnett)', '/Author': '(Siddharth Narayanaswamy\\\\054 T\\\\056 Brooks Paige\\\\054 Jan\\\\055Willem van de Meent\\\\054 Alban Desmaison\\\\054 Noah Goodman\\\\054 Pushmeet Kohli\\\\054 Frank Wood\\\\054 Philip Torr)', '/lastpage': '(5937)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\7775-task-driven-convolutional-recurrent-models-of-the-visual-system.pdf\n",
      "{'/Subject': '(Neural Information Processing Systems http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057)', '/Publisher': '(Curran Associates\\\\054 Inc\\\\056)', '/Language': '(en\\\\055US)', '/Created': '(2018)', '/EventType': '(Poster)', '/Description-Abstract': '(Feed\\\\055forward convolutional neural networks \\\\050CNNs\\\\051 are currently state\\\\055of\\\\055the\\\\055art for object classification tasks such as ImageNet\\\\056 Further\\\\054 they are quantitatively accurate models of temporally\\\\055averaged responses of neurons in the primate brain\\\\047s visual system\\\\056  However\\\\054 biological visual systems have two ubiquitous architectural features not shared with typical CNNs\\\\072 local recurrence within cortical areas\\\\054 and long\\\\055range feedback from downstream areas to upstream areas\\\\056  Here we explored the role of recurrence in improving classification performance\\\\056 We found that standard forms of recurrence \\\\050vanilla RNNs and LSTMs\\\\051 do not perform well within deep CNNs on the ImageNet task\\\\056 In contrast\\\\054 novel cells that incorporated two structural features\\\\054 bypassing and gating\\\\054 were able to boost task accuracy substantially\\\\056 We extended these design principles in an automated search over thousands of model architectures\\\\054 which identified novel local recurrent cells and long\\\\055range feedback connections useful for object recognition\\\\056 Moreover\\\\054 these task\\\\055optimized ConvRNNs matched the dynamics of neural activity in the primate visual system better than feedforward networks\\\\054 suggesting a role for the brain\\\\047s recurrent connections in performing difficult visual behaviors\\\\056)', '/Producer': '(PyPDF2)', '/Title': '(Task\\\\055Driven Convolutional Recurrent Models of the Visual System)', '/Date': '(2018)', '/ModDate': '(D\\\\07220181207063039\\\\05508\\\\04700\\\\047)', '/Published': '(2018)', '/Type': '(Conference Proceedings)', '/firstpage': '(5295)', '/Book': '(Advances in Neural Information Processing Systems 31)', '/Description': '(Paper accepted and presented at the Neural Information Processing Systems Conference \\\\050http\\\\072\\\\057\\\\057nips\\\\056cc\\\\057\\\\051)', '/Editors': '(S\\\\056 Bengio and H\\\\056 Wallach and H\\\\056 Larochelle and K\\\\056 Grauman and N\\\\056 Cesa\\\\055Bianchi and R\\\\056 Garnett)', '/Author': '(Aran Nayebi\\\\054 Daniel Bear\\\\054 Jonas Kubilius\\\\054 Kohitij Kar\\\\054 Surya Ganguli\\\\054 David Sussillo\\\\054 James J\\\\056 DiCarlo\\\\054 Daniel L\\\\056 Yamins)', '/lastpage': '(5306)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\8702.full.pdf\n",
      "{'/Subject': '()', '/Creator': '(XPP)', '/Title': '()', '/Producer': '()', '/ModDate': '(D:20100624154055Z)', '/CreationDate': '(D:20100624154055Z)', '/Keywords': '()', '/Author': '()'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A brain-based account of “basic-level” concepts.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20171115223859+05'30')\", '/Subject': '(NeuroImage, 161 \\\\(2017\\\\) 196-205. doi:10.1016/j.neuroimage.2017.08.049)', '/Author': '(Andrew James Bauer)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20171115223934+05'30')\", '/doi': '(10.1016/j.neuroimage.2017.08.049)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': \"(A brain-based account of ``basic-level'' concepts)\"}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'This study provides a brain-based account of how object concepts '\n",
      "             'at an intermediate (basic) level of speciﬁcity are represented, '\n",
      "             'offering an enriched view of what it means for a concept to be a '\n",
      "             'basic-level concept, a research topic pioneered by Rosch and '\n",
      "             'others (Rosch et al., 1976). Applying machine learning '\n",
      "             'techniques to fMRI data, it was possible to determine the '\n",
      "             'semantic content encoded in the neural representations of object '\n",
      "             'concepts at basic and subordinate levels of abstraction. The '\n",
      "             'representation of basic-level concepts (e.g. bird) was spatially '\n",
      "             'broad, encompassing sensorimotor brain areas that encode '\n",
      "             'concrete object properties, and also language and hetero- modal '\n",
      "             'integrative areas that encode abstract semantic content. The '\n",
      "             'representation of subordinate-level concepts (robin) was less '\n",
      "             'widely distributed, concentrated in perceptual areas that '\n",
      "             'underlie concrete content. Furthermore, basic-level concepts '\n",
      "             'were representative of their subordinates in that they were '\n",
      "             'neurally similar to their typical but not atypical subordinates '\n",
      "             '(bird was neurally similar to robin but not woodpecker). The '\n",
      "             'ﬁndings provide a brain- based account of the advantages that '\n",
      "             'basic-level concepts enjoy in everyday life over '\n",
      "             'subordinate-level concepts: the basic level is a broad '\n",
      "             'topographical representation that encompasses both concrete and '\n",
      "             'abstract semantic content, reﬂecting the multifaceted yet '\n",
      "             'intuitive meaning of basic-level concepts.',\n",
      " 'keywords': ['basic level',\n",
      "              'level of abstraction',\n",
      "              'neural representation',\n",
      "              'object concept',\n",
      "              'fmri',\n",
      "              'mvpa'],\n",
      " 'title': \"A brain-based account of ``basic-level'' concepts\"}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A Matran-Fernandez  IEEE TBME17.pdf\n",
      "{'/CreationDate': \"(D:20170304150608+05'30')\", '/Title': '(untitled)', '/ModDate': \"(D:20170317065310-04'00')\", '/Producer': '(Acrobat Distiller 10.1.10 \\\\(Windows\\\\))'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Objective. The N2pc event-related potential (ERP) appears on the '\n",
      "             'opposite side of the scalp with respect to the visual hemisphere '\n",
      "             'where an object of interest is located. We explored the '\n",
      "             'feasibility of using it to extract information on the spatial '\n",
      "             'location of targets in aerial images shown by means of a rapid '\n",
      "             'serial visual presentation (RSVP) protocol using single-trial '\n",
      "             'classi ﬁcation. Methods. Images were shown to 11 participants at '\n",
      "             'a presentation rate of 5 Hz while recording '\n",
      "             'electroencephalographic signals. With the resulting ERPs, we '\n",
      "             'trained linear classi ﬁers for single-trial detection of target '\n",
      "             'presence and location. We analyzed the classi ﬁers ’ decisions '\n",
      "             'and their raw output scores on independent test sets as well as '\n",
      "             'the averages and voltage distributions of the ERPs. Results. The '\n",
      "             'N2pc is elicited in RSVP presentation of complex images and can '\n",
      "             'be recognized in single trials (the median area under the '\n",
      "             'receiver operating characteristic curve was 0.76 for left versus '\n",
      "             'right classi ﬁcation). Moreover, the peak amplitude of this ERP '\n",
      "             'correlates with the horizontal position of the target within an '\n",
      "             'image. The N2pc varies signi ﬁcantly depending on handedness, '\n",
      "             'and these differences can be used for discriminating '\n",
      "             'participants in terms of their preferred hand. Conclusion and '\n",
      "             'Signi ﬁcance . The N2pc is elicited during RSVP presentation of '\n",
      "             'real complex images and contains analogue information that can '\n",
      "             'be used to roughly infer the horizontal position of targets. '\n",
      "             'Furthermore, differences in the N2pc due to handedness should be '\n",
      "             'taken into account when creating collaborative brain –computer '\n",
      "             'interfaces.',\n",
      " 'keywords': ['brain-computer interfaces (bcis)',\n",
      "              'handed-ness',\n",
      "              'n2pc',\n",
      "              'p300',\n",
      "              'rapid serial visual presentation (rsvp)'],\n",
      " 'title': '959'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A Matran-Fernandez  PONE17.pdf\n",
      "{'/Title': '(Towards the automated localisation of targets in rapid image-sifting by collaborative brain-computer interfaces)', '/EPS_processor': '(PStill version 1.76.22)', '/Creator': '(Arbortext Advanced Print Publisher 11.0.2857/W Unicode-x64)', '/CreationDate': \"(D:20170525195209+05'30')\", '/ModDate': \"(D:20170525195224+05'30')\", '/Producer': '(PDFlib+PDI 8.0.2p1 \\\\(C++/Win64\\\\); modified using iTextSharp\\x92 5.5.3 ©2000-2014 iText Group NV \\\\(AGPL-version\\\\))', '/Author': '(Ana Matran-Fernandez, Riccardo Poli)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A meta-analysis of fMRI decoding Quantifying influences on human visual population codes.pdf\n",
      "{'/CrossMarkDomains[2]': '(sciencedirect.com)', '/CreationDate': \"(D:20160202072944+05'30')\", '/CrossmarkMajorVersionDate': '(2010-04-23)', '/Subject': '(Neuropsychologia, 82 + \\\\(2016\\\\) 134-141. doi:10.1016/j.neuropsychologia.2016.01.018)', '/Author': '(Marc N. Coutanche)', '/Creator': '(Elsevier)', '/Keywords': '(Decoding; MVPA; Patterns; Meta-analysis; Vision; Objects)', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20160202072944+05'30')\", '/doi': '(10.1016/j.neuropsychologia.2016.01.018)', '/CrossMarkDomains[1]': '(elsevier.com)', '/Title': '(A meta-analysis of fMRI decoding_ Quantifying influences on human visual population codes)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Information in the human visual system is encoded in the '\n",
      "             'activity of distributed populations of neurons, which in turn is '\n",
      "             'reﬂected in functional magnetic resonance imaging (fMRI) data. '\n",
      "             'Over the last ﬁfteen years, activity patterns underlying a '\n",
      "             'variety of perceptual features and objects have been decoded '\n",
      "             'from the brains of participants in fMRI scans. Through a novel '\n",
      "             'multi-study meta-analysis, we have analyzed and modeled '\n",
      "             'relations between decoding strength in the visual ventral '\n",
      "             'stream, and stimulus and methodological variables that differ '\n",
      "             'across studies. We report ﬁndings that suggest: (i) several '\n",
      "             'organi- zational principles of the ventral stream, including a '\n",
      "             'gradient of pattern granulation and an increasing abstraction of '\n",
      "             'neural representations as one proceeds anteriorly; (ii) how '\n",
      "             'methodological choices affect decoding strength. The data also '\n",
      "             'show that studies with stronger decoding performance tend to be '\n",
      "             're- ported in higher-impact journals, by authors with a higher '\n",
      "             'h-index. As well as revealing principles of regional processing, '\n",
      "             'our results and approach can help investigators select from the '\n",
      "             'thousands of design and analysis options in an empirical manner, '\n",
      "             'to optimize future studies of fMRI decoding. & 2016 Elsevier '\n",
      "             'Ltd. All rights reserved.',\n",
      " 'keywords': ['decoding',\n",
      "              'mvpa',\n",
      "              'patterns',\n",
      "              'meta-analysis',\n",
      "              'vision',\n",
      "              'objects'],\n",
      " 'title': 'A meta-analysis of fMRI decoding_ Quantifying influences on human '\n",
      "          'visual population codes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A predictive coding account of bistable.pdf\n",
      "{'/Title': '(A predictive coding account of bistable perception - a model-based fMRI study)', '/EPS_processor': '(PStill version 1.76.22)', '/Creator': '(Arbortext Advanced Print Publisher 11.0.2857/W Unicode-x64)', '/CreationDate': \"(D:20170518095142+05'30')\", '/ModDate': \"(D:20170518095150+05'30')\", '/Producer': '(PDFlib+PDI 8.0.2p1 \\\\(C++/Win64\\\\); modified using iTextSharp\\x92 5.5.3 ©2000-2014 iText Group NV \\\\(AGPL-version\\\\))', '/Author': '(Veith Weilnhammer, Heiner Stuke, Guido Hesselmann, Philipp Sterzer, Katharina Schmack)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A R Marathe IEEE TNSRE14.pdf\n",
      "{'/CreationDate': \"(D:20140227095201-05'00')\", '/Title': '(untitled)', '/ModDate': \"(D:20140305063423-05')\", '/Producer': '(Acrobat Distiller 9.0.0 \\\\(Windows\\\\))'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': 'Patterns of neural data obtained from electroencephalography '\n",
      "             '(EEG) can be classiﬁed by machine learning techniques to '\n",
      "             'increase human-system performance. In controlled laboratory '\n",
      "             'settings this classiﬁcation approach works well; however, '\n",
      "             'transitioning these approaches into more dynamic, unconstrained '\n",
      "             'environments will present several signiﬁcant challenges. One '\n",
      "             'such challenge is an increase in temporal variability in '\n",
      "             'measured behavioral and neural responses, which often results in '\n",
      "             'suboptimal classiﬁcation performance. Previously, we reported a '\n",
      "             'novel classiﬁcation method designed to account for temporal '\n",
      "             'variability in the neural response in order to improve '\n",
      "             'classiﬁcation performance by using sliding windows in '\n",
      "             'hierarchical discriminant component analysis (HDCA), and '\n",
      "             'demonstrated a decrease in classiﬁcation error by over 50% when '\n",
      "             'compared to the standard HDCA method (Marathe et al., 2013). '\n",
      "             'Here, we expand upon this approach and show that embedded within '\n",
      "             'this new method is a novel signal transformation that, when '\n",
      "             'applied to EEG signals, signiﬁcantly improves the '\n",
      "             'signal-to-noise ratio and thereby enables more accurate '\n",
      "             'single-trial analysis. The results presented here have '\n",
      "             'signiﬁcant implications for both brain–computer interaction '\n",
      "             'technologies and basic science research into neural processes. '\n",
      "             'Index TermsBrain–computer interface (BCI), '\n",
      "             'electroencephalography (EEG), hierarchical discriminant '\n",
      "             'component analysis (HDCA) rapid serial visual presentation '\n",
      "             '(RSVP), real-world environment, single-trial, sliding HDCA, '\n",
      "             'temporal variability.',\n",
      " 'keywords': [],\n",
      " 'title': '201'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A R Marathe IEEE TNSRE16.pdf\n",
      "{'/CreationDate': \"(D:20160226181634-05'00')\", '/Title': '(untitled)', '/ModDate': \"(D:20160304062227-05'00')\", '/Producer': '(Acrobat Distiller 11.0 \\\\(Windows\\\\))'}\n",
      "[-- It is an ieee paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'The application space for brain–computer interface (BCI) '\n",
      "             'technologies is rapidly expanding with improvements in '\n",
      "             'technology. However, most real-time BCIs require extensive '\n",
      "             'individualized calibration prior to use, and systems often have '\n",
      "             'to be recalibrated to account for changes in the neural signals '\n",
      "             'due to a variety of factors including changes in human state, '\n",
      "             'the surrounding environment, and task conditions. Novel '\n",
      "             'approaches to reduce calibration time or effort will '\n",
      "             'dramatically improve the usability of BCI systems. Active '\n",
      "             'Learning (AL) is an iterative semi-supervised learning technique '\n",
      "             'for learning in situations in which data may be abundant, but '\n",
      "             'labels for the data are difﬁcult or expensive to obtain. In this '\n",
      "             'paper, we apply AL to a simulated BCI system for target '\n",
      "             'identiﬁcation using data from a rapid serial visual presentation '\n",
      "             '(RSVP) paradigm to minimize the amount of training samples '\n",
      "             'needed to initially calibrate a neural classiﬁer. Our results '\n",
      "             'show AL can produce similar overall classiﬁcation accuracy with '\n",
      "             'signiﬁcantly less labeled data (in some cases less than 20%) '\n",
      "             'when compared to alternative calibration approaches. In fact, AL '\n",
      "             'classiﬁcation performance matches performance of 10-fold '\n",
      "             'cross-validation (CV) in over 70% of subjects when training with '\n",
      "             'less than 50% of the data. To our knowledge, this is the ﬁrst '\n",
      "             'work to demonstrate the use of AL for ofﬂine '\n",
      "             'electroencephalography (EEG) calibration in a simulated BCI '\n",
      "             'paradigm. While AL itself is not often amenable for use in '\n",
      "             'real-time systems, this work opens the door to alternative '\n",
      "             'AL-like systems that are more amenable for BCI applications and '\n",
      "             'thus enables future efforts for developing highly adaptive BCI '\n",
      "             'systems. Index TermsActive learning, brain–computer interface, '\n",
      "             'electroencephalography, rapid-serial visual presentation.',\n",
      " 'keywords': [],\n",
      " 'title': '333'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Albers_NIMG2017.pdf\n",
      "{'/Author': '(Anke Marit Albers)', '/CreationDate': \"(D:20171003092724+05'30')\", '/Creator': '(Elsevier)', '/ElsevierWebPDFSpecifications': '(6.5)', '/ModDate': \"(D:20180125142556+01'00')\", '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, Corrected proof. doi:10.1016/j.neuroimage.2017.09.046)', '/Title': '(Decoupling of BOLD amplitude and pattern classification of orientation-selective activity in human visual cortex)', '/doi': '(10.1016/j.neuroimage.2017.09.046)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) of fMRI data has allowed '\n",
      "             'the investigation of neural representations of stimuli on the '\n",
      "             'basis of distributed patterns of activity within a brain region, '\n",
      "             'independently from overall brain activity. For instance, several '\n",
      "             'studies on early visual cortex have reported reliable MVPA '\n",
      "             'decoding of the identity of a stimulus representation that was '\n",
      "             'kept in working memory or internally generated, despite the fact '\n",
      "             'that the overall BOLD response was low or even at baseline '\n",
      "             'levels. Here we ask how it is possible that reliable stimulus '\n",
      "             'information can be decoded from early visual cortex even when '\n",
      "             'the overall BOLD signal remains low. We reanalyzed a data set in '\n",
      "             'which human participants (N ¼ 24) imagined or kept in working '\n",
      "             'memory an oriented visual grating. We divided voxels from V1, '\n",
      "             'V2, and V3 into groups based on orientation preference, and '\n",
      "             'compared the time course of mean BOLD responses to preferred and '\n",
      "             'non-preferred orientations with the time course of the '\n",
      "             'multivariate decoding performance. Decoding accuracy related to '\n",
      "             'a numerically small, but reliable univariate difference in the '\n",
      "             'mean BOLD response to preferred and non-preferred stimuli. The '\n",
      "             'time course of the difference in BOLD responses to preferred and '\n",
      "             'non- preferred orientations was highly similar to the time '\n",
      "             'course of the multivariate pattern classiﬁcation accuracy. The '\n",
      "             'reliability of the classiﬁcation strongly correlated with the '\n",
      "             'magnitude of differences in BOLD signal between preferred and '\n",
      "             'non-preferred stimuli. These activity differences were small '\n",
      "             'compared to the large overall BOLD modulations. This suggests '\n",
      "             'that a substantial part of the task-related BOLD response to '\n",
      "             'visual stimulation might not be stimulus-speciﬁc. Rather, '\n",
      "             'stimulus-evoked BOLD signals in early visual cortex during a '\n",
      "             'task context may be an amalgam of small stimulus-speciﬁc '\n",
      "             'responses and large task-related but non-stimulus-speciﬁc '\n",
      "             'responses. The latter are not evident during the maintenance or '\n",
      "             'internal generation of stimulus representations, but provide an '\n",
      "             'explanation of how reliable stimulus information can be decoded '\n",
      "             'from early visual cortex even though its overall BOLD signal '\n",
      "             'remains low.',\n",
      " 'keywords': ['bold activity',\n",
      "              'mvpa decoding',\n",
      "              'early visual cortex',\n",
      "              'orientation speciﬁcity'],\n",
      " 'title': 'Decoupling of BOLD amplitude and pattern classification of '\n",
      "          'orientation-selective activity in human visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Are you thinking what I'm thinking Synchronization of resting fMRI.pdf\n",
      "{'/CrossMarkDomains[2]': '(elsevier.com)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/CreationDate': \"(D:20180414181411+05'30')\", '/Subject': '(NeuroImage, 172 \\\\(2018\\\\) 740-752. doi:10.1016/j.neuroimage.2018.01.058)', '/Author': '(Anand A. Joshi)', '/Creator': '(Elsevier)', '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\))', '/ElsevierWebPDFSpecifications': '(6.5)', '/CrossmarkDomainExclusive': '(true)', '/robots': '(noindex)', '/ModDate': \"(D:20180414181500+05'30')\", '/doi': '(10.1016/j.neuroimage.2018.01.058)', '/CrossMarkDomains[1]': '(sciencedirect.com)', '/Title': \"(Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects)\"}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'We describe BrainSync, an orthogonal transform that allows '\n",
      "             'direct comparison of resting fMRI (rfMRI) time-series across '\n",
      "             'subjects. For this purpose, we exploit the geometry of the rfMRI '\n",
      "             'signal space to propose a novel orthogonal transformation that '\n",
      "             'synchronizes rfMRI time-series across sessions and subjects. '\n",
      "             'When synchronized, rfMRI signals become approximately equal at '\n",
      "             'homologous locations across subjects. The method is based on the '\n",
      "             'observation that rfMRI data exhibit similar con- nectivity '\n",
      "             'patterns across subjects, as reﬂected in the pairwise '\n",
      "             'correlations between different brain regions. We show that if '\n",
      "             'the data for two subjects have similar correlation patterns then '\n",
      "             'their time courses can be approximately synchronized by an '\n",
      "             'orthogonal transformation. This transform is unique, invertible, '\n",
      "             'efﬁcient to compute, and preserves the connectivity structure of '\n",
      "             'the original data for all subjects. Analogously to image '\n",
      "             'registration, where we spatially align structural brain images, '\n",
      "             'this temporal synchronization of brain signals across a '\n",
      "             'population, or within-subject across sessions, facilitates '\n",
      "             'cross-sectional and longitudinal studies of rfMRI data. The '\n",
      "             'utility of the BrainSync transform is illustrated through '\n",
      "             'demonstrative simulations and applications including '\n",
      "             'quantiﬁcation of rfMRI variability across subjects and sessions, '\n",
      "             'cortical functional parcellation across a population, timing '\n",
      "             'recovery in task fMRI data, comparison of task and resting state '\n",
      "             'data, and an application to complex naturalistic stimuli for '\n",
      "             'annotation prediction.',\n",
      " 'keywords': [],\n",
      " 'title': \"Are you thinking what I'm thinking? Synchronization of resting fMRI \"\n",
      "          'time-series across subjects'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Bayesian model reveals latent atrophy factors with dissociable cognitive trajectories in AD.pdf\n",
      "{'/CreationDate': \"(D:20161011173951+05'30')\", '/Creator': '(Arbortext Advanced Print Publisher 9.1.510/W Unicode)', '/CrossMarkDomains[1]': '(www.pnas.org)', '/CrossmarkDomainExclusive': '(false)', '/CrossmarkMajorVersionDate': '(2016-10-11)', '/ModDate': \"(D:20181213091441+08'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Bayesian model reveals latent atrophy factors with dissociable cognitive trajectories in Alzheimer\\x90s disease)', '/doi': '(10.1073/pnas.1611073113)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\brain.2011.0001.pdf\n",
      "{'/Keywords': '(artifact reduction,functional connectivity,independent component analysis \\\\(ICA\\\\),magnetoencephalography \\\\(MEG\\\\),resting-state network \\\\(RSN\\\\),signal processing,source localization)', '/Creator': '(Arbortext Advanced Print Publisher 9.0.114/W)', '/ModDate': \"(D:20180722193621-07'00')\", '/CreationDate': \"(D:20110531235541+05'30')\", '/Producer': '(Acrobat Distiller 8.1.0 \\\\(Windows\\\\); modified using iText 4.2.0 by 1T3XT)', '/Subject': '(Brain Connectivity 2011.1:49-59)', '/Title': '(A Signal-Processing Pipeline for Magnetoencephalography Resting-State Networks)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\BurianovaEtAl_2013_Final.pdf\n",
      "{'/CreationDate': \"(D:20130226224550+08'00')\", '/Creator': '(Elsevier)', '/ModDate': \"(D:20130226224556Z00'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Title': '(Multimodal functional imaging of motor imagery using a novel paradigm)', '/rgid': '(PB:234134009_AS:97618520707083@1400285477510)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Neuroimaging studies have shown that the neural mechanisms of '\n",
      "             'motor imagery (MI) overlap substantially with the mechanisms of '\n",
      "             'motor execution (ME). Surprisingly, however, the role of several '\n",
      "             'regions of the motor circuit- ry in MI remains controversial, a '\n",
      "             'variability that may be due to differences in neuroimaging '\n",
      "             'techniques, MI train- ing, instruction types, or tasks used to '\n",
      "             'evoke MI. The objectives of this study were twofold: (i) to '\n",
      "             'design a novel task that reliably invokes MI, provides a '\n",
      "             'reliable behavioral measure of MI performance, and is '\n",
      "             'transferable across imaging modalities; and (ii) to measure the '\n",
      "             'common and differential activations for MI and ME with '\n",
      "             'functional magnetic resonance imaging (fMRI) and '\n",
      "             'magnetoencephalography (MEG). We present a task in which it is '\n",
      "             'dif- ﬁcult to give accurate responses without the use of either '\n",
      "             'motor execution or motor imagery. The behavioral results '\n",
      "             'demonstrate that participants performed similarly on the task '\n",
      "             'when they imagined vs. executed move- ments and this performance '\n",
      "             'did not change over time. The fMRI results show a spatial '\n",
      "             'overlap of MI and ME in a number of motor and premotor areas, '\n",
      "             'sensory cortices, cerebellum, inferior frontal gyrus, and '\n",
      "             'ventrolateral thalamus. MI uniquely engaged bilateral occipital '\n",
      "             'areas, left parahippocampus, and other temporal and frontal '\n",
      "             'areas, whereas ME yielded unique activity in motor and sensory '\n",
      "             'areas, cerebellum, precuneus, and putamen. The MEG results show '\n",
      "             'a robust event-related beta band desynchronization in the '\n",
      "             'proximity of primary motor and premotor cortices during both ME '\n",
      "             'and MI. Together, these results further elucidate the neural '\n",
      "             'circuitry of MI and show that our task robustly and reliably '\n",
      "             'invokes motor imagery, and thus may prove useful for interro- '\n",
      "             'gating the functional status of the motor circuitry in patients '\n",
      "             'with motor disorders. © 2013 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['motor imagery', 'motor execution', 'fmri', 'meg'],\n",
      " 'title': 'Multimodal functional imaging of motor imagery using a novel '\n",
      "          'paradigm'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\C M Privitera J Vision10.pdf\n",
      "{'/ModDate': '(D:20180117011330)', '/Creator': '(Aspose Ltd.)', '/CreationDate': '(D:20100805203106Z)', '/Title': '(Pupil dilation during visual target detection)', '/dc:title': '(Pupil dilation during visual target detection)', '/Producer': '(Aspose.Pdf for .NET 8.3.0)'}\n",
      "[-- It is an ieee paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Can visual information encoded in cortical columns be decoded from MEG.pdf\n",
      "{'/Author': '(Radoslaw Martin Cichy)', '/CreationDate': \"(D:20151001161305+08'00')\", '/Creator': '(Elsevier)', '/CrossMarkDomains[1]': '(elsevier.com)', '/CrossMarkDomains[2]': '(sciencedirect.com)', '/CrossmarkDomainExclusive': '(true)', '/CrossmarkMajorVersionDate': '(2010-04-23)', '/ElsevierWebPDFSpecifications': '(6.4)', '/Keywords': '(Orientation encoding;  Magnetoencephalography;  Multivariate pattern analysis;  Cortical columns)', '/ModDate': \"(D:20151007063956+08'00')\", '/Producer': '(Acrobat Distiller 10.0.0 \\\\(Windows\\\\))', '/Subject': '(NeuroImage, 121 \\\\(2015\\\\) 193-204. doi:10.1016/j.neuroimage.2015.07.011)', '/Title': '(Can visual information encoded in cortical columns be decoded from magnetoencephalography data in humans?)', '/doi': '(10.1016/j.neuroimage.2015.07.011)', '/robots': '(noindex)'}\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-23a4be7c5026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-63b0be59c32e>\u001b[0m in \u001b[0;36mpdf_info\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'/Creator'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'(Elsevier)'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_elsevier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ieee\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-63b0be59c32e>\u001b[0m in \u001b[0;36m_elsevier\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_elsevier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[-- It is an elsevier paper. --]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_paper_elsevier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-62fd0b2a827f>\u001b[0m in \u001b[0;36mparse_paper_elsevier\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Get layout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mlayout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# For each box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfinterp.py\u001b[0m in \u001b[0;36mprocess_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[0mctm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_contents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mctm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfinterp.py\u001b[0m in \u001b[0;36mrender_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_resources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfinterp.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m    673\u001b[0m                         \u001b[1;31m# logger.debug('exec: %s %r', name, args)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m                             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m                         \u001b[1;31m# logger.debug('exec: %s', name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfinterp.py\u001b[0m in \u001b[0;36mdo_TJ\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mhandle_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPDFInterpreterError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No font specified!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m     \u001b[1;31m# show\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_Tj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfdevice.py\u001b[0m in \u001b[0;36mrender_string\u001b[1;34m(self, textstate, seq)\u001b[0m\n\u001b[0;32m     64\u001b[0m             textstate.linematrix = self.render_string_horizontal(\n\u001b[0;32m     65\u001b[0m                 \u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinematrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 scaling, charspace, wordspace, rise, dxscale)\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     def render_string_horizontal(self, seq, matrix, point, font, fontsize, scaling, charspace,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfdevice.py\u001b[0m in \u001b[0;36mrender_string_horizontal\u001b[1;34m(self, seq, matrix, point, font, fontsize, scaling, charspace, wordspace, rise, dxscale)\u001b[0m\n\u001b[0;32m     79\u001b[0m                         \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcharspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     x += self.render_char(translate_matrix(matrix, (x,y)),\n\u001b[1;32m---> 81\u001b[1;33m                                           font, fontsize, scaling, rise, cid)\n\u001b[0m\u001b[0;32m     82\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mwordspace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                         \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mwordspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\converter.py\u001b[0m in \u001b[0;36mrender_char\u001b[1;34m(self, matrix, font, fontsize, scaling, rise, cid)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mtextwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_width\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mtextdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_disp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLTChar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\layout.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, matrix, font, fontsize, scaling, rise, text, textwidth, textdisp)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscaling\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_matrix_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_matrix_pt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdfminer\\utils.py\u001b[0m in \u001b[0;36mapply_matrix_pt\u001b[1;34m(matrix, point)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_matrix_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pdf_path in all_pdfs('C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar'):\n",
    "    print('-'* 80)\n",
    "    print(pdf_path)\n",
    "    info = pdf_info(pdf_path)\n",
    "    if info:\n",
    "        pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
