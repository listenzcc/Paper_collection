{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from pdfrw import PdfReader\n",
    "from pdfminer.layout import LTTextBoxHorizontal, LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFTextExtractionNotAllowed\n",
    "from pdfminer.converter import PDFPageAggregator, TextConverter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from io import StringIO\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pdfs(src_path='examples'):\n",
    "    print('=' * 80)\n",
    "    print(src_path)\n",
    "    pdfs = [s for s in os.listdir(src_path) if s .endswith('.pdf')]\n",
    "    print(pdfs)\n",
    "    return [os.path.join(src_path, e) for e in pdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_info():\n",
    "    info = dict(\n",
    "        title = '',\n",
    "        keywords = [],\n",
    "        abstract = '',\n",
    "    )\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Visual Feature Extraction From Voxel-Weighted Averaging of Stimulus Images in 2 fMRI Studies',\n",
       " 'keywords': ['Bayesian estimation',\n",
       "  'component analysis',\n",
       "  'fMRI',\n",
       "  'generalized linear models',\n",
       "  'imaging',\n",
       "  'voxel'],\n",
       " 'abstract': 'Multiple studies have provided evidence for distributed object representation in the brain, with several recent experiments leveraging basis function estimates for partial image reconstruction from fMRI data. Using a novel combination of statistical decomposition, generalized linear models, and stimulus averaging on previously examined image sets and Bayesian regression of recorded fMRI activity during presentation of these data sets, we identify a subset of relevant voxels that appear to code for covarying object features. Using a technique we term “voxel-weighted averaging,” we isolate image ﬁlters that these voxels appear to implement. The results, though very cursory, appear to have signiﬁcant implications for hierarchical and deep-learningtype approaches toward the understanding of neural coding and representation.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = 'examples\\ieee_2.pdf'\n",
    "\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf'\n",
    "\n",
    "def parse_paper_ieee(pdf_path):\n",
    "\n",
    "    info = empty_info()\n",
    "\n",
    "    with open(pdf_path, 'rb') as fp:\n",
    "        # Prepare doc\n",
    "        praser = PDFParser(fp)\n",
    "        doc = PDFDocument()\n",
    "        praser.set_document(doc)\n",
    "        doc.set_parser(praser)\n",
    "        doc.initialize()\n",
    "        # Rude assertion\n",
    "        assert(doc.is_extractable)\n",
    "\n",
    "        # Prepare components\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "        # Read infos\n",
    "        # Only search on first page\n",
    "        page_limit = 1\n",
    "        is_title = False\n",
    "        for j, page in enumerate(doc.get_pages()):\n",
    "            # Break when page_limit is reached\n",
    "            if not(j < page_limit):\n",
    "                break\n",
    "            # Get layout\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            # For each box\n",
    "            for box in layout:\n",
    "                # If not LTTextBoxHorizontal, it should be passed\n",
    "                if not isinstance(box, LTTextBoxHorizontal):\n",
    "                    continue\n",
    "                # Get content\n",
    "                content = box.get_text()\n",
    "                # print('-' * 80)\n",
    "                # print(content)\n",
    "                if is_title:\n",
    "                    info['title'] = content.replace('\\n', ' ').strip()\n",
    "                    is_title = False\n",
    "                if content.startswith('IEEE'):\n",
    "                    is_title = True\n",
    "                    \n",
    "                # Remove short dash '—'\n",
    "                content = content.replace('—', '')\n",
    "                \n",
    "                # Record abstract\n",
    "                if content.startswith('Abstract'):\n",
    "                    content = content.replace('Abstract', '')\n",
    "                    info['abstract'] = content.replace('\\n', ' ').replace('- ', '').strip()\n",
    "                    \n",
    "                # Record keywords\n",
    "                content = content.replace('Index Terms', 'IndexTerms')\n",
    "                if content.startswith('IndexTerms'):\n",
    "                    keywords = content.replace('IndexTerms', '').replace('\\n', '').split(',')\n",
    "                    if keywords[-1].endswith('.'):\n",
    "                        keywords[-1] = keywords[-1][:-1]\n",
    "                    info['keywords'] = [e.strip() for e in keywords]\n",
    "    return info\n",
    "\n",
    "parse_paper_ieee(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A meta-analysis of fMRI decoding_ Quantifying influences on human visual population codes',\n",
       " 'keywords': ['Decoding',\n",
       "  'MVPA',\n",
       "  'Patterns',\n",
       "  'Meta-analysis',\n",
       "  'Vision',\n",
       "  'Objects'],\n",
       " 'abstract': 'Information in the human visual system is encoded in the activity of distributed populations of neurons, which in turn is reﬂected in functional magnetic resonance imaging (fMRI) data. Over the last ﬁfteen years, activity patterns underlying a variety of perceptual features and objects have been decoded from the brains of participants in fMRI scans. Through a novel multi-study meta-analysis, we have analyzed and modeled relations between decoding strength in the visual ventral stream, and stimulus and methodological variables that differ across studies. We report ﬁndings that suggest: (i) several organi- zational principles of the ventral stream, including a gradient of pattern granulation and an increasing abstraction of neural representations as one proceeds anteriorly; (ii) how methodological choices affect decoding strength. The data also show that studies with stronger decoding performance tend to be re- ported in higher-impact journals, by authors with a higher h-index. As well as revealing principles of regional processing, our results and approach can help investigators select from the thousands of design and analysis options in an empirical manner, to optimize future studies of fMRI decoding. & 2016 Elsevier Ltd. All rights reserved.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = 'examples\\elsevier_2.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S1053811916301914-main.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\10.1093@cercor@bhy123.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S0896627306005861-main.pdf'\n",
    "pdf_path = 'C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar\\\\1-s2.0-S0028393216300173-main.pdf'\n",
    "\n",
    "def parse_paper_elsevier(pdf_path):\n",
    "    info = empty_info()\n",
    "    info['title'] = PdfReader(pdf_path).Info['/Title'][1:-1]\n",
    "\n",
    "    with open(pdf_path, 'rb') as fp:\n",
    "        # Prepare doc\n",
    "        praser = PDFParser(fp)\n",
    "        doc = PDFDocument()\n",
    "        praser.set_document(doc)\n",
    "        doc.set_parser(praser)\n",
    "        doc.initialize()\n",
    "        # Rude assertion\n",
    "        assert(doc.is_extractable)\n",
    "\n",
    "        # Prepare components\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "        # Read infos\n",
    "        # Only search on first page\n",
    "        page_limit = 2\n",
    "        is_abstract = False\n",
    "        for j, page in enumerate(doc.get_pages()):\n",
    "            # Break when page_limit is reached\n",
    "            if not(j < page_limit):\n",
    "                break\n",
    "            # Get layout\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            # For each box\n",
    "            for box in layout:\n",
    "                # If not LTTextBoxHorizontal, it should be passed\n",
    "                if not isinstance(box, LTTextBoxHorizontal):\n",
    "                    continue\n",
    "                # Get content\n",
    "                content = box.get_text()\n",
    "                # print('-' * 80)\n",
    "                # print(content)\n",
    "                # Record abstract\n",
    "                if all([is_abstract,\n",
    "                        not content.startswith('Article history'),\n",
    "                        not content.startswith('Keywords'),\n",
    "                        not content.startswith('Introduction'),\n",
    "                        not content.startswith('1.')\n",
    "                       ]):\n",
    "                    info['abstract'] = ''.join(content).replace('\\n', ' ').strip()\n",
    "                    is_abstract = False\n",
    "                if any([content.lower().startswith('a b s t r a c t'),\n",
    "                        content.lower().startswith('abstract'),\n",
    "                        content.lower().startswith('summary')]):\n",
    "                    is_abstract = True\n",
    "                # Record keywords\n",
    "                if content.startswith('Keywords'):\n",
    "                    info['keywords'] = [e for e in content.split('\\n') if e][1:]\n",
    "                if content.startswith('Key words'):\n",
    "                    info['keywords'] = [e.strip() for e in content.replace(',', '\\n').split('\\n') if e][1:]\n",
    "\n",
    "    return info\n",
    "\n",
    "parse_paper_elsevier(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_info(pdf_path):\n",
    "    info = PdfReader(pdf_path).Info\n",
    "    if info['/Creator'] == '(Elsevier)':\n",
    "        return _elsevier(pdf_path)\n",
    "    return _ieee(pdf_path)\n",
    "    return None\n",
    "\n",
    "def _elsevier(pdf_path):\n",
    "    print('[-- It is an elsevier paper. --]')\n",
    "    info = parse_paper_elsevier(pdf_path)\n",
    "    return info\n",
    "\n",
    "def _ieee(pdf_path):\n",
    "    print('[-- It is an IEEE paper. --]')\n",
    "    info = parse_paper_ieee(pdf_path)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\n",
      "['! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf', '!10.1093@cercor@bhy123.pdf', '!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf', '!Integrating theoretical models with functional neuroimaging.pdf', '0102181v1.pdf', '07073970.pdf', '07264993.pdf', '07468569.pdf', '08025614.pdf', '08051252.pdf', '08269806.pdf', '08370896.pdf', '1-s2.0-S0010945217303258-main.pdf', '1-s2.0-S0028393217300593-main.pdf', '1-s2.0-S0042698909004751-main.pdf', '1-s2.0-S0893608016301800-main.pdf', '1-s2.0-S0896627306005861-main.pdf', '1-s2.0-S089662731830477X-main.pdf', '1-s2.0-S0925231215017634-main.pdf', '1-s2.0-S1053810015000355-main.pdf', '1-s2.0-S1053811907001073-main.pdf', '1-s2.0-S1053811911013012-main.pdf', '1-s2.0-S1053811912004429-main.pdf', '1-s2.0-S1053811913002851-main.pdf', '1-s2.0-S1053811914001220-main.pdf', '1-s2.0-S1053811914010325-main.pdf', '1-s2.0-S1053811915005315-main.pdf', '1-s2.0-S1053811915006205-main.pdf', '1-s2.0-S1053811916000124-main.pdf', '1-s2.0-S1053811916001269-main.pdf', '1-s2.0-S1053811916300076-main.pdf', '1-s2.0-S1053811916301914-main.pdf', '1-s2.0-S1053811916306802-main.pdf', '1-s2.0-S1053811917302458-main.pdf', '1-s2.0-S1053811917305906-main.pdf', '1-s2.0-S1053811917306523-main.pdf', '1-s2.0-S1053811917306638-main.pdf', '1-s2.0-S105381191730664X-main.pdf', '1-s2.0-S1053811917307474-main.pdf', '1-s2.0-S1053811917307942-main.pdf', '1-s2.0-S1053811917311023-main.pdf', '1-s2.0-S1053811918300442-main.pdf', '1-s2.0-S1053811918300624-main.pdf', '1-s2.0-S1053811918301411-main.pdf', '1-s2.0-S1053811918301423-main.pdf', '1-s2.0-S1053811918304440-main.pdf', '1-s2.0-S1053811918305226-main.pdf', '1-s2.0-S1053811918305408-main.pdf', '1-s2.0-S1053811918305718-main.pdf', '1-s2.0-S105381191830627X-main.pdf', '1-s2.0-S1053811918306712-main.pdf', '1-s2.0-S1053811918320615-main.pdf', '1-s2.0-S1053811918321207-main.pdf', '1-s2.0-S1053811919301211-main.pdf', '1-s2.0-S1053811919301454-main.pdf', '1-s2.0-S1053811919302058-main.pdf', '1-s2.0-S1053811919302691-main.pdf', '1-s2.0-S1364661317302000-main.pdf', '1-s2.0-S1364661318300433-main.pdf', '1-s2.0-S1364661318302821-main.pdf', '1-s2.0-S1878929317300257-main.pdf', '1-s2.0-S1878929318301178-main.pdf', '1-s2.0-S2352340917302056-main.pdf', '10.1093@cercor@bhy123.pdf', '10792166.pdf', '10827_2010_Article_262.pdf', '1311.full.pdf', '1411.6422.pdf', '1510.06479v2.pdf', '1612.03590.pdf', '1706.01757.pdf', '1803Nature_Image reconstruction by domain-transform manifold learning.pdf', '1812.00725v1.pdf', '1906.02691.pdf', '2012-Lizier-LocalInfoStorage.pdf', '2016-7.pdf', '22547.pdf', '302034.full.pdf', '358036.full.pdf', '4020.full.pdf', '407007.full.pdf', '6069.full.pdf', '6672-unsupervised-image-to-image-translation-networks.pdf', '7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf', '7775-task-driven-convolutional-recurrent-models-of-the-visual-system.pdf', '8702.full.pdf', 'A brain-based account of “basic-level” concepts.pdf', 'A Matran-Fernandez  IEEE TBME17.pdf', 'A Matran-Fernandez  PONE17.pdf', 'A meta-analysis of fMRI decoding Quantifying influences on human visual population codes.pdf', 'A predictive coding account of bistable.pdf', 'A R Marathe IEEE TNSRE14.pdf', 'A R Marathe IEEE TNSRE16.pdf', 'Albers_NIMG2017.pdf', \"Are you thinking what I'm thinking Synchronization of resting fMRI.pdf\", 'Bayesian model reveals latent atrophy factors with dissociable cognitive trajectories in AD.pdf', 'brain.2011.0001.pdf', 'BurianovaEtAl_2013_Final.pdf', 'C M Privitera J Vision10.pdf', 'Can visual information encoded in cortical columns be decoded from MEG.pdf', 'chanAH15ICIP15.pdf', 'Chang_Tsao_2017_The Code for Facial Identity in the Primate Brain.pdf', 'Chen_et_al-2018-Scientific_Reports.pdf', 'Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf', 'Cichy_2016.pdf', 'Congedo et al 2016.pdf', 'CSCTR_07sup_ManMonkeyIT.pdf', 'Cukur2013.pdf', 'D Won IEEE TNSRE18(1).pdf', 'D Won IEEE TNSRE18.pdf', 'DeanAAAI-05-ComputationalModel-CerebralCortex.pdf', 'Decoding Brain Representations by Multimodal Learning.pdf', 'Decoding naturalistic experiences from human brain activity via distributed representations of words.pdf', 'Dinh2015_Article_Real-TimeMEGSourceLocalization.pdf', 'disun_etd_2016.pdf', 'Domain-general and domain-specific neural changes underlying.pdf', 'Dynamics of scene representations in the human brain revealed by MEG.pdf', 'eaag2612.full.pdf', 'ECCV2018_CBAM_ Convolutional Block Attention Module.pdf', 'elife-25784.pdf', 'elife-32816-v2.pdf', 'emss-74424.pdf', 'Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf', 'fncom-12-00004.pdf', 'Forward modelling reveals dynamics of neural orientation.pdf', 'FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf', \"Functional brain connectivity is predictable from anatomic network's.pdf\", 'gk7591_Lotteretal_ICLR2017.pdf', 'H Cecotti IEEE TBME16(1).pdf', 'H Cecotti IEEE TBME16.pdf', 'H Cecotti IEEE TNNLS14.pdf', 'H Cecotti Int J Psychophysiol17.pdf', 'Hallucinations in Charles Bonnet Syndrome Induced.pdf', 'HsiehChia-ObjectDetectionWithPartialOcclusion.pdf', 'HybridVAE-Improving Deep Generative Models using Partial Observations.pdf', 'ICML18_JointGAN_ Multi-Domain Joint Distribution Learning with.pdf', 'Information Theoretic Evidence for Predictive Coding.pdf', 'Interactions Between Large-Scale Functional Brain Networks HMM.pdf', 'jin%2F2017%2F16-3%2Fjin-16-3-jin016%2Fjin-16-jin016.pdf', 'jn.00338.2011.pdf', 'journal.pone.0206107.pdf', 'kellman_yin_shipley_1998.pdf', 'KokDeLange_2015_Predictive_Coding_in_Sensory_Cortex.pdf', 'Koles1990_Article_SpatialPatternsUnderlyingPopul.pdf', 'kriegeskorte_RSA_frontiersSN20081.pdf', 'Large Scale Organization of Shape Processing in the ventral and dorsal pathways.pdf', 'Learning to Associate Orientation with Color in Early Visual Areas by Associative Decoded fMRI Neurofeedback.pdf', 'Le_Chang_VALSE_2018_faceRecognition.pdf', 'manual.pdf', 'Mapping between fMRI responses to movies and their natural language annotations.pdf', 'Mean first-passage time for maximal-entropy random walks in complex networks.pdf', 'Mechanisms of evoked and induced responses.pdf', 'mmc2.pdf', 'Modeling Task fMRI Data via Deep Convolutional Autoencoder.pdf', 'Multi-modal Latent Factor Exploration  in Typical Late-Onset Alzheimer’s Disease.pdf', 'Multi-subject hierarchical inverse covariance modelling improves estimation of functional brain networks.pdf', 'Multi-task connectivity reveals flexible hubs for Adptivie Control.pdf', 'Multivariate pattern analysis of MEG and EEG A comparison of.pdf', 'Multiview-3D-DPM.pdf', 'NeuroImage2017_FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf', 'NeuroImage2018_Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf', 'NeuroImage2018_Pattern component modeling_ A flexible approach for understanding the representational structure of brain activity patterns.pdf', 'nihms-536994.pdf', 'nihms-645980.pdf', 'nihms122940.pdf', 'nihms234413.pdf', 'nihms678626.pdf', 'nihms829712.pdf', 'NIPS2018_IntroVAE_ Introspective Variational Autoencoders for Photographic Image Synthesis.pdf', 'NIPS2018_Multimodal Generative Models for Scalable Weakly-Supervised Learning.pdf', 'nn0199_79.pdf', 'On_the_interpretation_of_weight_vectors_of_linear_.pdf', 'Optimal information networks Application for data-driven integrated health in populations.pdf', 'Optimizing deep video representation to match brain activity.pdf', 'Ou2015_Article_CharacterizingAndDifferentiati.pdf', 'R T Schirrmeister HBM17.pdf', 'Recognition of Occluded Objects.pdf', 'Representational similarity encoding for fMRI Pattern-based synthesis to.pdf', 'Rivet2009a.pdf', 's41467-018-03657-3.pdf', 's41593-018-0200-7.pdf', 's41598-018-22160-9.pdf', 's41598-018-28865-1.pdf', 'Scene complexity modulates degree of feedback activity during object detection in natural scenes.pdf', 'Serre_etal_PBR07.pdf', 'similarity based fusion MEG fMRI.pdf', 'Spatial attention enhances cortical tracking of quasi-rhythmic visual stimuli.pdf', 'Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs.pdf', 'Stack Sparse AutoEncoder Detector for Automatic Identification Epilepsy.pdf', 'Stimulus-Driven Population Activity Patterns in Macaque Primary Visual Cortex.pdf', 'Task-specific vision models explain task-specific areas of visual cortex (1).pdf', 'Task-specific vision models explain task-specific areas of visual cortex.pdf', 'theory of cortical function.pdf', 'Top-down effects in the brain.pdf', 'Toward Universal Lingustic Encoding.pdf', 'TowardIntegrationDNN-Neuroscience.pdf', 'Transfer learning of deep neural network representations for fMRI decoding.pdf', 'Visual pathways from the perspective of cost functions and multi-task deep neural networks (1).pdf', 'Visual pathways from the perspective of cost functions and multi-task deep neural networks.pdf', 'Wen et al_CC_2016_Neural Encoding and Decoding with Deep Learning for Dynamic Natural Vision.pdf', 'What is Changing when Decoding visual information movies iEEG (1).pdf', 'What is Changing when Decoding visual information movies iEEG (2).pdf', 'What When Where Visual Word Recog-TICS2014.pdf', 'zeilerECCV2014.pdf', 'zpq10607.pdf', '！A primer on encoding models in sensory neuroscience.pdf', '！NeuroEncodingandDecodingwithDL-DynamicNaturalVision.pdf', '！Zweig_InterpoNet_a_Brain_CVPR_2017_paper.pdf']\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\! VisualFeatureExtractionfromVoxel-Weighted-Averaging-fMRI.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Multiple studies have provided evidence for distributed object '\n",
      "             'representation in the brain, with several recent experiments '\n",
      "             'leveraging basis function estimates for partial image '\n",
      "             'reconstruction from fMRI data. Using a novel combination of '\n",
      "             'statistical decomposition, generalized linear models, and '\n",
      "             'stimulus averaging on previously examined image sets and '\n",
      "             'Bayesian regression of recorded fMRI activity during '\n",
      "             'presentation of these data sets, we identify a subset of '\n",
      "             'relevant voxels that appear to code for covarying object '\n",
      "             'features. Using a technique we term “voxel-weighted averaging,” '\n",
      "             'we isolate image ﬁlters that these voxels appear to implement. '\n",
      "             'The results, though very cursory, appear to have signiﬁcant '\n",
      "             'implications for hierarchical and deep-learningtype approaches '\n",
      "             'toward the understanding of neural coding and representation.',\n",
      " 'keywords': ['Bayesian estimation',\n",
      "              'component analysis',\n",
      "              'fMRI',\n",
      "              'generalized linear models',\n",
      "              'imaging',\n",
      "              'voxel'],\n",
      " 'title': 'Visual Feature Extraction From Voxel-Weighted Averaging of Stimulus '\n",
      "          'Images in 2 fMRI Studies'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!10.1093@cercor@bhy123.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!Improved estimation of subject-level functional connectivity using full and partial correlation with empirical Bayes shrinkage.pdf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Reliability of subject-level resting-state functional '\n",
      "             'connectivity (FC) is determined in part by the statistical '\n",
      "             'techniques employed in its estimation. Methods that pool '\n",
      "             'information across subjects to inform estimation of '\n",
      "             'subject-level effects (e.g., Bayesian approaches) have been '\n",
      "             'shown to enhance reliability of subject-level FC. However, fully '\n",
      "             'Bayesian approaches are computationally demanding, while '\n",
      "             'empirical Bayesian approaches typically rely on using repeated '\n",
      "             'measures to estimate the variance components in the model. Here, '\n",
      "             'we avoid the need for repeated measures by proposing a novel '\n",
      "             'measurement error model for FC describing the different sources '\n",
      "             'of variance and error, which we use to perform empirical Bayes '\n",
      "             'shrinkage of subject-level FC towards the group average. In '\n",
      "             'addition, since the traditional intra-class correlation '\n",
      "             'coefﬁcient (ICC) is inappropriate for biased es- timates, we '\n",
      "             'propose a new reliability measure denoted the mean squared error '\n",
      "             'intra-class correlation coefﬁcient (ICCMSE) to properly assess '\n",
      "             'the reliability of the resulting (biased) estimates. We apply '\n",
      "             'the proposed techniques to test-retest resting-state fMRI data '\n",
      "             'on 461 subjects from the Human Connectome Project to estimate '\n",
      "             'connectivity between 100 regions identiﬁed through independent '\n",
      "             'components analysis (ICA). We consider both correlation and '\n",
      "             'partial correlation as the measure of FC and assess the beneﬁt '\n",
      "             'of shrinkage for each measure, as well as the effects of scan '\n",
      "             'duration. We ﬁnd that shrinkage estimates of subject-level FC '\n",
      "             'exhibit substantially greater reli- ability than traditional '\n",
      "             'estimates across various scan durations, even for the most '\n",
      "             'reliable connections and regardless of connectivity measure. '\n",
      "             'Additionally, we ﬁnd partial correlation reliability to be '\n",
      "             'highly sensitive to the choice of penalty term, and to be '\n",
      "             'generally worse than that of full correlations except for '\n",
      "             'certain connections and a narrow range of penalty values. This '\n",
      "             'suggests that the penalty needs to be chosen carefully when '\n",
      "             'using partial correlations.',\n",
      " 'keywords': ['Functional connectivity',\n",
      "              'Connectome',\n",
      "              'Partial correlation',\n",
      "              'Reliability',\n",
      "              'Bayesian statistics',\n",
      "              'Shrinkage',\n",
      "              'Measurement error',\n",
      "              'Resting-state fMRI'],\n",
      " 'title': 'Improved estimation of subject-level functional connectivity using '\n",
      "          'full and partial correlation with empirical Bayes shrinkage'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\!Integrating theoretical models with functional neuroimaging.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The development of mathematical models to characterize '\n",
      "             'perceptual and cognitive processes dates back almost to the '\n",
      "             'inception of the field of psychology. Since the 1990s, human '\n",
      "             'functional neuroimaging has provided for rapid empirical and '\n",
      "             'theoretical advances across a variety of domains in cognitive '\n",
      "             'neuroscience. In more recent work, formal modeling and '\n",
      "             'neuroimaging approaches are being successfully combined, often '\n",
      "             'producing models with a level of specificity and rigor that '\n",
      "             'would not have been possible by studying behavior alone. In this '\n",
      "             'review, we highlight examples of recent studies that utilize '\n",
      "             'this combined approach to provide novel insights into the '\n",
      "             'mechanisms underlying human cognition. The studies described '\n",
      "             'here span domains of perception, attention, memory, '\n",
      "             'categorization, and cognitive control, employing a variety of '\n",
      "             'analytic and model-inspired approaches. Across these diverse '\n",
      "             'studies, a common theme is that individually tailored, creative '\n",
      "             'solutions are often needed to establish compelling links between '\n",
      "             'multi-parameter models and complex sets of neural data. We '\n",
      "             'conclude that future developments in model-based cognitive '\n",
      "             'neuroscience will have great potential to advance our '\n",
      "             'theoretical understanding and ability to model both low-level '\n",
      "             'and high-level cognitive processes. © 2016 Elsevier Inc. All '\n",
      "             'rights reserved.',\n",
      " 'keywords': [],\n",
      " 'title': 'Integrating theoretical models with functional neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\0102181v1.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07073970.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07264993.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Goal: The detection of brain responses corresponding to the '\n",
      "             'presentation of a particular class of images is a challenge in '\n",
      "             'brain–machine interface. Current systems based on the detection '\n",
      "             'of brain responses during rapid serial visual presentation '\n",
      "             '(RSVP) tasks possess advantages for both healthy and disabled '\n",
      "             'people, as they are gaze independent and can offer a high '\n",
      "             'throughput. Methods: We propose a novel paradigm based on a '\n",
      "             'dual-RSVP task that assumes a low target probability. Two '\n",
      "             'streams of images are presented simultaneously on the screen, '\n",
      "             'the second stream is identical to the ﬁrst one, but delayed in '\n",
      "             'time. Participants were asked to detect images containing a '\n",
      "             'person. They follow the ﬁrst stream until they see a target '\n",
      "             'image, then change their attention to the second stream until '\n",
      "             'the target image reappears, ﬁnally they change their attention '\n",
      "             'back to the ﬁrst stream. Results: The performance of '\n",
      "             'single-trial detection was evaluated on both streams and their '\n",
      "             'combination of the decisions with signal recorded with '\n",
      "             'magnetoencephalography (MEG) during the dual-RSVP task. We '\n",
      "             'compare classi ﬁcation performance across different sets of '\n",
      "             'channels (magnetometers, gradiometers) with a BLDA classi ﬁer '\n",
      "             'with inputs obtained after spatial ﬁltering. Conclusion: The '\n",
      "             'results suggest that single-trial detection can be obtained with '\n",
      "             'an area under the ROC curve superior to 0.95, and that an almost '\n",
      "             'perfect accuracy can be obtained with some subjects thanks to '\n",
      "             'the combination of the decisions from two trials, without '\n",
      "             'doubling the duration of the experiment. Signiﬁcance: The '\n",
      "             'present results show that a reliable accuracy can be obtained '\n",
      "             'with the MEG for target detection during a dual-RSVP task.',\n",
      " 'keywords': ['Event-related ﬁelds',\n",
      "              'magnetoencephalography(MEG)',\n",
      "              'rapid serial visual presentation',\n",
      "              'single-trial detection'],\n",
      " 'title': 'Single-Trial Detection With Magnetoencephalography During a '\n",
      "          'Dual-Rapid Serial Visual Presentation Task'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\07468569.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='RMTMIB'>, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Linear Gaussian state-space models are ubiquitous in signal '\n",
      "             'processing, and an important procedure is that of estimating '\n",
      "             'system parameters from observed data. Rather than making a '\n",
      "             'single point estimate, it is often desirable to conduct Bayesian '\n",
      "             'learning, in which the entire posterior distribution of the '\n",
      "             'unknown parameters is sought. This can be achieved using Markov '\n",
      "             'chain Monte Carlo. On some occasions it is possible to deduce '\n",
      "             'the form of the unknown system matrices in terms of a small '\n",
      "             'number of scalar parameters, by considering the underlying '\n",
      "             'physical processes involved. Here we study the case where this '\n",
      "             'is not possible, and the entire matrices must be treated as '\n",
      "             'unknowns. An efﬁcient Gibbs sampling algorithm exists for the '\n",
      "             'basic formulation of linear model. We extend this to the more '\n",
      "             'challenging situation where the transition model is possibly '\n",
      "             'degenerate, i.e., the transition covariance matrix is singular. '\n",
      "             'Appropriate Markov kernels are devised and demonstrated with '\n",
      "             'simulations.',\n",
      " 'keywords': ['Covariance matrices',\n",
      "              'linear systems',\n",
      "              'markov pro-cesses',\n",
      "              'monte carlo methods',\n",
      "              'parameter estimation',\n",
      "              'time seriesanalysis'],\n",
      " 'title': 'Bayesian Learning of Degenerate Linear Gaussian State Space Models '\n",
      "          'Using Markov Chain Monte Carlo'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08025614.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='BLEX'>, 2\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='MTSYN'>, 4\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='MTSYN'>, 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Principal component analysis (PCA) is an exploratory tool widely '\n",
      "             'used in data analysis to uncover the dominant patterns of '\n",
      "             'variability within a population. Despite its ability to '\n",
      "             'represent a data set in a low-dimensional space, PCA ’s '\n",
      "             'interpretability remai ns limited. Indeed, the components '\n",
      "             'produced by PCA are often noisy or exhibit no visually '\n",
      "             'meaningful patterns. Furthermore, the fact that the components '\n",
      "             'are usually non-sparse may also impede interpretation, unless '\n",
      "             'arbitrary thresholding is applied. However, in neuroimaging, it '\n",
      "             'is essential to uncover clinically interpretable phenotypic '\n",
      "             'markers that would account for the main variability in the brain '\n",
      "             'images of a population. Recently, some alternatives to the '\n",
      "             'standard PCA approach, such as sparse PCA (SPCA), have been '\n",
      "             'proposed, their aim being to limit the density of the '\n",
      "             'components. Nonetheless, sparsity alone does not entirely solve '\n",
      "             'the interpretability problem in neuroimaging, since it may yield '\n",
      "             'scattered and unstable components. We hypothesized that the '\n",
      "             'incorporation of prior information regarding the structure of '\n",
      "             'the data may lead to improved relevance and interpretability of '\n",
      "             'brain patterns. We therefore present a simple extension of the '\n",
      "             'popular PCA framework that adds structured sparsity penalties on '\n",
      "             'the loading vectors in order to identify the few stable regions '\n",
      "             'in the brain images that capture most of the variability. Such '\n",
      "             'structured sparsity can be obtained by combining, e.g., (cid:2)1 '\n",
      "             'and total variation (TV) penalties, where the TV regularization '\n",
      "             'encodes information on the underlying structure of the data. '\n",
      "             'This paper presents the structured SPCA (denoted SPCA-TV) '\n",
      "             'optimization framework and its resolution. We demonstrate '\n",
      "             'SPCA-TV ’s effectiveness and versatility on three different data '\n",
      "             'sets. It can be applied to any kind of structured data, such as, '\n",
      "             'e.g., N-dimensional array images or meshes of cortical surfaces. '\n",
      "             'The gains of SPCA-TV over unstructured approaches (such as SPCA '\n",
      "             'and ElasticNet PCA) or structured approach (such as GraphNet '\n",
      "             'PCA) are signi ﬁcant, since SPCA-TV reveals the variability',\n",
      " 'keywords': ['MRI', 'unsupervised machine learning', 'PCA', 'total variation'],\n",
      " 'title': 'Structured Sparse Principal Components Analysis With the TV-Elastic '\n",
      "          'Net Penalty'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08051252.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Unsupervised feature extractors are known to perform an efﬁcient '\n",
      "             'and discriminative representation of data. Insight into the '\n",
      "             'mappings they perform and human ability to understand them, '\n",
      "             'however, remain very limited. This is especially prominent when '\n",
      "             'multilayer deep learning architectures are used. This paper '\n",
      "             'demonstrates how to remove these bottlenecks within the '\n",
      "             'architecture of non-negativity constrained autoencoder. It is '\n",
      "             'shown that using both L1 and L2 regularizations that induce '\n",
      "             'non-negativity of weights, most of the weights in the network '\n",
      "             'become constrained to be non-negative, thereby resulting into a '\n",
      "             'more understandable structure with minute deterioration in '\n",
      "             'classi ﬁcation accuracy. Also, this proposed approach extracts '\n",
      "             'features that are more sparse and produces additional output '\n",
      "             'layer sparsi ﬁcation. The method is analyzed for accuracy and '\n",
      "             'feature interpretation on the MNIST data, the NORB normalized '\n",
      "             'uniform object data, and the Reuters text categorization data '\n",
      "             'set. Index Terms Deep learning (DL), part-based representation, '\n",
      "             'receptive ﬁeld, sparse autoencoder (SAE), white-box model.',\n",
      " 'keywords': [],\n",
      " 'title': '3969'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08269806.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Our experience of the world is multimodal we see objects, hear '\n",
      "             'sounds, feel texture, smell odors, and taste ﬂavors. Modality '\n",
      "             'refers to the way in which something happens or is experienced '\n",
      "             'and a research problem is characterized as multimodal when it '\n",
      "             'includes multiple such modalities. In order for Ar tiﬁcial '\n",
      "             'Intelligence to make progress in understanding the world around '\n",
      "             'us, it needs to be able to interpret such multimodal signals '\n",
      "             'together. Multimodal machine learning aims to build models that '\n",
      "             'can process and relate information from multiple modalities. It '\n",
      "             'is a vibrant multi-disciplinary ﬁeld of increasing impor tance '\n",
      "             'and with extraordinary potential. Instead of focusing on speciﬁc '\n",
      "             'multimodal applications, this paper surveys the recent advances '\n",
      "             'in multimodal machine learning itself and presents them in a '\n",
      "             'common taxonomy. We go beyond the typical early and late fusion '\n",
      "             'categorization and identify broader challenges that are faced by '\n",
      "             'multimodal machine learning, namely: representation, '\n",
      "             'translation, alignment, fusion, and co-learning. This new '\n",
      "             'taxonomy will enable researchers to better understand the state '\n",
      "             'of the ﬁeld and identify directions for future research.',\n",
      " 'keywords': ['Multimodal', 'machine learning', 'introductory', 'survey'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\08370896.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Feedback is a fundamental mechanism existing in the human visual '\n",
      "             'system, but has not been explored deeply in designing computer '\n",
      "             'vision algorithms. In this paper, we claim that feedback plays a '\n",
      "             'critical role in understanding convolutional neural networks '\n",
      "             '(CNNs), e.g., how a neuron in CNN describes an object’s pattern, '\n",
      "             'and how a collection of neurons form comprehensive perception to '\n",
      "             'an object. To model the feedback in CNNs, we propose a novel '\n",
      "             'model named Feedback CNN and develop two new processing '\n",
      "             'algorithms, i.e., neural pathway pruning and pattern recovering. '\n",
      "             'We have mathematically proven that the proposed method can reach '\n",
      "             'local optimum. Note that Feedback CNN belongs to weakly '\n",
      "             'supervised methods and can be trained only using category-level '\n",
      "             'labels. But it possesses powerful capability to accurately '\n",
      "             'localize and segment category-speciﬁc objects. We conduct '\n",
      "             'extensive visualization analysis, and the results reveal the '\n",
      "             'close relationship between neurons and object par ts in Feedback '\n",
      "             'CNN. Finally, we evaluate the proposed Feedback CNN over the '\n",
      "             'tasks of weakly supervised object localization and segmentation, '\n",
      "             'and the experimental results on ImageNet and Pascal VOC show '\n",
      "             'that our method remarkably outperforms the state-of-the-ar t '\n",
      "             'ones.',\n",
      " 'keywords': ['feedback',\n",
      "              'convolutional neural networks (CNNs)',\n",
      "              'weakly supervised',\n",
      "              'object localization',\n",
      "              'object segmentation'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0010945217303258-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Vision research has been shaped by the seminal insight that we '\n",
      "             'can understand the higher-tier visual cortex from the '\n",
      "             'perspective of multiple functional pathways with different '\n",
      "             'goals. In this paper, we try to give a computational account of '\n",
      "             'the functional organization of this system by reasoning from the '\n",
      "             'perspective of multi-task deep neural networks. Machine learning '\n",
      "             'has shown that tasks become easier to solve when they are '\n",
      "             'decomposed into subtasks with their own cost function. We '\n",
      "             'hypothesize that the visual system optimizes multiple cost '\n",
      "             'functions of unrelated tasks and this causes the emergence of a '\n",
      "             'ventral pathway dedicated to vision for perception, and a dorsal '\n",
      "             'pathway dedicated to vision for action. To evaluate the '\n",
      "             'functional organization in multi-task deep neural networks, we '\n",
      "             'propose a method that measures the contribution of a unit '\n",
      "             'towards each task, applying it to two networks that have been '\n",
      "             'trained on either two related or two unrelated tasks, using an '\n",
      "             'identical stimulus set. Results show that the network trained on '\n",
      "             'the unrelated tasks shows a decreasing degree of feature '\n",
      "             'representation sharing towards higher-tier layers while the '\n",
      "             'network trained on related tasks uniformly shows high degree of '\n",
      "             'sharing. We conjecture that the method we propose can be used to '\n",
      "             'analyze the anatomical and functional organization of the visual '\n",
      "             'system and beyond. We predict that the degree to which tasks are '\n",
      "             'related is a good descriptor of the degree to which they share '\n",
      "             'downstream cortical-units.',\n",
      " 'keywords': ['Dual-pathway',\n",
      "              'Deep learning',\n",
      "              'Cost functions',\n",
      "              'Representations',\n",
      "              'Visual processing'],\n",
      " 'title': 'Visual pathways from the perspective of cost functions and '\n",
      "          'multi-task deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0028393217300593-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual object recognition is a complex, dynamic process. '\n",
      "             'Multivariate pattern analysis methods, such as decoding, have '\n",
      "             'begun to reveal how the brain processes complex visual '\n",
      "             'information. Recently, temporal decoding methods for EEG and MEG '\n",
      "             'have oﬀered the potential to evaluate the temporal dynamics of '\n",
      "             'object recognition. Here we review the contribution of M/EEG '\n",
      "             'time-series decoding methods to understanding visual object '\n",
      "             'recognition in the human brain. Consistent with the current '\n",
      "             'understanding of the visual processing hierarchy, low-level '\n",
      "             'visual features dominate decodable object representations early '\n",
      "             'in the time-course, with more abstract representations related '\n",
      "             'to object category emerging later. A key ﬁnding is that the '\n",
      "             'time-course of object processing is highly dynamic and rapidly '\n",
      "             'evolving, with limited temporal generalisation of decodable '\n",
      "             'information. Several studies have examined the emergence of '\n",
      "             'object category structure, and we consider to what degree '\n",
      "             'category decoding can be explained by sensitivity to low-level '\n",
      "             'visual features. Finally, we evaluate recent work attempting to '\n",
      "             'link human behaviour to the neural time-course of object '\n",
      "             'processing.',\n",
      " 'keywords': ['MEG',\n",
      "              'EEG',\n",
      "              'MVPA',\n",
      "              'Time-series decoding',\n",
      "              'Object recognition',\n",
      "              'Object categorisation'],\n",
      " 'title': 'Decoding the time-course of object recognition in the human brain_ '\n",
      "          'From visual features to categorical decisions'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0042698909004751-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '1. Introduction',\n",
      " 'keywords': ['Illusory contours',\n",
      "              'Occluded contours',\n",
      "              'Identity hypothesis',\n",
      "              'Contour interpolation',\n",
      "              'Computational modeling'],\n",
      " 'title': 'A unified model of illusory and occluded contour interpolation'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0893608016301800-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The hard problem of consciousness is the problem of explaining '\n",
      "             'how we experience qualia or phenome- nal experiences, such as '\n",
      "             'seeing, hearing, and feeling, and knowing what they are. To '\n",
      "             'solve this problem, a theory of consciousness needs to link '\n",
      "             'brain to mind by modeling how emergent properties of several '\n",
      "             'brain mechanisms interacting together embody detailed properties '\n",
      "             'of individual conscious psychologi- cal experiences. This '\n",
      "             'article summarizes evidence that Adaptive Resonance Theory, or '\n",
      "             'ART, accomplishes this goal. ART is a cognitive and neural '\n",
      "             'theory of how advanced brains autonomously learn to attend, rec- '\n",
      "             'ognize, and predict objects and events in a changing world. ART '\n",
      "             'has predicted that ‘‘all conscious states are resonant states’’ '\n",
      "             'as part of its specification of mechanistic links between '\n",
      "             'processes of consciousness, learning, expectation, attention, '\n",
      "             'resonance, and synchrony. It hereby provides functional and '\n",
      "             'mechanistic explanations of data ranging from individual spikes '\n",
      "             'and their synchronization to the dynamics of con- scious '\n",
      "             'perceptual, cognitive, and cognitive–emotional experiences. ART '\n",
      "             'has reached sufficient maturity to begin classifying the brain '\n",
      "             'resonances that support conscious experiences of seeing, '\n",
      "             'hearing, feeling, and knowing. Psychological and neurobiological '\n",
      "             'data in both normal individuals and clinical patients are '\n",
      "             'clarified by this classification. This analysis also explains '\n",
      "             'why not all resonances become conscious, and why not all brain '\n",
      "             'dynamics are resonant. The global organization of the brain into '\n",
      "             'computationally com- plementary cortical processing streams '\n",
      "             '(complementary computing), and the organization of the cerebral '\n",
      "             'cortex into characteristic layers of cells (laminar computing), '\n",
      "             'figure prominently in these explanations of conscious and '\n",
      "             'unconscious processes. Alternative models of consciousness are '\n",
      "             'also discussed. © 2016 The Author. Published by Elsevier Ltd. '\n",
      "             'This is an open access article under the CC BY-NC-ND license '\n",
      "             '(http://creativecommons.org/licenses/by- nc- nd/4.0/).',\n",
      " 'keywords': ['Consciousness',\n",
      "              'Adaptive resonance',\n",
      "              'Attention',\n",
      "              'Vision',\n",
      "              'Audition',\n",
      "              'Emotion'],\n",
      " 'title': 'Towards solving the hard problem of consciousness: The varieties of '\n",
      "          'brain resonances and the conscious experiences that they support'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0896627306005861-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'It is generally assumed that sensitivity to different stimulus '\n",
      "             'orientations is mapped in a globally equiva- lent fashion across '\n",
      "             'primate visual cortex, at a spatial scale larger than that of '\n",
      "             'orientation columns. However, some evidence predicts instead '\n",
      "             'that radial orientations should produce higher activity than '\n",
      "             'other orientations, throughout visual cortex. Here, this radial '\n",
      "             'orientation bias was robustly conﬁrmed using (1) human psycho- '\n",
      "             'physics, plus fMRI in (2) humans and (3) behaving mon- keys. In '\n",
      "             'visual cortex, fMRI activity was at least 20% higher in the '\n",
      "             'retinotopic representations of polar angle which corresponded to '\n",
      "             'the radial stimulus orientations (relative to tangential). In a '\n",
      "             'global demonstration of this, we activated complementary '\n",
      "             'retinotopic quad- rants of visual cortex by simply changing '\n",
      "             'stimulus orientation, without changing stimulus location in the '\n",
      "             'visual ﬁeld. This evidence reveals a neural link between '\n",
      "             'orientation sensitivity and the cortical retinotopy, which have '\n",
      "             'previously been considered independent.',\n",
      " 'keywords': [],\n",
      " 'title': 'doi:10.1016/j.neuron.2006.07.021'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S089662731830477X-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Representation, Pattern Information, and Brain Signatures: From '\n",
      "          'Neurons to Neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S0925231215017634-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Deep learning algorithms are a subset of the machine learning '\n",
      "             'algorithms, which aim at discovering multiple levels of '\n",
      "             'distributed representations. Recently, numerous deep learning '\n",
      "             'algorithms have been proposed to solve traditional artiﬁcial '\n",
      "             'intelligence problems. This work aims to review the '\n",
      "             'state-of-the- art in deep learning algorithms in computer vision '\n",
      "             'by highlighting the contributions and challenges from over 210 '\n",
      "             'recent research papers. It ﬁrst gives an overview of various '\n",
      "             'deep learning approaches and their recent developments, and then '\n",
      "             'brieﬂy describes their applications in diverse vision tasks, '\n",
      "             'such as image classiﬁcation, object detection, image retrieval, '\n",
      "             'semantic segmentation and human pose estimation. Finally, the '\n",
      "             'paper summarizes the future trends and challenges in designing '\n",
      "             'and training deep neural networks.',\n",
      " 'keywords': ['Deep learning',\n",
      "              'Computer vision',\n",
      "              'Developments',\n",
      "              'Applications',\n",
      "              'Trends',\n",
      "              'Challenges'],\n",
      " 'title': 'Deep learning for visual understanding_ A review'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053810015000355-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The ability to select, within the complexity of sensory input, '\n",
      "             'the information most relevant for our purposes is inﬂuenced by '\n",
      "             'both internal settings (i.e., top-down control) and salient '\n",
      "             'features of external stimuli (i.e., bottom-up control). We here '\n",
      "             'investigated using fMRI the neural underpinning of the '\n",
      "             'interaction of top-down and bottom-up processes, as well as '\n",
      "             'their effects on extrastriate areas processing visual stimuli in '\n",
      "             'a category-selective fashion. We presented photos of bodies or '\n",
      "             'buildings embedded into frequency-matched visual noise to the '\n",
      "             'subjects. Stimulus saliency changed gradually due to an altered '\n",
      "             'degree to which photos stood-out in relation to the surrounding '\n",
      "             'noise (hence generating stronger bottom-up control signals). '\n",
      "             'Top-down settings were manipulated via instruction: par- '\n",
      "             'ticipants were asked to attend one stimulus category (i.e., ‘‘is '\n",
      "             'there a body?’’ or ‘‘is there a building?’’). Highly salient '\n",
      "             'stimuli that were inconsistent with participants’ attentional '\n",
      "             'top-down template activated the inferior frontal junction and '\n",
      "             'dorsal parietal regions bilat- erally. Stimuli consistent with '\n",
      "             'participants’ current attentional set additionally activated '\n",
      "             'insular cortex and the parietal operculum. Furthermore, the '\n",
      "             'extrastriate body area (EBA) exhibited increased neural activity '\n",
      "             'when attention was directed to bodies. However, the latter '\n",
      "             'effect was found only when stimuli were presented at '\n",
      "             'intermediate saliency levels, thus suggesting a top-down '\n",
      "             'modulation of this region only in the presence of weak bot- '\n",
      "             'tom-up signals. Taken together, our results highlight the role '\n",
      "             'of the inferior frontal junction and posterior parietal regions '\n",
      "             'in integrating bottom-up and top-down attentional control '\n",
      "             'signals.',\n",
      " 'keywords': ['Object attention', 'fMRI', 'Top-down', 'Bottom-up'],\n",
      " 'title': 'Selecting category specific visual information: Top-down and '\n",
      "          'bottom-up control of object based attention'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811907001073-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'keywords': ['Functional magnetic resonance imaging data analysis; Dynamic '\n",
      "              'analysis'],\n",
      " 'title': 'Dynamic discrimination analysis: A spatialâ\\xa0\\x8dtemporal SVM'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811911013012-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'MEG/EEG are non-invasive imaging techniques that record brain '\n",
      "             'activity with high temporal resolution. However, estimation of '\n",
      "             'brain source currents from surface recordings requires solving '\n",
      "             'an ill-conditioned in- verse problem. Converging lines of '\n",
      "             'evidence in neuroscience, from neuronal network models to '\n",
      "             'resting-state imaging and neurophysiology, suggest that cortical '\n",
      "             'activation is a distributed spatiotemporal dynamic process, '\n",
      "             'supported by both local and long-distance neuroanatomic '\n",
      "             'connections. Because spatiotemporal dy- namics of this kind are '\n",
      "             'central to brain physiology, inverse solutions could be improved '\n",
      "             'by incorporating models of these dynamics. In this article, we '\n",
      "             'present a model for cortical activity based on nearest- neighbor '\n",
      "             'autoregression that incorporates local spatiotemporal '\n",
      "             'interactions between distributed sources in a manner consistent '\n",
      "             'with neurophysiology and neuroanatomy. We develop a dynamic '\n",
      "             'Maximum a Posteriori Expectation-Maximization (dMAP-EM) source '\n",
      "             'localization algorithm for estimation of cortical sources and '\n",
      "             'model parameters based on the Kalman Filter, the Fixed Interval '\n",
      "             'Smoother, and the EM algorithms. We apply the dMAP-EM algorithm '\n",
      "             'to simulated experiments as well as to human experimental data. '\n",
      "             'Further- more, we derive expressions to relate our dynamic '\n",
      "             'estimation formulas to those of standard static models, and show '\n",
      "             'how dynamic methods optimally assimilate past and future data. '\n",
      "             'Our results establish the feasibil- ity of spatiotemporal '\n",
      "             'dynamic estimation in large-scale distributed source spaces with '\n",
      "             'several thousand source locations and hundreds of sensors, with '\n",
      "             'resulting inverse solutions that provide substantial perfor- '\n",
      "             'mance improvements over static methods.',\n",
      " 'keywords': ['MEG/EEG',\n",
      "              'Source localization',\n",
      "              'Inverse problem',\n",
      "              'Dynamic spatiotemporal modeling'],\n",
      " 'title': 'A spatiotemporal dynamic distributed solution to the MEG inverse '\n",
      "          'problem'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811912004429-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'A novel framework for analysing task-positive data in '\n",
      "             'magnetoencephalography (MEG) is presented that can identify '\n",
      "             'task-related networks. Techniques that combine beamforming, the '\n",
      "             'Hilbert transform and temporal independent component analysis '\n",
      "             '(ICA) have recently been applied to resting-state MEG data and '\n",
      "             'have been shown to extract resting-state networks similar to '\n",
      "             'those found in fMRI. Here we extend this approach in two ways. '\n",
      "             'First, we systematically investigate optimisation of '\n",
      "             'time-frequency windows for connectivity measurement. This is '\n",
      "             'achieved by estimating the distribution of functional '\n",
      "             'connectivity scores between nodes of known resting-state '\n",
      "             'networks and contrasting it with a distribution of artefactual '\n",
      "             'scores that are en- tirely due to spatial leakage caused by the '\n",
      "             'inverse problem. We ﬁnd that functional connectivity, both in '\n",
      "             'the resting-state and during a cognitive task, is best estimated '\n",
      "             'via correlations in the oscillatory envelope in the 8–20 Hz '\n",
      "             'frequency range, temporally down-sampled with windows of 1–4 s. '\n",
      "             'Second, we combine ICA with the general linear model (GLM) to '\n",
      "             'incorporate knowledge of task structure into our connectivity '\n",
      "             'analysis. The combination of ICA with the GLM helps overcome '\n",
      "             'problems of these techniques when used independent- ly: namely, '\n",
      "             'the interpretation and separation of interesting independent '\n",
      "             'components from those that repre- sent noise in ICA and the '\n",
      "             'correction for multiple comparisons when applying the GLM. We '\n",
      "             'demonstrate the approach on a 2-back working memory task and '\n",
      "             'show that this novel analysis framework is able to elucidate the '\n",
      "             'functional networks involved in the task beyond that which is '\n",
      "             'achieved using the GLM alone. We ﬁnd ev- idence of localised '\n",
      "             'task-related activity in the area of the hippocampus, which is '\n",
      "             'difﬁcult to detect reliably using standard methods. '\n",
      "             'Task-positive ICA, coupled with the GLM, has the potential to be '\n",
      "             'a powerful tool in the analysis of MEG data.',\n",
      " 'keywords': ['MEG',\n",
      "              'Working memory',\n",
      "              'Independent component analysis',\n",
      "              'General linear model',\n",
      "              'Hippocampus',\n",
      "              'Neural oscillations'],\n",
      " 'title': 'Inferring task-related networks using independent component '\n",
      "          'analysis in magnetoencephalography'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811913002851-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.layout:Too many boxes (102) to group, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Fractional occupancy kð Þ ¼ 1 T',\n",
      " 'keywords': ['Magnetoencephalography',\n",
      "              'MEG',\n",
      "              'EEG',\n",
      "              'Source reconstruction',\n",
      "              'Microstates',\n",
      "              'Connectivity',\n",
      "              'Hidden Markov Model'],\n",
      " 'title': 'Dynamic state allocation for MEG source reconstruction'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811914001220-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': \"Heavy demands are placed on the brain's attentional capacity \"\n",
      "             'when selecting a target item in a cluttered visual scene, or '\n",
      "             'when reading. It is widely accepted that such attentional '\n",
      "             'selection is mediated by top–down signals from higher cortical '\n",
      "             'areas to early visual areas such as the primary visual cortex '\n",
      "             '(V1). Further, it has also been reported that there is '\n",
      "             'considerable variation in the surface area of V1. This variation '\n",
      "             'may impact on either the number or speciﬁcity of attentional '\n",
      "             'feedback signals and, thereby, the efﬁciency of attentional '\n",
      "             'mechanisms. In this study, we investigated whether individual '\n",
      "             'differences between humans performing attention-demanding tasks '\n",
      "             'can be related to the functional area of V1. We found that those '\n",
      "             'with a larger representation in V1 of the central 12° of the '\n",
      "             'visual ﬁeld as measured using BOLD signals from fMRI were able '\n",
      "             'to perform a serial search task at a faster rate. In line with '\n",
      "             'recent suggestions of the vital role of visuo-spatial attention '\n",
      "             'in reading, the speed of reading showed a strong positive '\n",
      "             'correlation with the speed of visual search, although it showed '\n",
      "             'little correlation with the size of V1. The results support the '\n",
      "             'idea that the functional size of the primary visual cortex is an '\n",
      "             'important determinant of the efﬁciency of selective spatial '\n",
      "             'attention for simple tasks, and that the attentional processing '\n",
      "             'required for complex tasks like reading are to a large extent '\n",
      "             'determined by other brain areas and inter-areal connections.',\n",
      " 'keywords': ['Visual attention',\n",
      "              'Primary visual cortex',\n",
      "              'fMRI',\n",
      "              'Reading',\n",
      "              'Visual search'],\n",
      " 'title': 'feff00460075006e006300740069006f006e0061006c002000730069007a00650020006f0066002000680075006d0061006e002000760069007300750061006c00200061007200650061002000560031003a002000410020006e0065007500720061006c00200063006f007200720065006c0061007400650020006f006600200074006f007020130064006f0077006e00200061007400740065006e00740069006f006e'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811914010325-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Magnetoencephalography and electroencephalography (M/EEG) '\n",
      "             'measure non-invasively the weak electromag- netic ﬁelds induced '\n",
      "             'by post-synaptic neural currents. The estimation of the spatial '\n",
      "             'covariance of the signals re- corded on M/EEG sensors is a '\n",
      "             'building block of modern data analysis pipelines. Such '\n",
      "             'covariance estimates are used in brain–computer interfaces (BCI) '\n",
      "             'systems, in nearly all source localization methods for spatial '\n",
      "             'whitening as well as for data covariance estimation in '\n",
      "             'beamformers. The rationale for such models is that the signals '\n",
      "             'can be modeled by a zero mean Gaussian distribution. While '\n",
      "             'maximizing the Gaussian likelihood seems natural, it leads to a '\n",
      "             'covariance estimate known as empirical covariance (EC). It turns '\n",
      "             'out that the EC is a poor estimate of the true covariance when '\n",
      "             'the number of samples is small. To address this issue the '\n",
      "             'estimation needs to be regularized. The most common approach '\n",
      "             'downweights off-diagonal coefﬁcients, while more advanced '\n",
      "             'regularization methods are based on shrinkage techniques or '\n",
      "             'generative models with low rank assumptions: probabilistic PCA '\n",
      "             '(PPCA) and factor analysis (FA). Using cross-validation all of '\n",
      "             'these models can be tuned and compared based on Gaussian '\n",
      "             'likelihood computed on unseen data. We investigated these models '\n",
      "             'on simulations, one electroencephalography (EEG) dataset as well '\n",
      "             'as magnetoen- cephalography (MEG) datasets from the most common '\n",
      "             'MEG systems. First, our results demonstrate that different '\n",
      "             'models can be the best, depending on the number of samples, '\n",
      "             'heterogeneity of sensor types and noise properties. Second, we '\n",
      "             'show that the models tuned by cross-validation are superior to '\n",
      "             'models with hand-selected regular- ization. Hence, we propose an '\n",
      "             'automated solution to the often overlooked problem of covariance '\n",
      "             'estimation of M/EEG signals. The relevance of the procedure is '\n",
      "             'demonstrated here for spatial whitening and source localization '\n",
      "             'of MEG signals.',\n",
      " 'keywords': ['Electroencephalography (EEG)',\n",
      "              'Magnetoencephalography (MEG)',\n",
      "              'Neuroimaging',\n",
      "              'Principal component analysis (PCA)',\n",
      "              'Factor analysis (FA)',\n",
      "              'Covariance estimation',\n",
      "              'Whitening',\n",
      "              'Model selection',\n",
      "              'Statistical learning'],\n",
      " 'title': 'Automated model selection in covariance estimation and spatial '\n",
      "          'whitening of MEG and EEG signals'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811915005315-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'The advent of methods to investigate network dynamics has led to '\n",
      "             'discussion of whether somatosensory inputs are processed in '\n",
      "             'serial or in parallel. Both hypotheses are supported by DCM '\n",
      "             'analyses of fMRI studies. In the present study, we revisited '\n",
      "             'this controversy using DCM on magnetoencephalographic (MEG) data '\n",
      "             'during so- matosensory stimulation. Bayesian model comparison '\n",
      "             'was used to allow for direct inference on the processing stream. '\n",
      "             'Additionally we varied the duration of the time-window of '\n",
      "             'analyzed data after the somatosensory stim- ulus. This approach '\n",
      "             'allowed us to explore time dependent changes in the processing '\n",
      "             'stream of somatosensory information and to evaluate the '\n",
      "             'consistency of results. We found that models favoring a parallel '\n",
      "             'processing route best describe neural activities elicited by '\n",
      "             'somatosensory stimuli. This result was consistent for different '\n",
      "             'time-windows. Although it is assumed that the majority of '\n",
      "             'somatosensory information is delivered to the SI, the current '\n",
      "             'results indicate that at least a small part of somatosensory '\n",
      "             'information is delivered in parallel to the SII. These ﬁndings '\n",
      "             'emphasize the importance of data analysis with high temporal '\n",
      "             'resolution. © 2015 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['MEG',\n",
      "              'DCM',\n",
      "              'Somatosensory cortex',\n",
      "              'Effective connectivity',\n",
      "              'Perception'],\n",
      " 'title': 'Parallel processing of somatosensory information: Evidence from '\n",
      "          'dynamic causal modeling of MEG data'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811915006205-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'It is a principal open question whether noninvasive imaging '\n",
      "             'methods in humans can decode information encoded at a spatial '\n",
      "             'scale as ﬁne as the basic functional unit of cortex: cortical '\n",
      "             'columns. We addressed this question in ﬁve '\n",
      "             'magnetoencephalography (MEG) experiments by investigating a '\n",
      "             'columnar-level encoded visual feature: contrast edge '\n",
      "             'orientation. We found that MEG signals contained '\n",
      "             'orientation-speciﬁc information as early as approximately 50 ms '\n",
      "             'after stimulus onset even when controlling for confounds, such '\n",
      "             'as overrepresentation of particular orientations, stimulus edge '\n",
      "             'interactions, and global form-related signals. Theoretical '\n",
      "             'modeling con- ﬁrmed the plausibility of this empirical result. '\n",
      "             'An essential consequence of our results is that information '\n",
      "             'encoded in the human brain at the level of cortical columns '\n",
      "             'should in general be accessible by multivariate anal- ysis of '\n",
      "             'electrophysiological signals.',\n",
      " 'keywords': ['Orientation encoding',\n",
      "              'Magnetoencephalography',\n",
      "              'Multivariate pattern analysis',\n",
      "              'Cortical columns'],\n",
      " 'title': 'Can visual information encoded in cortical columns be decoded from '\n",
      "          'magnetoencephalography data in humans?'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916000124-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Object perception involves a range of visual and cognitive '\n",
      "             'processes, and is known to include both a feedfoward ﬂow of '\n",
      "             'information from early visual cortical areas to higher cortical '\n",
      "             'areas, along with feedback from areas such as prefrontal cortex. '\n",
      "             'Previous studies have found that low and high spatial frequency '\n",
      "             'information regarding ob- ject identity may be processed over '\n",
      "             'different timescales. Here we used the high temporal resolution '\n",
      "             'of magneto- encephalography (MEG) combined with multivariate '\n",
      "             'pattern analysis to measure information speciﬁcally related to '\n",
      "             'object identity in peri-frontal and peri-occipital areas. Using '\n",
      "             'stimuli closely matched in their low- level visual content, we '\n",
      "             'found that activity in peri-occipital cortex could be used to '\n",
      "             'decode object identity from ~ 80 ms post stimulus onset, and '\n",
      "             'activity in peri-frontal cortex could also be used to decode '\n",
      "             'object identity from a later time (~ 265 ms post stimulus '\n",
      "             'onset). Low spatial frequency information related to object '\n",
      "             'identity was present in the MEG signal at an earlier time than '\n",
      "             'high spatial frequency information for peri-occipital cortex, '\n",
      "             'but not for peri-frontal cortex. We additionally used Granger '\n",
      "             'causality analysis to compare feedforward and feed- back '\n",
      "             'inﬂuences on representational content, and found evidence of '\n",
      "             'both an early feedfoward ﬂow and later feed- back ﬂow of '\n",
      "             'information related to object identity. We discuss our ﬁndings '\n",
      "             'in relation to existing theories of object processing and '\n",
      "             'propose how the methods we use here could be used to address '\n",
      "             'further questions of the neural substrates underlying object '\n",
      "             'perception.',\n",
      " 'keywords': ['Magnetoencephalography',\n",
      "              'Pattern classiﬁer analysis',\n",
      "              'Feedback',\n",
      "              'Coarse-to-ﬁne',\n",
      "              'Granger causality',\n",
      "              'Visual perception'],\n",
      " 'title': 'Representational dynamics of object recognition: Feedforward and '\n",
      "          'feedback information flows'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916001269-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Perceptual similarity is a cognitive judgment that represents '\n",
      "             'the end-stage of a complex cascade of hierarchical processing '\n",
      "             'throughout visual cortex. Previous studies have shown a '\n",
      "             'correspondence between the similarity of coarse-scale fMRI '\n",
      "             'activation patterns and the perceived similarity of visual '\n",
      "             'stimuli, suggesting that visual objects that appear similar also '\n",
      "             'share similar underlying patterns of neural activation. Here we '\n",
      "             \"explore the temporal re- lationship between the human brain's \"\n",
      "             'time-varying representation of visual patterns and behavioral '\n",
      "             'judgments of perceptual similarity. The visual stimuli were '\n",
      "             'abstract patterns constructed from identical perceptual units '\n",
      "             '(oriented Gabor patches) so that each pattern had a unique '\n",
      "             'global form or perceptual ‘Gestalt’. The visual stimuli were '\n",
      "             'decodable from evoked neural activation patterns measured with '\n",
      "             'magnetoencephalography (MEG), how- ever, stimuli differed in the '\n",
      "             'similarity of their neural representation as estimated by '\n",
      "             'differences in decodability. Early after stimulus onset (from 50 '\n",
      "             'ms), a model based on retinotopic organization predicted the '\n",
      "             'representation- al similarity of the visual stimuli. Following '\n",
      "             'the peak correlation between the retinotopic model and neural '\n",
      "             'data at 80 ms, the neural representations quickly evolved so '\n",
      "             'that retinotopy no longer provided a sufﬁcient account of the '\n",
      "             \"brain's time-varying representation of the stimuli. Overall the \"\n",
      "             \"strongest predictor of the brain's representa- tion was a model \"\n",
      "             'based on human judgments of perceptual similarity, which reached '\n",
      "             'the limits of the maximum correlation with the neural data '\n",
      "             'deﬁned by the ‘noise ceiling’. Our results show that large-scale '\n",
      "             'brain activation patterns contain a neural signature for the '\n",
      "             'perceptual Gestalt of composite visual features, and demonstrate '\n",
      "             'a strong correspondence between perception and complex patterns '\n",
      "             'of brain activity. © 2016 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['Magnetoencephalography (MEG)',\n",
      "              'Representational similarity analysis',\n",
      "              'Perceptual similarity',\n",
      "              'Representational geometry',\n",
      "              'Decoding',\n",
      "              'Gestalt perception'],\n",
      " 'title': 'Perceptual similarity of visual patterns predicts dynamic neural '\n",
      "          'activation patterns measured with MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916300076-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Human scene recognition is a rapid multistep process evolving '\n",
      "             'over time from single scene image to spatial layout processing. '\n",
      "             'We used multivariate pattern analyses on magnetoencephalography '\n",
      "             '(MEG) data to unravel the time course of this cortical process. '\n",
      "             'Following an early signal for lower-level visual analysis of '\n",
      "             'single scenes at ~100 ms, we found a marker of real-world scene '\n",
      "             'size, i.e. spatial layout processing, at ~250 ms indexing neural '\n",
      "             'representations robust to changes in unrelated scene properties '\n",
      "             'and viewing conditions. For a quantitative model of how scene '\n",
      "             'size representations may arise in the brain, we compared MEG '\n",
      "             'data to a deep neural network model trained on scene '\n",
      "             'classiﬁcation. Representations of scene size emerged '\n",
      "             'intrinsically in the model, and resolved emerging neural scene '\n",
      "             'size representation. Together our data provide a ﬁrst '\n",
      "             'description of an electrophysiological signal for layout '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             'processing in humans, and suggest that deep neural networks are '\n",
      "             'a promising framework to investigate how spatial layout '\n",
      "             'representations emerge in the human brain.',\n",
      " 'keywords': ['Scene perception',\n",
      "              'Spatial layout',\n",
      "              'Magnetoencephalography',\n",
      "              'Deep neural network',\n",
      "              'Representational similarity analysis'],\n",
      " 'title': 'Dynamics of scene representations in the human brain revealed by '\n",
      "          'magnetoencephalography and deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916301914-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'MEG offers dynamic and spectral resolution for resting-state '\n",
      "             'connectivity which is unavailable in fMRI. However, there are a '\n",
      "             'wide range of available network estimation methods for MEG, and '\n",
      "             'little in the way of existing guid- ance on which ones to '\n",
      "             'employ. In this technical note, we investigate the extent to '\n",
      "             'which many popular measures of stationary connectivity are '\n",
      "             'suitable for use in resting-state MEG, localising magnetic '\n",
      "             'sources with a scalar beamformer. We use as empirical criteria '\n",
      "             'that network measures for individual subjects should be '\n",
      "             'repeatable, and that group-level connectivity estimation shows '\n",
      "             'good reproducibility. Using publically-available data from the '\n",
      "             'Human Connectome Project, we test the reliability of 12 network '\n",
      "             'estimation techniques against these criteria. We ﬁnd that the '\n",
      "             'impact of magnetic ﬁeld spread or spatial leakage artefact is '\n",
      "             'profound, creates a major confound for many connectivity '\n",
      "             'measures, and can artiﬁcially inﬂate measures of consistency. '\n",
      "             'Among those robust to this effect, we ﬁnd poor test-retest '\n",
      "             'reliability in phase- or coherence-based metrics such as the '\n",
      "             'phase lag index or the imaginary part of coherency. The most '\n",
      "             'consistent methods for stationary connectivity estimation over '\n",
      "             'all of our tests are simple amplitude envelope correlation and '\n",
      "             'partial correlation measures. © 2016 The Authors. Published by '\n",
      "             'Elsevier Inc. This is an open access article under the CC BY '\n",
      "             'license (http://creativecommons.org/licenses/by/4.0/).',\n",
      " 'keywords': ['MEG',\n",
      "              'Source leakage',\n",
      "              'Magnetic ﬁeld spread',\n",
      "              'Functional connectivity',\n",
      "              'Network analysis',\n",
      "              'Connectome'],\n",
      " 'title': 'How reliable are MEG resting-state connectivity metrics?'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811916306802-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n",
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n",
      "WARNING:pdfminer.converter:undefined: <PDFCIDFont: basefont='NBJCGE+MT-Extra', cidcoding='Adobe-Identity'>, 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'The study of functional connectivity using '\n",
      "             'magnetoencephalography (MEG) is an expanding area of '\n",
      "             'neuroimaging, and adds an extra dimension to the more common '\n",
      "             'assessments made using fMRI. The importance of such metrics is '\n",
      "             'growing, with recent demonstrations of their utility in clinical '\n",
      "             'research, however previous reports suggest that whilst group '\n",
      "             'level resting state connectivity is robust, single session '\n",
      "             'recordings lack repeatability. Such robustness is critical if '\n",
      "             'MEG measures in individual subjects are to prove clinically '\n",
      "             'valuable. In the present paper, we test how practical aspects of '\n",
      "             'experimental design aﬀect the intra-subject repeatability of MEG '\n",
      "             'ﬁndings; speciﬁcally we assess the eﬀect of co-registration '\n",
      "             'method and data recording duration. We show that the use of a '\n",
      "             'foam head-cast, which is known to improve co-registration '\n",
      "             'accuracy, increased signiﬁcantly the between session '\n",
      "             'repeatability of both beamformer reconstruction and connectivity '\n",
      "             'estimation. We also show that recording duration is a critical '\n",
      "             'parameter, with large improvements in repeatability apparent '\n",
      "             'when using ten minute, compared to ﬁve minute recordings. '\n",
      "             'Further analyses suggest that the origin of this latter eﬀect is '\n",
      "             'not underpinned by technical aspects of source reconstruction, '\n",
      "             'but rather by a genuine eﬀect of brain state; short recordings '\n",
      "             'are simply ineﬃcient at capturing the canonical MEG network in a '\n",
      "             'single subject. Our results provide important insights on '\n",
      "             'experimental design and will prove valuable for future MEG '\n",
      "             'connectivity studies.',\n",
      " 'keywords': ['Functional connectivity',\n",
      "              'Networks',\n",
      "              'Magnetoencephalography',\n",
      "              'MEG',\n",
      "              'Resting state',\n",
      "              'Beamformer'],\n",
      " 'title': 'Optimising experimental design for MEG resting state functional '\n",
      "          'connectivity measurement'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917302458-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'A long-standing core question in cognitive science is whether '\n",
      "             'diﬀerent modalities and representation types (pictures, words, '\n",
      "             'sounds, etc.) access a common store of semantic information. '\n",
      "             'Although diﬀerent input types have been shown to activate a '\n",
      "             'shared network of brain regions, this does not necessitate that '\n",
      "             'there is a common representation, as the neurons in these '\n",
      "             'regions could still diﬀerentially process the diﬀerent '\n",
      "             'modalities. However, multi-voxel pattern analysis can be used to '\n",
      "             'assess whether, e.g., pictures and words evoke a similar pattern '\n",
      "             'of activity, such that the patterns that separate categories in '\n",
      "             'one modality transfer to the other. Prior work using this method '\n",
      "             'has found support for a common code, but has two limitations: '\n",
      "             'they have either only examined disparate categories (e.g. '\n",
      "             'animals vs. tools) that are known to activate diﬀerent brain '\n",
      "             'regions, raising the possibility that the pattern separation and '\n",
      "             'inferred similarity reﬂects only large scale diﬀerences between '\n",
      "             'the categories or they have been limited to individual object '\n",
      "             'representations. By using natural scene categories, we not only '\n",
      "             'extend the current literature on cross-modal representations '\n",
      "             'beyond objects, but also, because natural scene categories '\n",
      "             'activate a common set of brain regions, we identify a more '\n",
      "             'ﬁne-grained (i.e. higher spatial resolution) common '\n",
      "             'representation. Speciﬁcally, we studied picture- and word-based '\n",
      "             'representations of natural scene stimuli from four diﬀerent '\n",
      "             'categories: beaches, cities, highways, and mountains. '\n",
      "             'Participants passively viewed blocks of either phrases (e.g. '\n",
      "             '\"sandy beach\") describing scenes or photographs from those same '\n",
      "             'scene categories. To determine whether the phrases and pictures '\n",
      "             'evoke a common code, we asked whether a classiﬁer trained on one '\n",
      "             'stimulus type (e.g. phrase stimuli) would transfer (i.e. '\n",
      "             'cross-decode) to the other stimulus type (e.g. picture stimuli). '\n",
      "             'The analysis revealed cross-decoding in the occipitotemporal, '\n",
      "             'posterior parietal and frontal cortices. This similarity of '\n",
      "             'neural activity patterns across the two input types, for '\n",
      "             'categories that co- activate local brain regions, provides '\n",
      "             'strong evidence of a common semantic code for pictures and words '\n",
      "             'in the brain.',\n",
      " 'keywords': ['Natural scenes',\n",
      "              'Semantics',\n",
      "              'Pictures',\n",
      "              'Words',\n",
      "              'MVPA',\n",
      "              'fMRI'],\n",
      " 'title': 'Evidence for similar patterns of neural activity elicited by '\n",
      "          'picture- and word-based representations of natural scenes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917305906-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual gamma oscillations have been proposed to subserve '\n",
      "             'perceptual binding, but their strong modulation by diverse '\n",
      "             'stimulus features confounds interpretations of their precise '\n",
      "             'functional role. Overcoming this challenge necessitates a '\n",
      "             'comprehensive account of the relationship between gamma '\n",
      "             'responses and stimulus features. Here we used multivariate '\n",
      "             'pattern analyses on human MEG data to characterize the '\n",
      "             'relationships between gamma responses and one basic stimulus '\n",
      "             'feature, the orientation of contrast edges. Our ﬁndings conﬁrmed '\n",
      "             'we could decode orientation information from induced responses '\n",
      "             'in two dominant frequency bands at 24–32 Hz and 50–58 Hz. '\n",
      "             'Decoding was higher for cardinal than oblique orientations, with '\n",
      "             'similar results also obtained for evoked MEG responses. In '\n",
      "             'contrast to multivariate analyses, orientation information was '\n",
      "             'mostly absent in uni- variate signals: evoked and induced '\n",
      "             'responses in early visual cortex were similar in all '\n",
      "             'orientations, with only exception an inverse oblique effect '\n",
      "             'observed in induced responses, such that cardinal orientations '\n",
      "             'produced weaker oscillatory signals than oblique orientations. '\n",
      "             'Taken together, our results showed multivariate methods are well '\n",
      "             'suited for the analysis of gamma oscillations, with multivariate '\n",
      "             'patterns robustly encoding orientation in- formation and '\n",
      "             'predominantly discriminating cardinal from oblique stimuli.',\n",
      " 'keywords': ['Orientation',\n",
      "              'Gratings',\n",
      "              'Gamma oscillations',\n",
      "              'Oblique effect',\n",
      "              'MEG',\n",
      "              'Multivariate analysis',\n",
      "              'Pattern classiﬁcation',\n",
      "              'Representational similarity analysis',\n",
      "              'Feature binding'],\n",
      " 'title': 'Decoding the orientation of contrast edges from MEG evoked and '\n",
      "          'induced responses'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917306523-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate decoding methods were developed originally as tools '\n",
      "             'to enable accurate predictions in real-world applications. The '\n",
      "             'realization that these methods can also be employed to study '\n",
      "             'brain function has led to their widespread adoption in the '\n",
      "             'neurosciences. However, prior to the rise of multivariate '\n",
      "             'decoding, the study of brain function was ﬁrmly embedded in a '\n",
      "             'statistical philosophy grounded on univariate methods of data '\n",
      "             'analysis. In this way, multivariate decoding for brain '\n",
      "             'interpretation grew out of two established frameworks: '\n",
      "             'multivariate decoding for predictions in real-world '\n",
      "             'applications, and classical univariate analysis based on the '\n",
      "             'study and interpretation of brain activation. We argue that this '\n",
      "             'led to two confusions, one reﬂecting a mixture of multi- variate '\n",
      "             'decoding for prediction or interpretation, and the other a '\n",
      "             'mixture of the conceptual and statistical phi- losophies '\n",
      "             'underlying multivariate decoding and classical univariate '\n",
      "             'analysis. Here we attempt to systematically disambiguate '\n",
      "             'multivariate decoding for the study of brain function from the '\n",
      "             'frameworks it grew out of. After elaborating these confusions '\n",
      "             'and their consequences, we describe six, often unappreciated, '\n",
      "             'differences between classical univariate analysis and '\n",
      "             'multivariate decoding. We then focus on how the common '\n",
      "             'interpretation of what is signal and noise changes in '\n",
      "             'multivariate decoding. Finally, we use four examples to '\n",
      "             'illustrate where these confusions may impact the interpretation '\n",
      "             'of neuroimaging data. We conclude with a discussion of potential '\n",
      "             'strategies to help resolve these confusions in interpreting '\n",
      "             'multivariate decoding results, including the potential departure '\n",
      "             'from multivariate decoding methods for the study of brain '\n",
      "             'function.',\n",
      " 'keywords': ['Multivariate decoding',\n",
      "              'Multivariate analysis',\n",
      "              'Multivariate pattern analysis',\n",
      "              'Encoding',\n",
      "              'Decoding',\n",
      "              'fMRI',\n",
      "              'Prediction'],\n",
      " 'title': 'Deconstructing multivariate decoding for the study of brain '\n",
      "          'function'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917306638-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The goal of cognitive neuroscience is to understand how mental '\n",
      "             'operations are performed by the brain. Given the complexity of '\n",
      "             'the brain, this is a challenging endeavor that requires the '\n",
      "             'development of formal models. Here, I provide a perspective on '\n",
      "             'models of neural information processing in cognitive '\n",
      "             'neuroscience. I deﬁne what these models are, explain why they '\n",
      "             'are useful, and specify criteria for evaluating models. I also '\n",
      "             'highlight the difference between functional and mechanistic '\n",
      "             'models, and call attention to the value that neuroanatomy has '\n",
      "             'for understanding brain function. Based on the principles I '\n",
      "             'propose, I proceed to evaluate the merit of recently touted deep '\n",
      "             'neural network models. I contend that these models are '\n",
      "             'promising, but substantial work is necessary (i) to clarify what '\n",
      "             'type of explanation these models provide, (ii) to determine what '\n",
      "             'speciﬁc effects they accurately explain, and (iii) to improve '\n",
      "             'our understanding of how they work.',\n",
      " 'keywords': [],\n",
      " 'title': 'Principles for models of neural information processing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S105381191730664X-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Natural visual scenes induce rich perceptual experiences that '\n",
      "             'are highly diverse from scene to scene and from person to '\n",
      "             'person. Here, we propose a new framework for decoding such '\n",
      "             'experiences using a distributed repre- sentation of words. We '\n",
      "             'used functional magnetic resonance imaging (fMRI) to measure '\n",
      "             'brain activity evoked by natural movie scenes. Then, we '\n",
      "             'constructed a high-dimensional feature space of perceptual '\n",
      "             'experiences using skip-gram, a state-of-the-art distributed word '\n",
      "             'embedding model. We built a decoder that associates brain '\n",
      "             'activity with perceptual experiences via the distributed word '\n",
      "             'representation. The decoder successfully estimated perceptual '\n",
      "             'contents consistent with the scene descriptions by multiple '\n",
      "             'annotators. Our results illustrate three advantages of our '\n",
      "             'decoding framework: (1) three types of perceptual contents could '\n",
      "             'be decoded in the form of nouns (objects), verbs (actions), and '\n",
      "             'adjectives (impressions) contained in 10,000 vocabulary words; '\n",
      "             '(2) despite using such a large vocabulary, we could decode novel '\n",
      "             'words that were absent in the datasets to train the decoder; and '\n",
      "             '(3) the inter-individual variability of the decoded contents '\n",
      "             'co-varied with that of the contents of scene de- scriptions. '\n",
      "             'These ﬁndings suggest that our decoding framework can recover '\n",
      "             'diverse aspects of perceptual expe- riences in naturalistic '\n",
      "             'situations and could be useful in various scientiﬁc and '\n",
      "             'practical applications.',\n",
      " 'keywords': ['Decoding',\n",
      "              'Semantic perception',\n",
      "              'Natural language processing',\n",
      "              'Humans',\n",
      "              'fMRI',\n",
      "              'Natural vision'],\n",
      " 'title': 'Decoding naturalistic experiences from human brain activity via '\n",
      "          'distributed representations of words'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917307474-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'There is growing interest in the rich temporal and spectral '\n",
      "             'properties of the functional connectome of the brain that are '\n",
      "             'provided by Electro- and Magnetoencephalography (EEG/MEG). '\n",
      "             'However, the problem of leakage be- tween brain sources that '\n",
      "             'arises when reconstructing brain activity from EEG/MEG '\n",
      "             'recordings outside the head makes it difﬁcult to distinguish '\n",
      "             'true connections from spurious connections, even when '\n",
      "             'connections are based on measures that ignore zero-lag '\n",
      "             'dependencies. In particular, standard anatomical parcellations '\n",
      "             'for potential cortical sources tend to over- or under-sample the '\n",
      "             'real spatial resolution of EEG/MEG. By using information from '\n",
      "             'cross- talk functions (CTFs) that objectively describe leakage '\n",
      "             'for a given sensor conﬁguration and distributed source '\n",
      "             'reconstruction method, we introduce methods for optimising the '\n",
      "             'number of parcels while simultaneously mini- mising the leakage '\n",
      "             'between them. More speciﬁcally, we compare two image '\n",
      "             'segmentation algorithms: 1) a split- and-merge (SaM) algorithm '\n",
      "             'based on standard anatomical parcellations and 2) a region '\n",
      "             'growing (RG) algorithm based on all the brain vertices with no '\n",
      "             'prior parcellation. Interestingly, when applied to minimum-norm '\n",
      "             're- constructions for EEG/MEG conﬁgurations from real data, both '\n",
      "             'algorithms yielded approximately 70 parcels despite their '\n",
      "             'different starting points, suggesting that this reﬂects the '\n",
      "             'resolution limit of this particular sensor conﬁguration and '\n",
      "             'reconstruction method. Importantly, when compared against '\n",
      "             'standard anatomical parcella- tions, resolution matrices of '\n",
      "             'adaptive parcellations showed notably higher sensitivity and '\n",
      "             'distinguishability of parcels. Furthermore, extensive '\n",
      "             'simulations of realistic networks revealed signiﬁcant '\n",
      "             'improvements in network reconstruction accuracies, particularly '\n",
      "             'in reducing false leakage-induced connections. Adaptive '\n",
      "             'parcellations therefore allow a more accurate reconstruction of '\n",
      "             'functional EEG/MEG connectomes.',\n",
      " 'keywords': ['Adaptive parcellation',\n",
      "              'Functional connectome',\n",
      "              'MEG/EEG',\n",
      "              'Cross-talk functions',\n",
      "              'Source reconstruction',\n",
      "              'Whole-brain connectivity'],\n",
      " 'title': 'Adaptive cortical parcellations for source reconstructed EEG/MEG '\n",
      "          'connectomes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917307942-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) of fMRI data has allowed '\n",
      "             'the investigation of neural representations of stimuli on the '\n",
      "             'basis of distributed patterns of activity within a brain region, '\n",
      "             'independently from overall brain activity. For instance, several '\n",
      "             'studies on early visual cortex have reported reliable MVPA '\n",
      "             'decoding of the identity of a stimulus representation that was '\n",
      "             'kept in working memory or internally generated, despite the fact '\n",
      "             'that the overall BOLD response was low or even at baseline '\n",
      "             'levels. Here we ask how it is possible that reliable stimulus '\n",
      "             'information can be decoded from early visual cortex even when '\n",
      "             'the overall BOLD signal remains low. We reanalyzed a data set in '\n",
      "             'which human participants (N ¼ 24) imagined or kept in working '\n",
      "             'memory an oriented visual grating. We divided voxels from V1, '\n",
      "             'V2, and V3 into groups based on orientation preference, and '\n",
      "             'compared the time course of mean BOLD responses to preferred and '\n",
      "             'non-preferred orientations with the time course of the '\n",
      "             'multivariate decoding performance. Decoding accuracy related to '\n",
      "             'a numerically small, but reliable univariate difference in the '\n",
      "             'mean BOLD response to preferred and non-preferred stimuli. The '\n",
      "             'time course of the difference in BOLD responses to preferred and '\n",
      "             'non- preferred orientations was highly similar to the time '\n",
      "             'course of the multivariate pattern classiﬁcation accuracy. The '\n",
      "             'reliability of the classiﬁcation strongly correlated with the '\n",
      "             'magnitude of differences in BOLD signal between preferred and '\n",
      "             'non-preferred stimuli. These activity differences were small '\n",
      "             'compared to the large overall BOLD modulations. This suggests '\n",
      "             'that a substantial part of the task-related BOLD response to '\n",
      "             'visual stimulation might not be stimulus-speciﬁc. Rather, '\n",
      "             'stimulus-evoked BOLD signals in early visual cortex during a '\n",
      "             'task context may be an amalgam of small stimulus-speciﬁc '\n",
      "             'responses and large task-related but non-stimulus-speciﬁc '\n",
      "             'responses. The latter are not evident during the maintenance or '\n",
      "             'internal generation of stimulus representations, but provide an '\n",
      "             'explanation of how reliable stimulus information can be decoded '\n",
      "             'from early visual cortex even though its overall BOLD signal '\n",
      "             'remains low.',\n",
      " 'keywords': ['BOLD activity',\n",
      "              'MVPA decoding',\n",
      "              'Early visual cortex',\n",
      "              'Orientation speciﬁcity'],\n",
      " 'title': 'Decoupling of BOLD amplitude and pattern classification of '\n",
      "          'orientation-selective activity in human visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811917311023-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Outlook on deep neural networks in computational cognitive '\n",
      "          'neuroscience'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918300442-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'We propose a new method for the localization of nonlinear '\n",
      "             'cross-frequency coupling in EEG and MEG data analysis, based on '\n",
      "             'the estimation of bicoherences at the source level. While for '\n",
      "             'the analysis of rhythmic brain activity, source directions are '\n",
      "             'commonly chosen to maximize power, we suggest to maximize '\n",
      "             'bicoherence instead. The resulting nonlinear cost function can '\n",
      "             'be minimized effectively using a gradient approach. We argue, '\n",
      "             'that bicoherence is also a generally useful tool to analyze '\n",
      "             'phase-amplitude coupling (PAC), by deriving formal relations '\n",
      "             'between PAC and bispectra. This is illustrated in simulated and '\n",
      "             'empirical LFP data. The localization method is applied to EEG '\n",
      "             'resting state data, where the most prominent bicoherence '\n",
      "             'signatures originate from the occipital alpha rhythm and the mu '\n",
      "             'rhythm. While the latter is hardly visible using power analysis, '\n",
      "             'we observe clear bicoherence peaks in the high alpha range of '\n",
      "             'sensorymotor areas. We additionally apply our method to '\n",
      "             'resting-state data of subjects with schizophrenia and healthy '\n",
      "             'controls and observe signiﬁcant bicoherence differences in motor '\n",
      "             'areas which could not be found from analyzing power differences.',\n",
      " 'keywords': [],\n",
      " 'title': 'Localizing bicoherence from EEG and MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918300624-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Retrieval orientations are memory states that bias retrieval '\n",
      "             'towards speciﬁc memory contents. Many neuro- imaging studies '\n",
      "             'have examined the inﬂuence of retrieval orientations on stimulus '\n",
      "             'processing, but very little direct evidence exists regarding the '\n",
      "             'ongoing maintenance of orientations themselves. Participants '\n",
      "             'completed two memory tasks with different retrieval goals. ERPs '\n",
      "             'were time-locked to a pre-stimulus ﬁxation asterisk and con- '\n",
      "             'trasted according to retrieval goals. Pre-stimulus ERPs elicited '\n",
      "             'during the two retrieval tasks diverged at frontal electrode '\n",
      "             'sites. These differences onset early and were sustained '\n",
      "             'throughout the ﬁxation-stimulus interval. The functional and '\n",
      "             'spatiotemporal characteristics of this ERP effect comprise the '\n",
      "             'ﬁrst direct electrophysiological evidence of the ongoing '\n",
      "             'maintenance of retrieval orientations throughout a task. '\n",
      "             'Moreover, this effect was eliminated in participants who '\n",
      "             'performed a stroop task prior to the memory tests, indicating '\n",
      "             'that reserves of cognitive control play an important role in the '\n",
      "             'maintenance of retrieval orientations throughout memory tasks.',\n",
      " 'keywords': ['Retrieval orientation',\n",
      "              'Episodic memory',\n",
      "              'Cognitive control',\n",
      "              'Post-retrieval processing',\n",
      "              'Event-related potential',\n",
      "              'Electrophysiology'],\n",
      " 'title': 'Direct electrophysiological evidence for the maintenance of '\n",
      "          'retrieval orientations and the role of cognitive control'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918301411-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) methods such as decoding '\n",
      "             'and representational similarity analysis (RSA) are growing '\n",
      "             'rapidly in popularity for the analysis of magnetoencephalography '\n",
      "             '(MEG) data. However, little is known about the relative '\n",
      "             'performance and characteristics of the speciﬁc dissimilarity '\n",
      "             'measures used to describe differ- ences between evoked '\n",
      "             'activation patterns. Here we used a multisession MEG data set to '\n",
      "             'qualitatively characterize a range of dissimilarity measures and '\n",
      "             'to quantitatively compare them with respect to decoding accuracy '\n",
      "             '(for decoding) and between-session reliability of '\n",
      "             'representational dissimilarity matrices (for RSA). We tested '\n",
      "             'dissimilarity measures from a range of classiﬁers (Linear '\n",
      "             'Discriminant Analysis – LDA, Support Vector Machine – SVM, '\n",
      "             'Weighted Robust Distance – WeiRD, Gaussian Naïve Bayes – GNB) '\n",
      "             'and distances (Euclidean distance, Pearson correlation). In '\n",
      "             'addition, we evaluated three key processing choices: 1) '\n",
      "             'preprocessing (noise normal- isation, removal of the pattern '\n",
      "             'mean), 2) weighting decoding accuracies by decision values, and '\n",
      "             '3) computing distances in three different partitioning schemes '\n",
      "             '(non-cross-validated, cross-validated, within-class-corrected). '\n",
      "             'Four main conclusions emerged from our results. First, '\n",
      "             'appropriate multivariate noise normalization substantially '\n",
      "             'improved decoding accuracies and the reliability of '\n",
      "             'dissimilarity measures. Second, LDA, SVM and WeiRD yielded high '\n",
      "             'peak decoding accuracies and nearly identical time courses. '\n",
      "             'Third, while using decoding accuracies for RSA was markedly less '\n",
      "             'reliable than continuous distances, this disadvantage was '\n",
      "             'ameliorated by decision-value- weighting of decoding accuracies. '\n",
      "             'Fourth, the cross-validated Euclidean distance provided unbiased '\n",
      "             'distance estimates and highly replicable representational '\n",
      "             'dissimilarity matrices. Overall, we strongly advise the use of '\n",
      "             'multivariate noise normalisation as a general preprocessing '\n",
      "             'step, recommend LDA, SVM and WeiRD as classiﬁers for decoding '\n",
      "             'and highlight the cross-validated Euclidean distance as a '\n",
      "             'reliable and unbiased default choice for RSA.',\n",
      " 'keywords': ['MEG',\n",
      "              'EEG',\n",
      "              'Multi-voxel pattern analysis',\n",
      "              'Decoding',\n",
      "              'Representational similarity analysis',\n",
      "              'Cross-validation',\n",
      "              'Noise normalisation',\n",
      "              'Machine learning'],\n",
      " 'title': 'Multivariate pattern analysis for MEG: A comparison of '\n",
      "          'dissimilarity measures'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918301423-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Movie viewing allows human perception and cognition to be '\n",
      "             'studied in complex, real-life-like situations in a brain-imaging '\n",
      "             'laboratory. Previous studies with functional magnetic resonance '\n",
      "             'imaging (fMRI) and with magneto- and electroencephalography (MEG '\n",
      "             'and EEG) have demonstrated consistent temporal dynamics of brain '\n",
      "             'activity across movie viewers. However, little is known about '\n",
      "             'the similarities and differences of fMRI and MEG or EEG dynamics '\n",
      "             'during such naturalistic situations. We thus compared MEG and '\n",
      "             'fMRI responses to the same 15-min black-and-white movie in the '\n",
      "             'same eight subjects who watched the movie twice during both MEG '\n",
      "             'and fMRI recordings. We analyzed intra- and intersubject '\n",
      "             'voxel-wise correlations within each imaging modality as well as '\n",
      "             'the correlation of the MEG envelopes and fMRI signals. The fMRI '\n",
      "             'signals showed voxel-wise within- and between-subjects '\n",
      "             'correlations up to r ¼ 0.66 and r ¼ 0.37, respectively, whereas '\n",
      "             'these correlations were clearly weaker for the envelopes of '\n",
      "             'band-pass ﬁltered (7 frequency bands below 100 Hz) MEG signals '\n",
      "             '(within-subjects correlation r < 0.14 and between-subjects r < '\n",
      "             '0.05). Direct MEG–fMRI voxel-wise correlations were unreliable. '\n",
      "             'Notably, applying a spatial-ﬁltering approach to the MEG data '\n",
      "             'uncovered consistent canonical variates that showed considerably '\n",
      "             'stronger (up to r ¼ 0.25) between- subjects correlations than '\n",
      "             'the univariate voxel-wise analysis. Furthermore, the envelopes '\n",
      "             'of the time courses of these variates up to about 10 Hz showed '\n",
      "             'association with fMRI signals in a general linear model. '\n",
      "             'Similarities between envelopes of MEG canonical variates and '\n",
      "             'fMRI voxel time-courses were seen mostly in occipital, but also '\n",
      "             'in temporal and frontal brain regions, whereas intra- and '\n",
      "             'intersubject correlations for MEG and fMRI separately were '\n",
      "             'strongest only in the occipital areas. In contrast to the '\n",
      "             'conventional univariate analysis, the spatial-ﬁltering approach '\n",
      "             'was able to uncover associ- ations between the MEG envelopes and '\n",
      "             'fMRI time courses, shedding light on the similarities of '\n",
      "             'hemodynamic and electromagnetic brain activities during movie '\n",
      "             'viewing.',\n",
      " 'keywords': ['Magnetoencephalography',\n",
      "              'Functional magnetic resonance imaging',\n",
      "              'Naturalistic stimulation',\n",
      "              'Movie',\n",
      "              'Intersubject correlation',\n",
      "              'Canonical correlation analysis'],\n",
      " 'title': 'Consistency and similarity of MEG- and fMRI-signal time courses '\n",
      "          'during movie viewing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918304440-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual object representations are commonly thought to emerge '\n",
      "             'rapidly, yet it has remained unclear to what extent early brain '\n",
      "             'responses reﬂect purely low-level visual features of these '\n",
      "             'objects and how strongly those features contribute to later '\n",
      "             'categorical or conceptual representations. Here, we aimed to '\n",
      "             'estimate a lower temporal bound for the emergence of conceptual '\n",
      "             'representations by deﬁning two criteria that characterize such '\n",
      "             'representations: 1) conceptual object representations should '\n",
      "             'generalize across different exemplars of the same object, and 2) '\n",
      "             'these representations should reﬂect high-level behavioral '\n",
      "             'judgments. To test these criteria, we compared '\n",
      "             'magnetoencephalography (MEG) recordings between two groups of '\n",
      "             'participants (n ¼ 16 per group) exposed to different exemplar '\n",
      "             'images of the same object concepts. Further, we disentangled '\n",
      "             'low-level from high-level MEG responses by estimating the unique '\n",
      "             'and shared contribution of models of behavioral judgments, '\n",
      "             'semantics, and different layers of deep neural networks of '\n",
      "             'visual object processing. We ﬁnd that 1) both generalization '\n",
      "             'across exemplars as well as generalization of object-related '\n",
      "             'signals across time increase after 150 ms, peaking around 230 '\n",
      "             'ms; 2) representations speciﬁc to behavioral judgments emerged '\n",
      "             'rapidly, peaking around 160 ms. Collectively, these results '\n",
      "             'suggest a lower bound for the emergence of conceptual object '\n",
      "             'representations around 150 ms following stimulus onset.',\n",
      " 'keywords': [],\n",
      " 'title': 'The temporal evolution of conceptual object representations '\n",
      "          'revealed through models of behavior, semantics and deep neural '\n",
      "          'networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305226-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Recent advances in multivariate fMRI analysis stress the '\n",
      "             'importance of information inherent to voxel patterns. Key to '\n",
      "             'interpreting these patterns is estimating the underlying '\n",
      "             'dimensionality of neural representations. Dimensions may '\n",
      "             'correspond to psychological dimensions, such as length and '\n",
      "             'orientation, or involve other coding schemes. Unfortunately, the '\n",
      "             'noise structure of fMRI data inﬂates dimensionality estimates '\n",
      "             'and thus makes it difﬁcult to assess the true underlying '\n",
      "             'dimensionality of a pattern. To address this challenge, we '\n",
      "             'developed a novel approach to identify brain regions that carry '\n",
      "             'reliable task-modulated signal and to derive an estimate of the '\n",
      "             \"signal's functional dimensionality. We combined singular value \"\n",
      "             'decomposition with cross-validation to ﬁnd the best low- '\n",
      "             'dimensional projection of a pattern of voxel-responses at a '\n",
      "             'single-subject level. Goodness of the low-dimensional '\n",
      "             'reconstruction is measured as Pearson correlation with a test '\n",
      "             'set, which allows to test for signiﬁcance of the low- '\n",
      "             'dimensional reconstruction across participants. Using '\n",
      "             'hierarchical Bayesian modeling, we derive the best estimate and '\n",
      "             'associated uncertainty of underlying dimensionality across '\n",
      "             'participants. We validated our method on simu- lated data of '\n",
      "             'varying underlying dimensionality, showing that recovered '\n",
      "             'dimensionalities match closely true dimensionalities. We then '\n",
      "             'applied our method to three published fMRI data sets all '\n",
      "             'involving processing of visual stimuli. The results highlight '\n",
      "             'three possible applications of estimating the functional '\n",
      "             'dimensionality of neural data. Firstly, it can aid evaluation of '\n",
      "             'model-based analyses by revealing which areas express reliable, '\n",
      "             'task- modulated signal that could be missed by speciﬁc models. '\n",
      "             'Secondly, it can reveal functional differences across brain '\n",
      "             'regions. Thirdly, knowing the functional dimensionality allows '\n",
      "             'assessing task-related differences in the complexity of neural '\n",
      "             'patterns.',\n",
      " 'keywords': ['Neural representations',\n",
      "              'Dimensionality reduction',\n",
      "              'Multivariate analysis'],\n",
      " 'title': 'Estimating the functional dimensionality of neural representations'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305408-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In navigating our environment, we rapidly process and extract '\n",
      "             'meaning from visual cues. However, the rela- tionship between '\n",
      "             'visual features and categorical representations in natural scene '\n",
      "             'perception is still not well un- derstood. Here, we used natural '\n",
      "             'scene stimuli from different categories and ﬁltered at different '\n",
      "             'spatial frequencies to address this question in a passive '\n",
      "             'viewing paradigm. Using representational similarity analysis '\n",
      "             '(RSA) and cross- decoding of magnetoencephalography (MEG) data, '\n",
      "             'we show that categorical representations emerge in human visual '\n",
      "             'cortex at ~180 ms and are linked to spatial frequency '\n",
      "             'processing. Furthermore, dorsal and ventral stream areas reveal '\n",
      "             'temporally and spatially overlapping representations of low and '\n",
      "             'high-level layer activations extracted from a feedforward neural '\n",
      "             'network. Our results suggest that neural patterns from '\n",
      "             'extrastriate visual cortex switch from low-level to categorical '\n",
      "             'representations within 200 ms, highlighting the rapid cascade of '\n",
      "             'processing stages essential in human visual perception.',\n",
      " 'keywords': ['Multivariate pattern analysis (MVPA)',\n",
      "              'Representational similarity analysis (RSA)',\n",
      "              'Magnetoencephalography (MEG)',\n",
      "              'Convolutional neural network (CNN)',\n",
      "              'Scene categorization'],\n",
      " 'title': 'Spatial frequency supports the emergence of categorical '\n",
      "          'representations in visual cortex during natural scene perception'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918305718-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'New advances in encoding and decoding of brain signals'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S105381191830627X-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Unknown operator: '\\x00'\n",
      "WARNING:root:Unknown operator: '\\x00'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Recently, there has been increased interest in fusing multimodal '\n",
      "             'imaging to better understand brain organization by integrating '\n",
      "             'information on both brain structure and function. In particular, '\n",
      "             'incorporating anatomical knowl- edge leads to desirable outcomes '\n",
      "             'such as increased accuracy in brain network estimates and '\n",
      "             'greater reproduc- ibility of topological features across '\n",
      "             'scanning sessions. Despite the clear advantages, major '\n",
      "             'challenges persist in integrative analyses including an '\n",
      "             'incomplete understanding of the structure-function relationship '\n",
      "             'and inaccura- cies in mapping anatomical structures due to '\n",
      "             'inherent deﬁciencies in existing imaging technology. This calls '\n",
      "             'for the development of advanced network modeling tools that '\n",
      "             'appropriately incorporate anatomical structure in constructing '\n",
      "             'brain functional networks. We propose a hierarchical Bayesian '\n",
      "             'Gaussian graphical modeling approach which models the brain '\n",
      "             'functional networks via sparse precision matrices whose degree '\n",
      "             'of edge speciﬁc shrinkage is a random variable that is modeled '\n",
      "             'using both anatomical structure and an independent baseline '\n",
      "             'component. The proposed approach adaptively shrinks functional '\n",
      "             'connections and ﬂexibly identiﬁes functional connections '\n",
      "             'supported by structural connectivity knowledge. This enables '\n",
      "             'robust brain network estimation even in the presence of '\n",
      "             'misspeciﬁed anatomical knowledge, while accommodating '\n",
      "             'heterogeneity in the structure- function relationship. We '\n",
      "             'implement the approach via an efﬁcient optimization algorithm '\n",
      "             'which yields maximum a posteriori estimates. Extensive numerical '\n",
      "             'studies involving multiple functional network structures reveal '\n",
      "             'the clear advantages of the proposed approach over competing '\n",
      "             'methods in accurately estimating brain functional connectivity, '\n",
      "             'even when the anatomical knowledge is misspeciﬁed up to a '\n",
      "             'certain degree. An appli- cation of the approach to data from '\n",
      "             'the Philadelphia Neurodevelopmental Cohort (PNC) study reveals '\n",
      "             'gender based connectivity differences across multiple age '\n",
      "             'groups, and higher reproducibility in the estimation of network '\n",
      "             'metrics compared to alternative methods.',\n",
      " 'keywords': ['Adaptive shrinkage',\n",
      "              'Brain networks',\n",
      "              'Gaussian graphical models',\n",
      "              'Multimodal imaging',\n",
      "              'Philadelphia neurodevelopmental cohort',\n",
      "              'Reproducibility'],\n",
      " 'title': 'Integrative Bayesian analysis of brain functional networks '\n",
      "          'incorporating anatomical knowledge'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918306712-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In this paper, we present a novel hierarchical multiscale '\n",
      "             'Bayesian algorithm for electromagnetic brain imaging using '\n",
      "             'magnetoencephalography (MEG) and electroencephalography (EEG). '\n",
      "             'In particular, we present a solution to the source '\n",
      "             'reconstruction problem for sources that vary in spatial extent. '\n",
      "             'We deﬁne sensor data measurements using a generative '\n",
      "             'probabilistic graphical model that is hier- archical across '\n",
      "             'spatial scales of brain regions and voxels. We then derive a '\n",
      "             'novel Bayesian algorithm for probabilistic inference with this '\n",
      "             'graphical model. This algorithm enables robust reconstruction of '\n",
      "             'sources that have diﬀerent spatial extent, from spatially '\n",
      "             'contiguous clusters of dipoles to isolated dipolar sources. We '\n",
      "             'test new algorithms with several representative benchmarks on '\n",
      "             'both simu- lated and real brain activities. The source locations '\n",
      "             'and the correct estimation of source time courses used for the '\n",
      "             'simulated data are chosen to test the per- formance on '\n",
      "             'challenging source conﬁgurations. In simulations, performance of '\n",
      "             'the novel algorithm shows superiority to several existing '\n",
      "             'benchmark algorithms. We also demonstrate that the new algorithm '\n",
      "             'is more robust to correlated brain activity present in real MEG '\n",
      "             'and EEG data and is able to resolve distinct and functionally '\n",
      "             'relevant brain areas with real MEG and EEG datasets.',\n",
      " 'keywords': ['Brain Mapping, Magnetoencephalography, Electroencephalography, '\n",
      "              'Bayesian.'],\n",
      " 'title': 'Hierarchical multiscale Bayesian algorithm for robust MEG/EEG '\n",
      "          'source reconstruction'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918320615-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Functional Magnetic Resonance Imaging (fMRI) has been '\n",
      "             'successfully used for Brain Computer Interfacing (BCI) to '\n",
      "             'classify (imagined) movements of different limbs. However, '\n",
      "             'reliable classiﬁcation of more subtle signals originating from '\n",
      "             'co-localized neural networks in the sensorimotor cortex, e.g. '\n",
      "             'individual movements of ﬁngers of the same hand, has proved to '\n",
      "             'be more challenging, especially when taking into account the '\n",
      "             'requirement for high single trial reliability in the BCI '\n",
      "             'context. In recent years, Multi Voxel Pattern Analysis (MVPA) '\n",
      "             'has gained momentum as a suitable method to disclose such weak, '\n",
      "             'distributed activation patterns. Much attention has been devoted '\n",
      "             'to developing and validating data analysis strategies, but '\n",
      "             'relatively little guidance is available on the choice of '\n",
      "             'experimental design, even less so in the context of BCI-MVPA. '\n",
      "             'When applicable, block designs are considered the safest choice, '\n",
      "             'but the expectations, strategies and adaptation induced by '\n",
      "             'blocking of similar trials can make it a sub-optimal strategy. '\n",
      "             'Fast event-related designs, in contrast, require a more '\n",
      "             'complicated analysis and show stronger dependence on linearity '\n",
      "             'assumptions but allow for randomly alternating trials. However, '\n",
      "             'they lack resting intervals that enable the BCI participant to '\n",
      "             'process feedback. In this proof-of-concept paper a hybrid '\n",
      "             'blocked fast-event related design is introduced that is novel in '\n",
      "             'the context of MVPA and BCI experiments, and that might overcome '\n",
      "             'these issues by combining the rest periods of the block design '\n",
      "             'with the shorter and randomly alternating trial characteristics '\n",
      "             'of a rapid event-related design. A well-established button-press '\n",
      "             'experiment was used to perform a within-subject comparison of '\n",
      "             'the proposed design with a block and a slow event-related '\n",
      "             'design. The proposed hybrid blocked fast-event related design '\n",
      "             'showed a decoding accuracy that was close to that of the block '\n",
      "             'design, which showed highest accuracy. It allowed for '\n",
      "             'across-design decoding, i.e. reliable prediction of examples '\n",
      "             'obtained with another design. Finally, it also showed the most '\n",
      "             'stable incremental decoding results, obtaining good performance '\n",
      "             'with relatively few blocks. Our ﬁndings suggest that the blocked '\n",
      "             'fast event-related design could be a viable alternative to block '\n",
      "             'designs in the context of BCI-MVPA, when expectations, '\n",
      "             'strategies and adaptation make blocking of trials of the same '\n",
      "             'type a sub-optimal strategy. Additionally, the blocked fast '\n",
      "             'event-related design is also suitable for applications in which '\n",
      "             'fast incremental decoding is desired, and enables the use of a '\n",
      "             'slow or block design during the test phase.',\n",
      " 'keywords': [],\n",
      " 'title': 'Optimizing fMRI experimental design for MVPA-based BCI control: '\n",
      "          'Combining the strengths of block and event-related designs'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811918321207-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The way that our brain processes visual information is directly '\n",
      "             'affected by our experience. Repeated exposure to a visual '\n",
      "             'stimulus triggers experience-dependent plasticity in the visual '\n",
      "             'cortex of many species. Humans also have the unique ability to '\n",
      "             'acquire visual knowledge through instruction. We introduced '\n",
      "             'human participants to the real- world size of previously '\n",
      "             'unfamiliar species, and to the functional motion of novel tools, '\n",
      "             'during a functional magnetic resonance imaging scan. Using '\n",
      "             'machine learning, we compared activity patterns evoked by images '\n",
      "             'of the new items, before and after participants learned the '\n",
      "             \"animals' real-world size or tools' motion. We found that, after \"\n",
      "             \"acquiring size information, participants' visual activity \"\n",
      "             'patterns for the new animals became more confusable with '\n",
      "             'activity patterns evoked by similar-sized known animals in early '\n",
      "             'visual cortex, but not in ventral temporal cortex, reﬂecting an '\n",
      "             'inﬂuence of new size knowledge on posterior, but not anterior, '\n",
      "             'components of the ventral stream. In contrast, learning the '\n",
      "             'functional motion of new tools did not lead to an equivalent '\n",
      "             'change in recorded activity. Finally, the time-points marked by '\n",
      "             'evidence of new size information in early visual cortex were '\n",
      "             'more likely to show size information and greater activation in '\n",
      "             'the right angular gyrus, a key hub of semantic knowledge and '\n",
      "             'spatial cognition. Overall, these ﬁndings suggest that learning '\n",
      "             \"an item's real-world size by instruction in- ﬂuences subsequent \"\n",
      "             'activity in visual cortex and in a region that is central to '\n",
      "             'semantic and spatial brain systems.',\n",
      " 'keywords': ['Size', 'Learning', 'Vision', 'Concepts', 'Animacy', 'Memory'],\n",
      " 'title': 'Neural activity in human visual cortex is transformed by learning '\n",
      "          'real world size'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919301211-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Neural oscillatory signals has been associated with many '\n",
      "             'high-level functions (e.g. attention and working memory), '\n",
      "             'because they reﬂect correlated behaviors of neural population '\n",
      "             'that would facilitate the information transfer in the brain. On '\n",
      "             'the other hand, a decreased power of oscillation (event-related '\n",
      "             'desynchronization, ERD) has been associated with an irregular '\n",
      "             'state in which many neurons behave in an uncorrelated manner. In '\n",
      "             'contrast to this view, here we show that the human ERD is linked '\n",
      "             'to the increased regularity of oscillatory signals. Using '\n",
      "             'magnetoencephalography, we found that presenting a visual '\n",
      "             'stimulus not only induced a decrease in power of alpha (8–12 Hz) '\n",
      "             'to beta (13–30 Hz) rhythms in the contralateral visual cortex '\n",
      "             'but also reduced the mean and variance of their inter-peak '\n",
      "             'intervals (IPIs). This indicates that the suppressed alpha/beta '\n",
      "             'rhythms became faster (reduced mean) and more regular (reduced '\n",
      "             'variance) during visual stimulation. The same changes in IPIs, '\n",
      "             'especially those of beta rhythm, were observed when subjects '\n",
      "             'allocated their attention to a contralateral visual ﬁeld. Those '\n",
      "             'results revealed a new role of the event-related decrease in '\n",
      "             'alpha/beta power and further suggested that our brain regulates '\n",
      "             'and accelerates a clock for neural computations by actively '\n",
      "             'suppressing the oscillation amplitude in task-relevant regions.',\n",
      " 'keywords': ['Event-related desynchronization (ERD)',\n",
      "              'Neural periodicity',\n",
      "              'Posner spatial cuing task',\n",
      "              'Inhibitory control',\n",
      "              'Alpha blocking'],\n",
      " 'title': 'Desynchronizing to be faster? Perceptual- and '\n",
      "          'attentional-modulation of brain rhythms at the sub-millisecond '\n",
      "          'scale'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919301454-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Human contrast discrimination performance is limited by '\n",
      "             'transduction nonlinearities and variability of the neural '\n",
      "             'representation (noise). Whereas the nonlinearities have been '\n",
      "             'well-characterised, there is less agreement about the speciﬁcs '\n",
      "             'of internal noise. Psychophysical models assume that it impacts '\n",
      "             'late in sensory processing, whereas neuroimaging and '\n",
      "             'intracranial electrophysiology studies suggest that the noise is '\n",
      "             'much earlier. We investigated whether perceptually-relevant '\n",
      "             'internal noise arises in early visual areas or later decision '\n",
      "             'making areas. We recorded EEG and MEG during a '\n",
      "             'two-interval-forced-choice contrast discrimination task and used '\n",
      "             'multivariate pattern analysis to decode target/non-target and '\n",
      "             'selected/non-selected intervals from evoked responses. We found '\n",
      "             'that perceptual decisions could be decoded from both EEG and MEG '\n",
      "             'signals, even when the stimuli in both intervals were physically '\n",
      "             'identical. Above-chance decision classiﬁcation started <100 ms '\n",
      "             'after stimulus onset, suggesting that neural noise affects '\n",
      "             'sensory signals early in the visual pathway. Classiﬁcation '\n",
      "             'accuracy increased over time, peaking at >500 ms. Applying '\n",
      "             'multivariate analysis to separate anatomically-deﬁned brain '\n",
      "             'regions in MEG source space, we found that occipital regions '\n",
      "             'were informative early on but then information spreads for- '\n",
      "             'wards across parietal and frontal regions. This is consistent '\n",
      "             'with neural noise affecting sensory processing at multiple '\n",
      "             'stages of perceptual decision making. We suggest how early '\n",
      "             \"sensory noise might be resolved with Birdsall's linearisation, \"\n",
      "             'in which a dominant noise source obscures subsequent '\n",
      "             'nonlinearities, to allow the visual system to preserve the wide '\n",
      "             'dynamic range of early areas whilst still beneﬁtting from '\n",
      "             'contrast-invariance at later stages. A preprint of this work is '\n",
      "             'available at: https://doi.org/10.1101/364612.',\n",
      " 'keywords': ['Contrast discrimination',\n",
      "              'EEG',\n",
      "              'MEG',\n",
      "              'Source space',\n",
      "              'Pattern classiﬁcation',\n",
      "              'Internal noise'],\n",
      " 'title': 'Internal noise in contrast discrimination propagates forwards from '\n",
      "          'early visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919302058-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Human high-level visual cortex shows a distinction between '\n",
      "             'animate and inanimate objects, as revealed by fMRI. Recent '\n",
      "             'studies have shown that object animacy can similarly be decoded '\n",
      "             'from MEG sensor patterns. Which object properties drive this '\n",
      "             'decoding? Here, we disentangled the inﬂuence of perceptual and '\n",
      "             'categorical object properties by presenting perceptually matched '\n",
      "             'objects (e.g., snake and rope) that were nonetheless easily '\n",
      "             'recognizable as being animate or inanimate. In a series of '\n",
      "             'behavioral experiments, three aspects of perceptual '\n",
      "             'dissimilarity of these objects were quantiﬁed: overall '\n",
      "             'dissimilarity, outline dissimilarity, and texture dissimilarity. '\n",
      "             'Neural dissimilarity of MEG sensor patterns was modeled using '\n",
      "             'regression analysis, in which perceptual dissimilarity (from the '\n",
      "             'behavioral experiments) and cate- gorical dissimilarity served '\n",
      "             'as predictors of neural dissimilarity. We found that perceptual '\n",
      "             'dissimilarity was strongly reﬂected in MEG sensor patterns from '\n",
      "             '80 ms after stimulus onset, with separable contributions of '\n",
      "             'outline and texture dissimilarity. Surprisingly, when '\n",
      "             'controlling for perceptual dissimilarity, MEG patterns did not '\n",
      "             'carry information about object category (animate vs inanimate) '\n",
      "             'at any time point. Nearly identical results were found in a '\n",
      "             'second MEG experiment that required basic-level object '\n",
      "             'recognition. This is in contrast to results observed in fMRI '\n",
      "             'using the same stimuli, task, and analysis approach: fMRI voxel '\n",
      "             'patterns in object-selective cortex showed a highly reliable '\n",
      "             'categorical distinction even when controlling for perceptual '\n",
      "             'dissimilarity. These results suggest that MEG sensor patterns do '\n",
      "             'not capture object animacy independently of perceptual '\n",
      "             'differences between animate and inanimate objects.',\n",
      " 'keywords': [],\n",
      " 'title': 'MEG sensor patterns reflect perceptual but not categorical '\n",
      "          'similarity of animate and inanimate objects'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1053811919302691-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Eye movements are an integral part of human perception, but can '\n",
      "             'induce artifacts in many magneto- encephalography (MEG) and '\n",
      "             'electroencephalography (EEG) studies. For this reason, '\n",
      "             'investigators try to minimize eye movements and remove these '\n",
      "             'artifacts from their data using diﬀerent techniques. When these '\n",
      "             'artifacts are not purely random, but consistent regarding '\n",
      "             'certain stimuli or conditions, the possibility arises that eye '\n",
      "             'movements are actually inducing eﬀects in the MEG signal. It '\n",
      "             'remains unclear how much of an inﬂuence eye movements can have '\n",
      "             'on observed eﬀects in MEG, since most MEG studies lack a control '\n",
      "             'analysis to verify whether an eﬀect found in the MEG signal is '\n",
      "             'induced by eye movements. Here, we ﬁnd that we can decode '\n",
      "             'stimulus location from eye movements in two diﬀerent stages of a '\n",
      "             'working memory match-to-sample task that encompass diﬀerent '\n",
      "             'areas of research typically done with MEG. This means that the '\n",
      "             'observed MEG eﬀect might be (partly) due to eye movements '\n",
      "             'instead of any true neural correlate. We suggest how to check '\n",
      "             'for eye movement eﬀects in the data and make suggestions on how '\n",
      "             'to minimize eye movement artifacts from occurring in the ﬁrst '\n",
      "             'place.',\n",
      " 'keywords': [],\n",
      " 'title': 'Eye movements explain decodability during perception and cued '\n",
      "          'attention in MEG'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661317302000-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': 'Network Design and the Brain'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661318300433-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Facial Displays Are Tools for Social Influence'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1364661318302821-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': 'Hallucinations and Strong Priors'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1878929317300257-main.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Electrophysiological studies of adults indicate that brain '\n",
      "             'activity is enhanced during viewing of repeated faces, at a '\n",
      "             'latency of about 250 ms after the onset of the face (M250/N250). '\n",
      "             'The present study aimed to determine if this eﬀect was also '\n",
      "             'present in preschool-aged children, whose brain activity was '\n",
      "             'measured in a custom-sized pe- diatric MEG system. The results '\n",
      "             'showed that, unlike adults, face repetition did not show any '\n",
      "             'signiﬁcant mod- ulation of M250 amplitude in children; however '\n",
      "             'children’s M250 latencies were signiﬁcantly faster for repeated '\n",
      "             'than non-repeated faces. Dynamic causal modelling (DCM) of the '\n",
      "             'M250 in both age groups tested the eﬀects of face repetition '\n",
      "             'within the core face network including the occipital face area '\n",
      "             '(OFA), the fusiform face area (FFA), and the superior temporal '\n",
      "             'sulcus (STS). DCM revealed that repetition of identical faces '\n",
      "             'altered both forward and backward connections in children and '\n",
      "             'adults; however the modulations involved inputs to both FFA and '\n",
      "             'OFA in adults but only to OFA in children. These ﬁndings suggest '\n",
      "             'that the amplitude-insensitivity of the immature M250 may be due '\n",
      "             'to a weaker connection between the FFA and lower visual areas.',\n",
      " 'keywords': ['MEG', 'Face recognition', 'Repetition', 'DCM', 'M250', 'M170'],\n",
      " 'title': 'Development of face recognition_ Dynamic causal modelling of MEG '\n",
      "          'data'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S1878929318301178-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The use of movie-watching as an acquisition state for functional '\n",
      "             'connectivity (FC) MRI has recently enabled multiple groups to '\n",
      "             'obtain rich data sets in younger children with both substantial '\n",
      "             'sample sizes and scan dura- tions. Using naturalistic paradigms '\n",
      "             'such as movies has also provided analytic flexibility for these '\n",
      "             'developmental studies that extends beyond conventional resting '\n",
      "             'state approaches. This review highlights the advantages and '\n",
      "             'challenges of using movies for developmental neuroimaging and '\n",
      "             'explores some of the methodological issues involved in designing '\n",
      "             'pediatric studies with movies. Emerging themes from '\n",
      "             'movie-watching studies are dis- cussed, including an emphasis on '\n",
      "             'intersubject correlations, developmental changes in network '\n",
      "             'interactions under complex naturalistic conditions, and dynamic '\n",
      "             'age-related changes in both sensory and higher-order network FC '\n",
      "             'even in narrow age ranges. Converging evidence suggests an '\n",
      "             'enhanced ability to identify brain- behavior correlations in '\n",
      "             'children when using movie-watching data relative to both resting '\n",
      "             'state and conven- tional tasks. Future directions and cautionary '\n",
      "             'notes highlight the potential and the limitations of using '\n",
      "             'movies to study FC in pediatric populations.',\n",
      " 'keywords': ['Naturalistic viewing',\n",
      "              'Movies',\n",
      "              'Resting state',\n",
      "              'Intersubject correlations',\n",
      "              'Head motion',\n",
      "              'Children'],\n",
      " 'title': 'Movies in the magnet_ Naturalistic paradigms in developmental '\n",
      "          'functional neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1-s2.0-S2352340917302056-main.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern classiﬁcation methods have been '\n",
      "             'successfully applied to decode orientation of visual grating '\n",
      "             'stimuli from BOLD fMRI activity recorded in human visual cortex '\n",
      "             '(Kamitani and Tong, 2005; Haynes and Rees, 2005) [12,10]. Though '\n",
      "             'there has been extensive research investigating the true spatial '\n",
      "             'scale of the orientation speciﬁc signals (Op de Beeck, 2010; '\n",
      "             'Swisher et al., 2010; Alink et al., 2013; Freeman et al., 2011, '\n",
      "             '2013) [2,15,1,4,5], it remained inconclusive what spatial '\n",
      "             'acquisition resolution is required, or is optimal, for decoding '\n",
      "             'analyses. The research article entitled “The effect of '\n",
      "             'acquisition resolution on orientation decoding from V1 BOLD fMRI '\n",
      "             'at 7 T” Sengupta et al. (2017) [14] studied the effect of '\n",
      "             'spatial acquisition resolution and also ana- lyzed the strength '\n",
      "             'and spatial scale of orientation discriminating signals. In this '\n",
      "             'article, for the ﬁrst time, we present empirical ultra high-ﬁeld '\n",
      "             'fMRI data, obtained as a part of the aforementioned study, which '\n",
      "             'were recorded at four spatial resolutions (0.8 mm, 1.4 mm, 2 mm, '\n",
      "             'and 3 mm isotropic voxel size) for orientation',\n",
      " 'keywords': [],\n",
      " 'title': 'Ultra high-field \\\\(7T\\\\) multi-resolution fMRI data for '\n",
      "          'orientation decoding in visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10.1093@cercor@bhy123.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10792166.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\10827_2010_Article_262.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1311.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1411.6422.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1510.06479v2.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1612.03590.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1706.01757.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1803Nature_Image reconstruction by domain-transform manifold learning.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FQAFHN+EuclidExtra'>, 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1812.00725v1.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\1906.02691.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\2012-Lizier-LocalInfoStorage.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\2016-7.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unknown operator: 'qBX'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Editor: Cindy A. Lustig',\n",
      " 'keywords': ['Event-related potentials',\n",
      "              'Perceptual learning',\n",
      "              'C1',\n",
      "              'Higher-order cortical processing',\n",
      "              'Primary visual cortex'],\n",
      " 'title': 'Predicting perceptual learning from higher-order cortical '\n",
      "          'processing'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\22547.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unknown operator: 'H\\x89b``dd'\n",
      "WARNING:root:Unknown operator: '\\xa0'\n",
      "WARNING:root:Type mismatch: None != 'a'\n",
      "WARNING:root:Unknown operator: '\\x01'\n",
      "WARNING:root:Unknown operator: '\\x1e'\n",
      "WARNING:pdfminer.pdfinterp:Malformed inline image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\302034.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\358036.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\4020.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\407007.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\6069.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\6672-unsupervised-image-to-image-translation-networks.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\7775-task-driven-convolutional-recurrent-models-of-the-visual-system.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\8702.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A brain-based account of “basic-level” concepts.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'This study provides a brain-based account of how object concepts '\n",
      "             'at an intermediate (basic) level of speciﬁcity are represented, '\n",
      "             'offering an enriched view of what it means for a concept to be a '\n",
      "             'basic-level concept, a research topic pioneered by Rosch and '\n",
      "             'others (Rosch et al., 1976). Applying machine learning '\n",
      "             'techniques to fMRI data, it was possible to determine the '\n",
      "             'semantic content encoded in the neural representations of object '\n",
      "             'concepts at basic and subordinate levels of abstraction. The '\n",
      "             'representation of basic-level concepts (e.g. bird) was spatially '\n",
      "             'broad, encompassing sensorimotor brain areas that encode '\n",
      "             'concrete object properties, and also language and hetero- modal '\n",
      "             'integrative areas that encode abstract semantic content. The '\n",
      "             'representation of subordinate-level concepts (robin) was less '\n",
      "             'widely distributed, concentrated in perceptual areas that '\n",
      "             'underlie concrete content. Furthermore, basic-level concepts '\n",
      "             'were representative of their subordinates in that they were '\n",
      "             'neurally similar to their typical but not atypical subordinates '\n",
      "             '(bird was neurally similar to robin but not woodpecker). The '\n",
      "             'ﬁndings provide a brain- based account of the advantages that '\n",
      "             'basic-level concepts enjoy in everyday life over '\n",
      "             'subordinate-level concepts: the basic level is a broad '\n",
      "             'topographical representation that encompasses both concrete and '\n",
      "             'abstract semantic content, reﬂecting the multifaceted yet '\n",
      "             'intuitive meaning of basic-level concepts.',\n",
      " 'keywords': ['Basic level',\n",
      "              'Level of abstraction',\n",
      "              'Neural representation',\n",
      "              'Object concept',\n",
      "              'fMRI',\n",
      "              'MVPA'],\n",
      " 'title': \"A brain-based account of ``basic-level'' concepts\"}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A Matran-Fernandez  IEEE TBME17.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Objective. The N2pc event-related potential (ERP) appears on the '\n",
      "             'opposite side of the scalp with respect to the visual hemisphere '\n",
      "             'where an object of interest is located. We explored the '\n",
      "             'feasibility of using it to extract information on the spatial '\n",
      "             'location of targets in aerial images shown by means of a rapid '\n",
      "             'serial visual presentation (RSVP) protocol using single-trial '\n",
      "             'classi ﬁcation. Methods. Images were shown to 11 participants at '\n",
      "             'a presentation rate of 5 Hz while recording '\n",
      "             'electroencephalographic signals. With the resulting ERPs, we '\n",
      "             'trained linear classi ﬁers for single-trial detection of target '\n",
      "             'presence and location. We analyzed the classi ﬁers ’ decisions '\n",
      "             'and their raw output scores on independent test sets as well as '\n",
      "             'the averages and voltage distributions of the ERPs. Results. The '\n",
      "             'N2pc is elicited in RSVP presentation of complex images and can '\n",
      "             'be recognized in single trials (the median area under the '\n",
      "             'receiver operating characteristic curve was 0.76 for left versus '\n",
      "             'right classi ﬁcation). Moreover, the peak amplitude of this ERP '\n",
      "             'correlates with the horizontal position of the target within an '\n",
      "             'image. The N2pc varies signi ﬁcantly depending on handedness, '\n",
      "             'and these differences can be used for discriminating '\n",
      "             'participants in terms of their preferred hand. Conclusion and '\n",
      "             'Signi ﬁcance . The N2pc is elicited during RSVP presentation of '\n",
      "             'real complex images and contains analogue information that can '\n",
      "             'be used to roughly infer the horizontal position of targets. '\n",
      "             'Furthermore, differences in the N2pc due to handedness should be '\n",
      "             'taken into account when creating collaborative brain –computer '\n",
      "             'interfaces.',\n",
      " 'keywords': ['Brain-computer interfaces (BCIs)',\n",
      "              'handed-ness',\n",
      "              'N2pc',\n",
      "              'P300',\n",
      "              'rapid serial visual presentation (RSVP)'],\n",
      " 'title': '959'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A Matran-Fernandez  PONE17.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A meta-analysis of fMRI decoding Quantifying influences on human visual population codes.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '1.',\n",
      " 'keywords': ['Decoding',\n",
      "              'MVPA',\n",
      "              'Patterns',\n",
      "              'Meta-analysis',\n",
      "              'Vision',\n",
      "              'Objects'],\n",
      " 'title': 'A meta-analysis of fMRI decoding_ Quantifying influences on human '\n",
      "          'visual population codes'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A predictive coding account of bistable.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A R Marathe IEEE TNSRE14.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Patterns of neural data obtained from electroencephalography '\n",
      "             '(EEG) can be classiﬁed by machine learning techniques to '\n",
      "             'increase human-system performance. In controlled laboratory '\n",
      "             'settings this classiﬁcation approach works well; however, '\n",
      "             'transitioning these approaches into more dynamic, unconstrained '\n",
      "             'environments will present several signiﬁcant challenges. One '\n",
      "             'such challenge is an increase in temporal variability in '\n",
      "             'measured behavioral and neural responses, which often results in '\n",
      "             'suboptimal classiﬁcation performance. Previously, we reported a '\n",
      "             'novel classiﬁcation method designed to account for temporal '\n",
      "             'variability in the neural response in order to improve '\n",
      "             'classiﬁcation performance by using sliding windows in '\n",
      "             'hierarchical discriminant component analysis (HDCA), and '\n",
      "             'demonstrated a decrease in classiﬁcation error by over 50% when '\n",
      "             'compared to the standard HDCA method (Marathe et al., 2013). '\n",
      "             'Here, we expand upon this approach and show that embedded within '\n",
      "             'this new method is a novel signal transformation that, when '\n",
      "             'applied to EEG signals, signiﬁcantly improves the '\n",
      "             'signal-to-noise ratio and thereby enables more accurate '\n",
      "             'single-trial analysis. The results presented here have '\n",
      "             'signiﬁcant implications for both brain–computer interaction '\n",
      "             'technologies and basic science research into neural processes. '\n",
      "             'Index TermsBrain–computer interface (BCI), '\n",
      "             'electroencephalography (EEG), hierarchical discriminant '\n",
      "             'component analysis (HDCA) rapid serial visual presentation '\n",
      "             '(RSVP), real-world environment, single-trial, sliding HDCA, '\n",
      "             'temporal variability.',\n",
      " 'keywords': [],\n",
      " 'title': '201'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\A R Marathe IEEE TNSRE16.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'The application space for brain–computer interface (BCI) '\n",
      "             'technologies is rapidly expanding with improvements in '\n",
      "             'technology. However, most real-time BCIs require extensive '\n",
      "             'individualized calibration prior to use, and systems often have '\n",
      "             'to be recalibrated to account for changes in the neural signals '\n",
      "             'due to a variety of factors including changes in human state, '\n",
      "             'the surrounding environment, and task conditions. Novel '\n",
      "             'approaches to reduce calibration time or effort will '\n",
      "             'dramatically improve the usability of BCI systems. Active '\n",
      "             'Learning (AL) is an iterative semi-supervised learning technique '\n",
      "             'for learning in situations in which data may be abundant, but '\n",
      "             'labels for the data are difﬁcult or expensive to obtain. In this '\n",
      "             'paper, we apply AL to a simulated BCI system for target '\n",
      "             'identiﬁcation using data from a rapid serial visual presentation '\n",
      "             '(RSVP) paradigm to minimize the amount of training samples '\n",
      "             'needed to initially calibrate a neural classiﬁer. Our results '\n",
      "             'show AL can produce similar overall classiﬁcation accuracy with '\n",
      "             'signiﬁcantly less labeled data (in some cases less than 20%) '\n",
      "             'when compared to alternative calibration approaches. In fact, AL '\n",
      "             'classiﬁcation performance matches performance of 10-fold '\n",
      "             'cross-validation (CV) in over 70% of subjects when training with '\n",
      "             'less than 50% of the data. To our knowledge, this is the ﬁrst '\n",
      "             'work to demonstrate the use of AL for ofﬂine '\n",
      "             'electroencephalography (EEG) calibration in a simulated BCI '\n",
      "             'paradigm. While AL itself is not often amenable for use in '\n",
      "             'real-time systems, this work opens the door to alternative '\n",
      "             'AL-like systems that are more amenable for BCI applications and '\n",
      "             'thus enables future efforts for developing highly adaptive BCI '\n",
      "             'systems. Index TermsActive learning, brain–computer interface, '\n",
      "             'electroencephalography, rapid-serial visual presentation.',\n",
      " 'keywords': [],\n",
      " 'title': '333'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Albers_NIMG2017.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis (MVPA) of fMRI data has allowed '\n",
      "             'the investigation of neural representations of stimuli on the '\n",
      "             'basis of distributed patterns of activity within a brain region, '\n",
      "             'independently from overall brain activity. For instance, several '\n",
      "             'studies on early visual cortex have reported reliable MVPA '\n",
      "             'decoding of the identity of a stimulus representation that was '\n",
      "             'kept in working memory or internally generated, despite the fact '\n",
      "             'that the overall BOLD response was low or even at baseline '\n",
      "             'levels. Here we ask how it is possible that reliable stimulus '\n",
      "             'information can be decoded from early visual cortex even when '\n",
      "             'the overall BOLD signal remains low. We reanalyzed a data set in '\n",
      "             'which human participants (N ¼ 24) imagined or kept in working '\n",
      "             'memory an oriented visual grating. We divided voxels from V1, '\n",
      "             'V2, and V3 into groups based on orientation preference, and '\n",
      "             'compared the time course of mean BOLD responses to preferred and '\n",
      "             'non-preferred orientations with the time course of the '\n",
      "             'multivariate decoding performance. Decoding accuracy related to '\n",
      "             'a numerically small, but reliable univariate difference in the '\n",
      "             'mean BOLD response to preferred and non-preferred stimuli. The '\n",
      "             'time course of the difference in BOLD responses to preferred and '\n",
      "             'non- preferred orientations was highly similar to the time '\n",
      "             'course of the multivariate pattern classiﬁcation accuracy. The '\n",
      "             'reliability of the classiﬁcation strongly correlated with the '\n",
      "             'magnitude of differences in BOLD signal between preferred and '\n",
      "             'non-preferred stimuli. These activity differences were small '\n",
      "             'compared to the large overall BOLD modulations. This suggests '\n",
      "             'that a substantial part of the task-related BOLD response to '\n",
      "             'visual stimulation might not be stimulus-speciﬁc. Rather, '\n",
      "             'stimulus-evoked BOLD signals in early visual cortex during a '\n",
      "             'task context may be an amalgam of small stimulus-speciﬁc '\n",
      "             'responses and large task-related but non-stimulus-speciﬁc '\n",
      "             'responses. The latter are not evident during the maintenance or '\n",
      "             'internal generation of stimulus representations, but provide an '\n",
      "             'explanation of how reliable stimulus information can be decoded '\n",
      "             'from early visual cortex even though its overall BOLD signal '\n",
      "             'remains low.',\n",
      " 'keywords': ['BOLD activity',\n",
      "              'MVPA decoding',\n",
      "              'Early visual cortex',\n",
      "              'Orientation speciﬁcity'],\n",
      " 'title': 'Decoupling of BOLD amplitude and pattern classification of '\n",
      "          'orientation-selective activity in human visual cortex'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Are you thinking what I'm thinking Synchronization of resting fMRI.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'We describe BrainSync, an orthogonal transform that allows '\n",
      "             'direct comparison of resting fMRI (rfMRI) time-series across '\n",
      "             'subjects. For this purpose, we exploit the geometry of the rfMRI '\n",
      "             'signal space to propose a novel orthogonal transformation that '\n",
      "             'synchronizes rfMRI time-series across sessions and subjects. '\n",
      "             'When synchronized, rfMRI signals become approximately equal at '\n",
      "             'homologous locations across subjects. The method is based on the '\n",
      "             'observation that rfMRI data exhibit similar con- nectivity '\n",
      "             'patterns across subjects, as reﬂected in the pairwise '\n",
      "             'correlations between different brain regions. We show that if '\n",
      "             'the data for two subjects have similar correlation patterns then '\n",
      "             'their time courses can be approximately synchronized by an '\n",
      "             'orthogonal transformation. This transform is unique, invertible, '\n",
      "             'efﬁcient to compute, and preserves the connectivity structure of '\n",
      "             'the original data for all subjects. Analogously to image '\n",
      "             'registration, where we spatially align structural brain images, '\n",
      "             'this temporal synchronization of brain signals across a '\n",
      "             'population, or within-subject across sessions, facilitates '\n",
      "             'cross-sectional and longitudinal studies of rfMRI data. The '\n",
      "             'utility of the BrainSync transform is illustrated through '\n",
      "             'demonstrative simulations and applications including '\n",
      "             'quantiﬁcation of rfMRI variability across subjects and sessions, '\n",
      "             'cortical functional parcellation across a population, timing '\n",
      "             'recovery in task fMRI data, comparison of task and resting state '\n",
      "             'data, and an application to complex naturalistic stimuli for '\n",
      "             'annotation prediction.',\n",
      " 'keywords': [],\n",
      " 'title': \"Are you thinking what I'm thinking? Synchronization of resting fMRI \"\n",
      "          'time-series across subjects'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Bayesian model reveals latent atrophy factors with dissociable cognitive trajectories in AD.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\brain.2011.0001.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\BurianovaEtAl_2013_Final.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Neuroimaging studies have shown that the neural mechanisms of '\n",
      "             'motor imagery (MI) overlap substantially with the mechanisms of '\n",
      "             'motor execution (ME). Surprisingly, however, the role of several '\n",
      "             'regions of the motor circuit- ry in MI remains controversial, a '\n",
      "             'variability that may be due to differences in neuroimaging '\n",
      "             'techniques, MI train- ing, instruction types, or tasks used to '\n",
      "             'evoke MI. The objectives of this study were twofold: (i) to '\n",
      "             'design a novel task that reliably invokes MI, provides a '\n",
      "             'reliable behavioral measure of MI performance, and is '\n",
      "             'transferable across imaging modalities; and (ii) to measure the '\n",
      "             'common and differential activations for MI and ME with '\n",
      "             'functional magnetic resonance imaging (fMRI) and '\n",
      "             'magnetoencephalography (MEG). We present a task in which it is '\n",
      "             'dif- ﬁcult to give accurate responses without the use of either '\n",
      "             'motor execution or motor imagery. The behavioral results '\n",
      "             'demonstrate that participants performed similarly on the task '\n",
      "             'when they imagined vs. executed move- ments and this performance '\n",
      "             'did not change over time. The fMRI results show a spatial '\n",
      "             'overlap of MI and ME in a number of motor and premotor areas, '\n",
      "             'sensory cortices, cerebellum, inferior frontal gyrus, and '\n",
      "             'ventrolateral thalamus. MI uniquely engaged bilateral occipital '\n",
      "             'areas, left parahippocampus, and other temporal and frontal '\n",
      "             'areas, whereas ME yielded unique activity in motor and sensory '\n",
      "             'areas, cerebellum, precuneus, and putamen. The MEG results show '\n",
      "             'a robust event-related beta band desynchronization in the '\n",
      "             'proximity of primary motor and premotor cortices during both ME '\n",
      "             'and MI. Together, these results further elucidate the neural '\n",
      "             'circuitry of MI and show that our task robustly and reliably '\n",
      "             'invokes motor imagery, and thus may prove useful for interro- '\n",
      "             'gating the functional status of the motor circuitry in patients '\n",
      "             'with motor disorders. © 2013 Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['Motor imagery', 'Motor execution', 'fMRI', 'MEG'],\n",
      " 'title': 'Multimodal functional imaging of motor imagery using a novel '\n",
      "          'paradigm'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\C M Privitera J Vision10.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Can visual information encoded in cortical columns be decoded from MEG.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'It is a principal open question whether noninvasive imaging '\n",
      "             'methods in humans can decode information encoded at a spatial '\n",
      "             'scale as ﬁne as the basic functional unit of cortex: cortical '\n",
      "             'columns. We addressed this question in ﬁve '\n",
      "             'magnetoencephalography (MEG) experiments by investigating a '\n",
      "             'columnar-level encoded visual feature: contrast edge '\n",
      "             'orientation. We found that MEG signals contained '\n",
      "             'orientation-speciﬁc information as early as approximately 50 ms '\n",
      "             'after stimulus onset even when controlling for confounds, such '\n",
      "             'as overrepresentation of particular orientations, stimulus edge '\n",
      "             'interactions, and global form-related signals. Theoretical '\n",
      "             'modeling con- ﬁrmed the plausibility of this empirical result. '\n",
      "             'An essential consequence of our results is that information '\n",
      "             'encoded in the human brain at the level of cortical columns '\n",
      "             'should in general be accessible by multivariate anal- ysis of '\n",
      "             'electrophysiological signals.',\n",
      " 'keywords': ['Orientation encoding',\n",
      "              'Magnetoencephalography',\n",
      "              'Multivariate pattern analysis',\n",
      "              'Cortical columns'],\n",
      " 'title': 'Can visual information encoded in cortical columns be decoded from '\n",
      "          'magnetoencephalography data in humans?'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\chanAH15ICIP15.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Chang_Tsao_2017_The Code for Facial Identity in the Primate Brain.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Primates recognize complex objects such as faces with remarkable '\n",
      "             'speed and reliability. Here, we reveal the brain’s code for '\n",
      "             'facial identity. Experiments in macaques demonstrate an '\n",
      "             'extraordinarily simple transformation between faces and '\n",
      "             'responses of cells in face patches. By formatting faces as '\n",
      "             'points in a high-dimensional linear space, we discovered that '\n",
      "             'each face cell’s ﬁring rate is proportional to the pro- jection '\n",
      "             'of an incoming face stimulus onto a single axis in this space, '\n",
      "             'allowing a face cell ensemble to encode the location of any face '\n",
      "             'in the space. Using this code, we could precisely decode faces '\n",
      "             'from neu- ral population responses and predict neural ﬁring '\n",
      "             'rates to faces. Furthermore, this code disavows the '\n",
      "             'long-standing assumption that face cells encode speciﬁc facial '\n",
      "             'identities, conﬁrmed by engineering faces with drastically '\n",
      "             'different appearance that eli- cited identical responses in '\n",
      "             'single face cells. Our work suggests that other objects could be '\n",
      "             'encoded by analogous metric coordinate systems.',\n",
      " 'keywords': [],\n",
      " 'title': 'The Code for Facial Identity in the Primate Brain'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Chen_et_al-2018-Scientific_Reports.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Cichy_2016.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Congedo et al 2016.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\CSCTR_07sup_ManMonkeyIT.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Inferior temporal (IT) object representations have been '\n",
      "             'intensively studied in monkeys and humans, but representations '\n",
      "             'of the same particular objects have never been compared between '\n",
      "             'the species. Moreover, IT’s role in categorization is not well '\n",
      "             'understood. Here, we presented monkeys and humans with the same '\n",
      "             'images of real-world objects and measured the IT response '\n",
      "             'pattern elicited by each image. In order to relate the '\n",
      "             'representations between the species and to computational models, '\n",
      "             'we compare response-pattern dissimilarity matrices. IT response '\n",
      "             'patterns form category clusters, which match between man and '\n",
      "             'monkey. The clusters corre- spond to animate and inanimate '\n",
      "             'objects; within the animate objects, faces and bodies form '\n",
      "             'subclusters. Within each category, IT distinguishes individual '\n",
      "             'exemplars, and the within-category exemplar simi- larities also '\n",
      "             'match between the species. Our ﬁndings suggest that primate IT '\n",
      "             'across species may host a common code, which combines a '\n",
      "             'categorical and a continuous representation of objects.',\n",
      " 'keywords': [],\n",
      " 'title': 'Matching Categorical Object Representations in Inferior Temporal '\n",
      "          'Cortex of Man and Monkey'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Cukur2013.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\D Won IEEE TNSRE18(1).pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Most event-related potential (ERP)-based brain –computer '\n",
      "             'interface (BCI) spellers primarily use matrix layouts and '\n",
      "             'generally require moderate eye movement for successful '\n",
      "             'operation. The fundamental objective of this paper is to enhance '\n",
      "             'the perceptibility of target characters by introducing motion '\n",
      "             'stimuli to classical rapid serial visual presentation (RSVP) '\n",
      "             'spellers that do not require any eye movement, thereby applying '\n",
      "             'them to paralyzed patients with oculomotor dysfunctions. To test '\n",
      "             'the feasibility of the proposed motion-based RSVP paradigm, we '\n",
      "             'implemented three RSVP spellers: 1) ﬁxed-direction motion '\n",
      "             '(FM-RSVP); 2) random-direction motion (RM-RSVP); and 3) (the '\n",
      "             'conventional) non-motion stimulation (NM-RSVP), and evaluated '\n",
      "             'the effect of the three different stimulation methods on '\n",
      "             'spelling performance. The two motion-based stimulation methods, '\n",
      "             'FMand RM-RSVP, showed shorter P300 latency and higher P300 '\n",
      "             'amplitudes (i.e., 360.4 –379.6 ms; 5.5867 – 5.7662 µV) than the '\n",
      "             'NM-RSVP (i.e., 480.4 ms; 4.7426 µV). This led to higher and more '\n",
      "             'stable performances for FMand RM-RSVP spellers than NM-RSVP '\n",
      "             'speller (i.e., 79.06± 6.45% for NM-RSVP, 90.60 ± 2.98% for '\n",
      "             'RM-RSVP, and 92.74 ± 2.55% for FM-RSVP). In particular, the '\n",
      "             'proposed motion-based RSVP paradigm was signi ﬁcantly bene ﬁcial '\n",
      "             'for about half of the subjects who might not accurately perceive '\n",
      "             'rapidly presented static stimuli. These results indicate that '\n",
      "             'the use of proposed motion-based RSVP paradigm is more bene '\n",
      "             'ﬁcial for target recognition when developing BCI applications '\n",
      "             'for severely paralyzed patients with complex ocular '\n",
      "             'dysfunctions.',\n",
      " 'keywords': ['Brain-computer interface (BCI)',\n",
      "              'gaze-independent',\n",
      "              'event-related potential (ERP)',\n",
      "              'rapid serialvisual presentation (RSVP)'],\n",
      " 'title': 'Motion-Based Rapid Serial Visual Presentation for Gaze-Independent '\n",
      "          'Brain-Computer Interfaces'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\D Won IEEE TNSRE18.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='EFHBWX+CMSY9'>, 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Most event-related potential (ERP)-based brain –computer '\n",
      "             'interface (BCI) spellers primarily use matrix layouts and '\n",
      "             'generally require moderate eye movement for successful '\n",
      "             'operation. The fundamental objective of this paper is to enhance '\n",
      "             'the perceptibility of target characters by introducing motion '\n",
      "             'stimuli to classical rapid serial visual presentation (RSVP) '\n",
      "             'spellers that do not require any eye movement, thereby applying '\n",
      "             'them to paralyzed patients with oculomotor dysfunctions. To test '\n",
      "             'the feasibility of the proposed motion-based RSVP paradigm, we '\n",
      "             'implemented three RSVP spellers: 1) ﬁxed-direction motion '\n",
      "             '(FM-RSVP); 2) random-direction motion (RM-RSVP); and 3) (the '\n",
      "             'conventional) non-motion stimulation (NM-RSVP), and evaluated '\n",
      "             'the effect of the three different stimulation methods on '\n",
      "             'spelling performance. The two motion-based stimulation methods, '\n",
      "             'FMand RM-RSVP, showed shorter P300 latency and higher P300 '\n",
      "             'amplitudes (i.e., 360.4 –379.6 ms; 5.5867 – 5.7662 µV) than the '\n",
      "             'NM-RSVP (i.e., 480.4 ms; 4.7426 µV). This led to higher and more '\n",
      "             'stable performances for FMand RM-RSVP spellers than NM-RSVP '\n",
      "             'speller (i.e., 79.06± 6.45% for NM-RSVP, 90.60 ± 2.98% for '\n",
      "             'RM-RSVP, and 92.74 ± 2.55% for FM-RSVP). In particular, the '\n",
      "             'proposed motion-based RSVP paradigm was signi ﬁcantly bene ﬁcial '\n",
      "             'for about half of the subjects who might not accurately perceive '\n",
      "             'rapidly presented static stimuli. These results indicate that '\n",
      "             'the use of proposed motion-based RSVP paradigm is more bene '\n",
      "             'ﬁcial for target recognition when developing BCI applications '\n",
      "             'for severely paralyzed patients with complex ocular '\n",
      "             'dysfunctions.',\n",
      " 'keywords': ['Brain-computer interface (BCI)',\n",
      "              'gaze-independent',\n",
      "              'event-related potential (ERP)',\n",
      "              'rapid serialvisual presentation (RSVP)'],\n",
      " 'title': 'Motion-Based Rapid Serial Visual Presentation for Gaze-Independent '\n",
      "          'Brain-Computer Interfaces'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\DeanAAAI-05-ComputationalModel-CerebralCortex.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Decoding Brain Representations by Multimodal Learning.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'This paper tackles the problem of learning brain-visual '\n",
      "             'representations for understanding neural processes behind human '\n",
      "             'visual perception, with a view towards replicating these '\n",
      "             'processes into machines. The core idea is to learn plausible '\n",
      "             'presentations through the use of human neural activity evoked by '\n",
      "             'natural images as a supervision mechanism for deep learning '\n",
      "             'models. We propose a multimodal approach that uses deep encoders '\n",
      "             'for images and EEGs, trained in a siamese conﬁguration for '\n",
      "             'learning a joint manifold that maximizes a compatibility measure '\n",
      "             'between visual features and brain representations. We carry out '\n",
      "             'image classiﬁcation and saliency detection on the learned '\n",
      "             'manifold, and shed light on the possible representations '\n",
      "             'generated by the human brain when perceiving the visual world. '\n",
      "             'Performance analysis shows that neural signals can be used to '\n",
      "             'effectively supervise the training of deep learning models, as '\n",
      "             'demonstrated by the achieved performance in both image '\n",
      "             'classiﬁcation and saliency detection. Fur thermore, the learned '\n",
      "             'brain-visual manifold is consistent with cognitive neuroscience '\n",
      "             'literature about visual perception and, most impor tantly, '\n",
      "             'highlights new associations between brain areas, image patches '\n",
      "             'and computational kernels. In par ticular, we are able to '\n",
      "             'approximate brain responses to visual stimuli by training an ar '\n",
      "             'tiﬁcial model with image features correlated to neural activity.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Decoding naturalistic experiences from human brain activity via distributed representations of words.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Natural visual scenes induce rich perceptual experiences that '\n",
      "             'are highly diverse from scene to scene and from person to '\n",
      "             'person. Here, we propose a new framework for decoding such '\n",
      "             'experiences using a distributed repre- sentation of words. We '\n",
      "             'used functional magnetic resonance imaging (fMRI) to measure '\n",
      "             'brain activity evoked by natural movie scenes. Then, we '\n",
      "             'constructed a high-dimensional feature space of perceptual '\n",
      "             'experiences using skip-gram, a state-of-the-art distributed word '\n",
      "             'embedding model. We built a decoder that associates brain '\n",
      "             'activity with perceptual experiences via the distributed word '\n",
      "             'representation. The decoder successfully estimated perceptual '\n",
      "             'contents consistent with the scene descriptions by multiple '\n",
      "             'annotators. Our results illustrate three advantages of our '\n",
      "             'decoding framework: (1) three types of perceptual contents could '\n",
      "             'be decoded in the form of nouns (objects), verbs (actions), and '\n",
      "             'adjectives (impressions) contained in 10,000 vocabulary words; '\n",
      "             '(2) despite using such a large vocabulary, we could decode novel '\n",
      "             'words that were absent in the datasets to train the decoder; and '\n",
      "             '(3) the inter-individual variability of the decoded contents '\n",
      "             'co-varied with that of the contents of scene de- scriptions. '\n",
      "             'These ﬁndings suggest that our decoding framework can recover '\n",
      "             'diverse aspects of perceptual expe- riences in naturalistic '\n",
      "             'situations and could be useful in various scientiﬁc and '\n",
      "             'practical applications.',\n",
      " 'keywords': ['Decoding',\n",
      "              'Semantic perception',\n",
      "              'Natural language processing',\n",
      "              'Humans',\n",
      "              'fMRI',\n",
      "              'Natural vision'],\n",
      " 'title': 'Decoding naturalistic experiences from human brain activity via '\n",
      "          'distributed representations of words'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Dinh2015_Article_Real-TimeMEGSourceLocalization.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'With its millisecond temporal resolution, Magnetoencephalography '\n",
      "             '(MEG) is well suited for real-time monitoring of brain activity. '\n",
      "             'Real-time feedback allows the adaption of the experiment to the '\n",
      "             'subject’s reaction and increases time efﬁciency by shortening '\n",
      "             'acquisition and off-line analysis. Two formidable challenges '\n",
      "             'exist in real-time analysis: the low signal-to-noise ratio (SNR) '\n",
      "             'and the limited time available for computations. Since the low '\n",
      "             'SNR reduces the number of distinguishable sources, we propose an '\n",
      "             'approach which downsizes the source space based on a cortical '\n",
      "             'atlas and allows to discern the sources in the presence of '\n",
      "             'noise. Each cortical region is represented by a small set of '\n",
      "             'dipoles, which is obtained by a clustering algorithm. Using this '\n",
      "             'approach, we adapted dynamic statistical parametric mapping for '\n",
      "             'real-time source localization. In terms of point spread and '\n",
      "             'crosstalk between regions the proposed clustering',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\disun_etd_2016.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Domain-general and domain-specific neural changes underlying.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Visual expertise induces changes in neural processing for many '\n",
      "             'different domains of expertise. However, it is unclear how '\n",
      "             'expertise effects for different domains of expertise are '\n",
      "             'related. In the present fMRI study, we combine large-scale '\n",
      "             'univariate and multi-voxel analyses to contrast the '\n",
      "             'expertise-related neural changes associated with two different '\n",
      "             'domains of expertise, bird expertise (ornithology) and mineral '\n",
      "             'expertise (mineralogy). Results indicated distributed '\n",
      "             'expertise-related neural changes, with effects for both domains '\n",
      "             'of expertise in high-level visual cortex and effects for bird '\n",
      "             'expertise even extending to low-level visual regions and the '\n",
      "             'frontal lobe. Importantly, a multivariate generalization '\n",
      "             'analysis showed that effects in high-level visual cortex were '\n",
      "             'speciﬁc to the domain of expertise. In contrast, the neural '\n",
      "             'changes in the frontal lobe relating to expertise showed '\n",
      "             'signiﬁcant generalization, signaling the presence of '\n",
      "             'domain-independent expertise effects. In conclusion, expertise '\n",
      "             'is related to a combination of domain-speciﬁc and domain-general '\n",
      "             'changes in neural processing.',\n",
      " 'keywords': ['Visual expertise', 'fMRI', 'Object recognition'],\n",
      " 'title': 'Domain-general and domain-specific neural changes underlying visual '\n",
      "          'expertise'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Dynamics of scene representations in the human brain revealed by MEG.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Human scene recognition is a rapid multistep process evolving '\n",
      "             'over time from single scene image to spatial layout processing. '\n",
      "             'We used multivariate pattern analyses on magnetoencephalography '\n",
      "             '(MEG) data to unravel the time course of this cortical process. '\n",
      "             'Following an early signal for lower-level visual analysis of '\n",
      "             'single scenes at ~100 ms, we found a marker of real-world scene '\n",
      "             'size, i.e. spatial layout processing, at ~250 ms indexing neural '\n",
      "             'representations robust to changes in unrelated scene properties '\n",
      "             'and viewing conditions. For a quantitative model of how scene '\n",
      "             'size representations may arise in the brain, we compared MEG '\n",
      "             'data to a deep neural network model trained on scene '\n",
      "             'classiﬁcation. Representations of scene size emerged '\n",
      "             'intrinsically in the model, and resolved emerging neural scene '\n",
      "             'size representation. Together our data provide a ﬁrst '\n",
      "             'description of an electrophysiological signal for layout '\n",
      "             'processing in humans, and suggest that deep neural networks are '\n",
      "             'a promising framework to investigate how spatial layout '\n",
      "             'representations emerge in the human brain.',\n",
      " 'keywords': ['Scene perception',\n",
      "              'Spatial layout',\n",
      "              'Magnetoencephalography',\n",
      "              'Deep neural network',\n",
      "              'Representational similarity analysis'],\n",
      " 'title': 'Dynamics of scene representations in the human brain revealed by '\n",
      "          'magnetoencephalography and deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\eaag2612.full.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\ECCV2018_CBAM_ Convolutional Block Attention Module.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '. We propose Convolutional Block Attention Module (CBAM), a '\n",
      "             'simple yet eﬀective attention module for feed-forward '\n",
      "             'convolutional neural networks. Given an intermediate feature '\n",
      "             'map, our module sequentially infers attention maps along two '\n",
      "             'separate dimensions, channel and spatial, then the attention '\n",
      "             'maps are multiplied to the input feature map for adaptive '\n",
      "             'feature reﬁnement. Because CBAM is a lightweight and general '\n",
      "             'module, it can be integrated into any CNN architectures '\n",
      "             'seamlessly with negligible overheads and is end-to-end trainable '\n",
      "             'along with base CNNs. We validate our CBAM through extensive '\n",
      "             'experiments on ImageNet-1K, MS COCO detection, and VOC 2007 '\n",
      "             'detection datasets. Our experiments show consistent improvements '\n",
      "             'in classiﬁcation and detection performances with various models, '\n",
      "             'demonstrating the wide applicability of CBAM. The code and '\n",
      "             'models will be publicly available.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\elife-25784.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Successful recognition of partially occluded objects is presumed '\n",
      "             'to involve dynamic interactions between brain areas responsible '\n",
      "             'for vision and cognition, but neurophysiological evidence for '\n",
      "             'the involvement of feedback signals is lacking. Here, we '\n",
      "             'demonstrate that neurons in the ventrolateral prefrontal cortex '\n",
      "             '(vlPFC) of monkeys performing a shape discrimination task '\n",
      "             'respond more strongly to occluded than unoccluded stimuli. In '\n",
      "             'contrast, neurons in visual area V4 respond more strongly to '\n",
      "             'unoccluded stimuli. Analyses of V4 response dynamics reveal that '\n",
      "             'many neurons exhibit two transient response peaks, the second of '\n",
      "             'which emerges after vlPFC response onset and displays stronger '\n",
      "             'selectivity for occluded shapes. We replicate these findings '\n",
      "             'using a model of V4/vlPFC interactions in which '\n",
      "             'occlusion-sensitive vlPFC neurons feed back to shapeselective V4 '\n",
      "             'neurons, thereby enhancing V4 responses and selectivity to '\n",
      "             'occluded shapes. These results reveal how signals from frontal '\n",
      "             'and visual cortex could interact to facilitate object '\n",
      "             'recognition under occlusion.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\elife-32816-v2.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Despite the importance of an observer’s goals in determining how '\n",
      "             'a visual object is categorized, surprisingly little is known '\n",
      "             'about how humans process the task context in which objects occur '\n",
      "             'and how it may interact with the processing of objects. Using '\n",
      "             'magnetoencephalography (MEG), functional magnetic resonance '\n",
      "             'imaging (fMRI) and multivariate techniques, we studied the '\n",
      "             'spatial and temporal dynamics of task and object processing. Our '\n",
      "             'results reveal a sequence of separate but overlapping '\n",
      "             'task-related processes spread across frontoparietal and '\n",
      "             'occipitotemporal cortex. Task exhibited late effects on object '\n",
      "             'processing by selectively enhancing task-relevant object '\n",
      "             'features, with limited impact on the overall pattern of object '\n",
      "             'representations. Combining MEG and fMRI data, we reveal a '\n",
      "             'parallel rise in task-related signals throughout the cerebral '\n",
      "             'cortex, with an increasing dominance of task over object '\n",
      "             'representations from early to higher visual areas. Collectively, '\n",
      "             'our results reveal the complex dynamics underlying task and '\n",
      "             'object representations throughout human cortex.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\emss-74424.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In neuroscience, stimulus-response relationships have '\n",
      "             'traditionally been analyzed using either encoding or decoding '\n",
      "             'models. Here we propose a hybrid approach that decomposes neural '\n",
      "             'activity into multiple components, each representing a portion '\n",
      "             'of the stimulus. The technique is implemented via canonical '\n",
      "             'correlation analysis (CCA) by temporally ﬁltering the stimulus '\n",
      "             '(encoding) and spatially ﬁltering the neural responses '\n",
      "             '(decoding) such that the resulting components are maximally '\n",
      "             'correlated. In contrast to existing methods, this approach '\n",
      "             'recovers multiple correlated stimulus-response pairs, and thus '\n",
      "             'affords a richer, multidimensional analysis of neural '\n",
      "             'representations. We ﬁrst validated the technique’s ability to '\n",
      "             'recover multiple stimulus-driven components using '\n",
      "             'electroencephalographic (EEG) data simulated with a ﬁnite '\n",
      "             'element model of the head. We then applied the technique to real '\n",
      "             'EEG responses to auditory and audiovisual narratives experienced '\n",
      "             'identically across subjects, as well as uniquely experienced '\n",
      "             'video game play. During narratives, both auditory and visual '\n",
      "             'stimulus-response correlations (SRC) were modulated by attention '\n",
      "             'and tracked inter-subject correlations. During video game play, '\n",
      "             'SRC varied with game difﬁculty and the presence of a dual task. '\n",
      "             'Interestingly, the strongest component extracted for visual and '\n",
      "             'auditory features of ﬁlm clips had nearly identical spatial '\n",
      "             'distributions, suggesting that the predominant encephalographic '\n",
      "             'response to naturalistic stimuli is supramodal. The diversity of '\n",
      "             'these ﬁndings demonstrates the utility of measuring '\n",
      "             'multidimensional SRC via hybrid encoding- decoding.',\n",
      " 'keywords': [],\n",
      " 'title': 'Extracting multidimensional stimulus-response correlations using '\n",
      "          'hybrid encoding-decoding of neural activity'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\fncom-12-00004.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Forward modelling reveals dynamics of neural orientation.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Brain decoding relates behavior to brain activity through '\n",
      "             'predictive models. These are also used to identify brain regions '\n",
      "             'involved in the cognitive operations related to the observed '\n",
      "             'behavior. Training such multivariate models is a '\n",
      "             'high-dimensional statistical problem that calls for suitable '\n",
      "             'priors. State of the art priors –eg small total- variation– '\n",
      "             'enforce spatial structure on the maps to stabilize them and '\n",
      "             'improve prediction. However, they come with a hefty '\n",
      "             'computational cost. We build upon very fast dimension reduction '\n",
      "             'with spatial structure and model ensembling to achieve decoders '\n",
      "             'that are fast on large datasets and increase the stability of '\n",
      "             'the predictions and the maps. Our approach, fast regularized '\n",
      "             'ensemble of models (FReM), includes an implicit spatial '\n",
      "             'regularization by using a voxel grouping with a fast clustering '\n",
      "             'algorithm. In addition, it aggregates different estimators '\n",
      "             'obtained across splits of a cross-validation loop, each time '\n",
      "             'keeping the best possible model. Experiments on a large number '\n",
      "             'of brain imaging datasets show that our combination of voxel '\n",
      "             'clustering and model ensembling improves decoding maps stability '\n",
      "             'and reduces the variance of prediction accuracy. Importantly, '\n",
      "             'our method requires less samples than state-of-the-art methods '\n",
      "             'to achieve a given level of prediction accuracy. Finally, FreM '\n",
      "             'is much faster than other spatially-regularized methods and, in '\n",
      "             'addition, it can better exploit parallel computing resources.',\n",
      " 'keywords': ['fMRI', 'Supervised learning', 'Decoding', 'Bagging', 'MVPA'],\n",
      " 'title': 'FReM - Scalable and stable decoding with fast regularized ensemble '\n",
      "          'of models'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Functional brain connectivity is predictable from anatomic network's.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'How structural connectivity (SC) gives rise to functional '\n",
      "             'connectivity (FC) is not fully understood. Here we '\n",
      "             'mathematically derive a simple relationship between SC measured '\n",
      "             'from diffusion tensor imaging, and FC from resting state fMRI. '\n",
      "             'We establish that SC and FC are related via (structural) '\n",
      "             'Laplacian spectra, whereby FC and SC share eigenvectors and '\n",
      "             'their eigenvalues are exponentially related. This gives, for the '\n",
      "             'ﬁrst time, a simple and analytical relationship between the '\n",
      "             'graph spectra of structural and functional networks. Laplacian '\n",
      "             'eigenvectors are shown to be good predictors of functional '\n",
      "             'eigenvectors and networks based on independent component '\n",
      "             'analysis of functional time series. A small number of Laplacian '\n",
      "             'eigenmodes are shown to be sufﬁcient to reconstruct FC matrices, '\n",
      "             'serving as basis functions. This approach is fast, and requires '\n",
      "             'no time-consuming sim- ulations. It was tested on two empirical '\n",
      "             'SC/FC datasets, and was found to signiﬁcantly outperform '\n",
      "             'generative model simulations of coupled neural masses.',\n",
      " 'keywords': ['Graph theory',\n",
      "              'Networks',\n",
      "              'Functional network',\n",
      "              'Structural network',\n",
      "              'Eigen decomposition',\n",
      "              'Laplacian'],\n",
      " 'title': 'Functional brain connectivity is predictable from anatomic '\n",
      "          \"network's Laplacian eigen-structure\"}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\gk7591_Lotteretal_ICLR2017.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\H Cecotti IEEE TBME16(1).pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Goal: The detection of brain responses corresponding to the '\n",
      "             'presentation of a particular class of images is a challenge in '\n",
      "             'brain–machine interface. Current systems based on the detection '\n",
      "             'of brain responses during rapid serial visual presentation '\n",
      "             '(RSVP) tasks possess advantages for both healthy and disabled '\n",
      "             'people, as they are gaze independent and can offer a high '\n",
      "             'throughput. Methods: We propose a novel paradigm based on a '\n",
      "             'dual-RSVP task that assumes a low target probability. Two '\n",
      "             'streams of images are presented simultaneously on the screen, '\n",
      "             'the second stream is identical to the ﬁrst one, but delayed in '\n",
      "             'time. Participants were asked to detect images containing a '\n",
      "             'person. They follow the ﬁrst stream until they see a target '\n",
      "             'image, then change their attention to the second stream until '\n",
      "             'the target image reappears, ﬁnally they change their attention '\n",
      "             'back to the ﬁrst stream. Results: The performance of '\n",
      "             'single-trial detection was evaluated on both streams and their '\n",
      "             'combination of the decisions with signal recorded with '\n",
      "             'magnetoencephalography (MEG) during the dual-RSVP task. We '\n",
      "             'compare classi ﬁcation performance across different sets of '\n",
      "             'channels (magnetometers, gradiometers) with a BLDA classi ﬁer '\n",
      "             'with inputs obtained after spatial ﬁltering. Conclusion: The '\n",
      "             'results suggest that single-trial detection can be obtained with '\n",
      "             'an area under the ROC curve superior to 0.95, and that an almost '\n",
      "             'perfect accuracy can be obtained with some subjects thanks to '\n",
      "             'the combination of the decisions from two trials, without '\n",
      "             'doubling the duration of the experiment. Signiﬁcance: The '\n",
      "             'present results show that a reliable accuracy can be obtained '\n",
      "             'with the MEG for target detection during a dual-RSVP task.',\n",
      " 'keywords': ['Event-related ﬁelds',\n",
      "              'magnetoencephalography(MEG)',\n",
      "              'rapid serial visual presentation',\n",
      "              'single-trial detection'],\n",
      " 'title': 'Single-Trial Detection With Magnetoencephalography During a '\n",
      "          'Dual-Rapid Serial Visual Presentation Task'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\H Cecotti IEEE TBME16.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Goal: The detection of brain responses corresponding to the '\n",
      "             'presentation of a particular class of images is a challenge in '\n",
      "             'brain–machine interface. Current systems based on the detection '\n",
      "             'of brain responses during rapid serial visual presentation '\n",
      "             '(RSVP) tasks possess advantages for both healthy and disabled '\n",
      "             'people, as they are gaze independent and can offer a high '\n",
      "             'throughput. Methods: We propose a novel paradigm based on a '\n",
      "             'dual-RSVP task that assumes a low target probability. Two '\n",
      "             'streams of images are presented simultaneously on the screen, '\n",
      "             'the second stream is identical to the ﬁrst one, but delayed in '\n",
      "             'time. Participants were asked to detect images containing a '\n",
      "             'person. They follow the ﬁrst stream until they see a target '\n",
      "             'image, then change their attention to the second stream until '\n",
      "             'the target image reappears, ﬁnally they change their attention '\n",
      "             'back to the ﬁrst stream. Results: The performance of '\n",
      "             'single-trial detection was evaluated on both streams and their '\n",
      "             'combination of the decisions with signal recorded with '\n",
      "             'magnetoencephalography (MEG) during the dual-RSVP task. We '\n",
      "             'compare classi ﬁcation performance across different sets of '\n",
      "             'channels (magnetometers, gradiometers) with a BLDA classi ﬁer '\n",
      "             'with inputs obtained after spatial ﬁltering. Conclusion: The '\n",
      "             'results suggest that single-trial detection can be obtained with '\n",
      "             'an area under the ROC curve superior to 0.95, and that an almost '\n",
      "             'perfect accuracy can be obtained with some subjects thanks to '\n",
      "             'the combination of the decisions from two trials, without '\n",
      "             'doubling the duration of the experiment. Signiﬁcance: The '\n",
      "             'present results show that a reliable accuracy can be obtained '\n",
      "             'with the MEG for target detection during a dual-RSVP task.',\n",
      " 'keywords': ['Event-related ﬁelds',\n",
      "              'magnetoencephalography(MEG)',\n",
      "              'rapid serial visual presentation',\n",
      "              'single-trial detection'],\n",
      " 'title': 'Single-Trial Detection With Magnetoencephalography During a '\n",
      "          'Dual-Rapid Serial Visual Presentation Task'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\H Cecotti IEEE TNNLS14.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Accurate detection of single-trial event-related potentials '\n",
      "             '(ERPs) in the electroencephalogram (EEG) is a dif ﬁcult problem '\n",
      "             'that requires ef ﬁcient signal processing and machine learning '\n",
      "             'techniques. Supervised spatial ﬁltering methods that enhance the '\n",
      "             'discriminative information in EEG data are commonly used to '\n",
      "             'improve single-trial ERP detection. We propose a convolutional '\n",
      "             'neural network (CNN) with a layer dedicated to spatial ﬁltering '\n",
      "             'for the detection of ERPs and with training based on the '\n",
      "             'maximization of the area under the receiver operating '\n",
      "             'characteristic curve (AUC). The CNN is compared with three '\n",
      "             'common classi ﬁers: 1) Bayesian linear discriminant analysis; 2) '\n",
      "             'multilayer perceptron (MLP); and 3) support vector machines. '\n",
      "             'Prior to classi ﬁcation, the data were spatially ﬁltered with '\n",
      "             'xDAWN (for the maximization of the signal-to-signal-plus-noise '\n",
      "             'ratio), common spatial pattern, or not spatially ﬁltered. The 12 '\n",
      "             'analytical techniques were tested on EEG data recorded in three '\n",
      "             'rapid serial visual presentation experiments that required the '\n",
      "             'observer to discriminate rare target stimuli from frequent '\n",
      "             'nontarget stimuli. Classi ﬁcation performance discriminating '\n",
      "             'targets from nontargets depended on both the spatial ﬁltering '\n",
      "             'method and the classi ﬁer. In addition, the nonlinear classi ﬁer '\n",
      "             'MLP outperformed the linear methods. Finally, training based AUC '\n",
      "             'maximization provided better performance than training based on '\n",
      "             'the minimization of the mean square error. The results support '\n",
      "             'the conclusion that the choice of the systems architecture is '\n",
      "             'critical and both spatial ﬁltering and classi ﬁcation must be '\n",
      "             'considered together. Index Terms Brain –computer interface '\n",
      "             '(BCI), common spatial patterns (CSP), convolution, '\n",
      "             'electroencephalogram (EEG), neural networks, rapid serial visual '\n",
      "             'presentation (RSVP), spatial ﬁlters.',\n",
      " 'keywords': [],\n",
      " 'title': 'Single-Trial Classiﬁcation of Event-Related Potentials in Rapid '\n",
      "          'Serial Visual Presentation Tasks Using Supervised Spatial Filtering'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\H Cecotti Int J Psychophysiol17.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The detection of event-related potentials (ERPs) in the '\n",
      "             'electroencephalogram (EEG) signal is a fundamental com- ponent '\n",
      "             'in non-invasive brain-computer interface (BCI) research, and in '\n",
      "             'modern cognitive neuroscience studies. Whereas the grand average '\n",
      "             'response across trials provides an estimation of essential '\n",
      "             'characteristics of a brain- evoked response, an estimation of '\n",
      "             'the differences between trials for a particular type of stimulus '\n",
      "             'can provide key insight about the brain dynamics and possible '\n",
      "             'origins of the brain response. The research in ERP single- trial '\n",
      "             'detection has been mainly driven by applications in biomedical '\n",
      "             'engineering, with an interest from machine learning and signal '\n",
      "             'processing groups that test novel methods on noisy signals. '\n",
      "             'Efﬁcient single-trial detection techniques require processing '\n",
      "             'steps that include temporal ﬁltering, spatial ﬁltering, and '\n",
      "             'classiﬁcation. In this paper, we review the current '\n",
      "             'state-of-the-art methods for single-trial detection of '\n",
      "             'event-related potentials with applications in BCI. Efﬁcient '\n",
      "             'single-trial detection techniques should embed simple yet '\n",
      "             'efﬁcient functions requiring as few hyper-parameters as '\n",
      "             'possible. The focus of this paper is on methods that do not '\n",
      "             'include a large number of hyper-parameters and can be easily '\n",
      "             'implemented with datasets containing a limited number of trials. '\n",
      "             'A benchmark of different classiﬁcation methods is proposed on a '\n",
      "             'database recorded from sixteen healthy subjects during a rapid '\n",
      "             'serial visual presentation task. The results support the '\n",
      "             'conclusion that single-trial detec- tion can be achieved with an '\n",
      "             'area under the ROC curve superior to 0.9 with less than ten '\n",
      "             'sensors and 20 trials corresponding to the presentation of a '\n",
      "             'target. Whereas the number of sensors is not a key element for '\n",
      "             'efﬁcient single-trial detection, the number of trials must be '\n",
      "             'carefully chosen for creating a robust classiﬁer. © 2016 '\n",
      "             'Elsevier B.V. All rights reserved.',\n",
      " 'keywords': ['Event-related potentials',\n",
      "              'Brain-computer Interface',\n",
      "              'Biomedical engineering',\n",
      "              'Spatial ﬁltering',\n",
      "              'Multivariate pattern analysis',\n",
      "              'Classiﬁcation'],\n",
      " 'title': 'Best practice for single-trial detection of event-related '\n",
      "          'potentials: Application to brain-computer interfaces'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Hallucinations in Charles Bonnet Syndrome Induced.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\HsiehChia-ObjectDetectionWithPartialOcclusion.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '-Object occlusion presents a major challenge for robust object '\n",
      "             'detection in static images.  We describe  an object detection '\n",
      "             'system that explicitly models and accounts for arbitrary but '\n",
      "             'consistent occlusion patterns.  Our  model builds on the '\n",
      "             'state-of-the-art object detection system based on a deformable '\n",
      "             'parts-based model.  We’ve  augmented this model with latent '\n",
      "             'binary visibility variables for each pixel, as well as pairwise '\n",
      "             'consistency  visibility potentials.  We will show an efficient '\n",
      "             'inference algorithm for matching our visibility model to a test  '\n",
      "             'image during detection. In training, we employ a latent SVM '\n",
      "             'learning framework, as well as reusing parts of the  inference '\n",
      "             'algorithm that we’ve developed for matching.  Our system is '\n",
      "             'trained and tested on the PASCAL object  detection challenge '\n",
      "             'dataset.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\HybridVAE-Improving Deep Generative Models using Partial Observations.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\ICML18_JointGAN_ Multi-Domain Joint Distribution Learning with.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Information Theoretic Evidence for Predictive Coding.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Interactions Between Large-Scale Functional Brain Networks HMM.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='RMTMIB'>, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Functional magnetic resonance imaging (fMRI) provides a window '\n",
      "             'on the human brain at work. Spontaneous brain activity measured '\n",
      "             'during resting-state has already provided many insights into '\n",
      "             'brain function. In particular, recent interest in dynamic '\n",
      "             'interactions between brain regions has increased the need for '\n",
      "             'more advanced modeling tools. Here, we deploy a recent fMRI '\n",
      "             'deconvolution technique to express resting-state temporal '\n",
      "             'ﬂuctuations as a combination of large-scale functional network '\n",
      "             'activity pro ﬁles. Then, building upon a novel sparse coupled '\n",
      "             'hidden Markov model (SCHMM) framework, we parameterised their '\n",
      "             'temporal evolution as a mix between intrinsic dynamics, and a '\n",
      "             'restricted set of cross-network modulatory couplings extracted '\n",
      "             'in datadriven manner. We demonstrate and validate the method on '\n",
      "             'simulated data, for which we observed that the SCHMM could '\n",
      "             'accurately estimate network dynamics, revealing more precise '\n",
      "             'insights about direct network-to-network modulatory in ﬂuences '\n",
      "             'than with conventional correlational methods. On experimental '\n",
      "             'resting-state fMRI data, we unraveled a set of reproducible '\n",
      "             'cross-network couplings across two independent datasets. Our '\n",
      "             'framework opens new perspectives for capturing complex temporal '\n",
      "             'dynamics and their changes in health and disease.',\n",
      " 'keywords': ['Dynamic functional connectivity',\n",
      "              'total acti-vation',\n",
      "              'innovation-driven co-activation patterns',\n",
      "              'sparsecoupled hidden Markov model',\n",
      "              '(cid:2)1 regularisation.S PONTANEOUS brain activity can be '\n",
      "              'measured non-invasively in human volunteers using resting-state '\n",
      "              '(RS)functional magnetic resonance imaging (fMRI). The studyof '\n",
      "              'RS functionalconnectivity(FC) statisticalinter-dependencies '\n",
      "              'between brain regions’ activity traceshas'],\n",
      " 'title': 'Interactions Between Large-Scale Functional Brain Networks are '\n",
      "          'Captured by Sparse Coupled HMMs'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\jin%2F2017%2F16-3%2Fjin-16-3-jin016%2Fjin-16-jin016.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '. Decoding of human brain activity has always been a primary '\n",
      "             'goal in neuroscience especially with functional magnetic '\n",
      "             'resonance imaging (fMRI) data. In recent years, Convolutional '\n",
      "             'neural network (CNN) has become a popular method for the '\n",
      "             'extraction of features due to its higher accuracy, however it '\n",
      "             'needs a lot of computation and training data. In this study, an '\n",
      "             'algorithm is developed using Multivariate pattern analysis '\n",
      "             '(MVPA) and modiﬁed CNN to decode the behavior of the brain for '\n",
      "             'different images with limited data sets. Selection of signiﬁcant '\n",
      "             'features is an important part of fMRI data analysis, since it '\n",
      "             'reduces the computational burden and improves the prediction '\n",
      "             'performance; signiﬁcant features are selected using a t -test. '\n",
      "             'MVPA uses machine learning algorithms to classify different '\n",
      "             'brain states and helps with prediction during the task. General '\n",
      "             'linear model (GLM) is used to ﬁnd the unknown parameters of '\n",
      "             'every individual voxel and a classiﬁcation is done using a '\n",
      "             'multiclass support vector machine (SVM). A proposed MVPA-CNN '\n",
      "             'based algorithm is compared with a region of interest (ROI) '\n",
      "             'based method and MVPA based estimated values. The proposed '\n",
      "             'method showed better overall accuracy (68.6%) compared to ROI '\n",
      "             '(61.88%) and estimation values (64.17%). Keywords: Convolutional '\n",
      "             'neural network, fMRI, MVPA, GLM, SVM',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\jn.00338.2011.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\journal.pone.0206107.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\kellman_yin_shipley_1998.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\KokDeLange_2015_Predictive_Coding_in_Sensory_Cortex.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=116\n",
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='FIKCOB+Wingdings-Regular'>, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'In recent years, predictive coding has become an increasingly '\n",
      "             'inﬂuential model of how the brain processes sensory information. '\n",
      "             'Predictive coding theories state that the brain is constantly '\n",
      "             'trying to predict the inputs it receives, and each region in the '\n",
      "             'cortical sensory hierarchy represents both these predictions and '\n",
      "             'the mismatch between predictions and input (prediction error). '\n",
      "             'In this chapter, we review the extant empirical evidence for '\n",
      "             'this theory, as well as discuss recent theoretical advances. We '\n",
      "             'ﬁnd that predictive coding provides a good explanation for many '\n",
      "             'phenomena observed in perception, and generates testable '\n",
      "             'hypotheses. Furthermore, we suggest possible avenues for further '\n",
      "             'empirical testing and for broadening the perspective of the role '\n",
      "             'predictive coding may play in cognition.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Koles1990_Article_SpatialPatternsUnderlyingPopul.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\kriegeskorte_RSA_frontiersSN20081.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Large Scale Organization of Shape Processing in the ventral and dorsal pathways.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Learning to Associate Orientation with Color in Early Visual Areas by Associative Decoded fMRI Neurofeedback.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Associative learning is an essential brain process where the '\n",
      "             'contingency of different items increases after training. '\n",
      "             'Associative learning has been found to occur in many brain '\n",
      "             'regions [1–4]. However, there is no clear evidence that '\n",
      "             'associative learning of vi- sual features occurs in early visual '\n",
      "             'areas, although a number of studies have indicated that learning '\n",
      "             'of a single visual feature (perceptual learning) involves early '\n",
      "             'visual areas [5–8]. Here, via decoded fMRI neu- rofeedback '\n",
      "             'termed ‘‘DecNef’’ [9], we tested whether associative learning of '\n",
      "             'orientation and color can be created in early visual areas. '\n",
      "             'During 3 days of training, DecNef induced fMRI signal patterns '\n",
      "             'that corresponded to a speciﬁc target color (red) mostly in '\n",
      "             'early visual areas while a vertical achromatic grating was '\n",
      "             'physically presented to participants. As a result, participants '\n",
      "             'came to perceive ‘‘red’’ signiﬁ- cantly more frequently than '\n",
      "             '‘‘green’’ in an achromatic vertical grating. This effect was '\n",
      "             'also observed 3–5 months after the training. These results '\n",
      "             'suggest that long-term associative learning of two different '\n",
      "             'visual features such as orientation and color was created, most '\n",
      "             'likely in early visual areas. This newly extended technique that '\n",
      "             'induces associative learning is called ‘‘A-DecNef,’’ and it may '\n",
      "             'be used as an important tool for understanding and modifying '\n",
      "             'brain functions because associations are funda- mental and '\n",
      "             'ubiquitous functions in the brain.',\n",
      " 'keywords': [],\n",
      " 'title': 'Learning to Associate Orientation with Color in Early Visual Areas '\n",
      "          'by Associative Decoded fMRI Neurofeedback'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Le_Chang_VALSE_2018_faceRecognition.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\manual.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Mapping between fMRI responses to movies and their natural language annotations.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Several research groups have shown how to map fMRI responses to '\n",
      "             'the meanings of presented stimuli. This paper presents new '\n",
      "             'methods for doing so when only a natural language annotation is '\n",
      "             'available as the description of the stimulus. We study fMRI data '\n",
      "             'gathered from subjects watching an episode of BBCs Sherlock '\n",
      "             '(Chen et al., 2017), and learn bidirectional mappings between '\n",
      "             'fMRI responses and natural language representations. By '\n",
      "             'leveraging data from multiple subjects watching the same movie, '\n",
      "             'we were able to perform scene classiﬁcation with 72% accuracy '\n",
      "             '(random guessing would give 4%) and scene ranking with average '\n",
      "             'rank in the top 4% (random guessing would give 50%). The key '\n",
      "             'ingredients underlying this high level of performance are (a) '\n",
      "             'the use of the Shared Response Model (SRM) and its variant '\n",
      "             'SRM-ICA (Chen et al., 2015; Zhang et al., 2016) to aggregate '\n",
      "             'fMRI data from multiple subjects, both of which are shown to be '\n",
      "             'superior to standard PCA in producing low-dimensional '\n",
      "             'representations for the tasks in this paper; (b) a sentence '\n",
      "             'embedding technique adapted from the natural lan- guage '\n",
      "             'processing (NLP) literature (Arora et al., 2017) that produces '\n",
      "             'semantic vector representation of the an- notations; (c) using '\n",
      "             'previous timestep information in the featurization of the '\n",
      "             'predictor data. These optimizations in how we featurize the fMRI '\n",
      "             'data and text annotations provide a substantial improvement in '\n",
      "             'classiﬁcation performance, relative to standard approaches.',\n",
      " 'keywords': ['FMRI',\n",
      "              'Text annotations',\n",
      "              'Natural language processing',\n",
      "              'Shared response model',\n",
      "              'Natural movie stimulus',\n",
      "              'Multi-modal model'],\n",
      " 'title': 'Mapping between fMRI responses to movies and their natural language '\n",
      "          'annotations'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Mean first-passage time for maximal-entropy random walks in complex networks.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Mechanisms of evoked and induced responses.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'doi:10.1016/j.neuroimage.2006.02.034'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\mmc2.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Associative learning is an essential brain process where the '\n",
      "             'contingency of different items increases after training. '\n",
      "             'Associative learning has been found to occur in many brain '\n",
      "             'regions [1–4]. However, there is no clear evidence that '\n",
      "             'associative learning of vi- sual features occurs in early visual '\n",
      "             'areas, although a number of studies have indicated that learning '\n",
      "             'of a single visual feature (perceptual learning) involves early '\n",
      "             'visual areas [5–8]. Here, via decoded fMRI neu- rofeedback '\n",
      "             'termed ‘‘DecNef’’ [9], we tested whether associative learning of '\n",
      "             'orientation and color can be created in early visual areas. '\n",
      "             'During 3 days of training, DecNef induced fMRI signal patterns '\n",
      "             'that corresponded to a speciﬁc target color (red) mostly in '\n",
      "             'early visual areas while a vertical achromatic grating was '\n",
      "             'physically presented to participants. As a result, participants '\n",
      "             'came to perceive ‘‘red’’ signiﬁ- cantly more frequently than '\n",
      "             '‘‘green’’ in an achromatic vertical grating. This effect was '\n",
      "             'also observed 3–5 months after the training. These results '\n",
      "             'suggest that long-term associative learning of two different '\n",
      "             'visual features such as orientation and color was created, most '\n",
      "             'likely in early visual areas. This newly extended technique that '\n",
      "             'induces associative learning is called ‘‘A-DecNef,’’ and it may '\n",
      "             'be used as an important tool for understanding and modifying '\n",
      "             'brain functions because associations are funda- mental and '\n",
      "             'ubiquitous functions in the brain.',\n",
      " 'keywords': [],\n",
      " 'title': 'Learning to Associate Orientation with Color in Early Visual Areas '\n",
      "          'by Associative Decoded fMRI Neurofeedback'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Modeling Task fMRI Data via Deep Convolutional Autoencoder.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'Task-based fMRI (tfMRI) has been widely used to  study '\n",
      "             'functional brain networks under task performance.  Modeling '\n",
      "             'tfMRI data is challenging due to at least two problems:  the '\n",
      "             'lack of the ground truth of underlying neural activity and the  '\n",
      "             'highly complex intrinsic structure of tfMRI data. To better  '\n",
      "             'understand brain networks based on fMRI data, data-driven  '\n",
      "             'approaches have been proposed, for instance, Independent  '\n",
      "             'Component Analysis (ICA) and Sparse Dictionary Learning  (SDL). '\n",
      "             'However, both ICA and SDL only build shallow models,  and they '\n",
      "             'are under the strong assumption that original fMRI  signal could '\n",
      "             'be linearly decomposed into time series components  with their '\n",
      "             'corresponding spatial maps. As growing evidence  shows that '\n",
      "             'human brain function is hierarchically organized, new  '\n",
      "             'approaches that can infer and model the hierarchical structure '\n",
      "             'of  brain networks are widely called for. Recently, deep '\n",
      "             'convolutional  neural network (CNN) has drawn much attention, in '\n",
      "             'that deep  CNN has proven to be a powerful method for learning '\n",
      "             'high-level  and mid-level abstractions from low -level raw data. '\n",
      "             'Inspired by  the power of deep CNN, in this study, we developed '\n",
      "             'a new neural  network structure based on CNN, called Deep '\n",
      "             'Convolutional  Auto-Encoder (DCAE), in order to take the '\n",
      "             'advantages of both  data-driven approach and CNN’s hierarchical '\n",
      "             'feature abstraction  ability for the purpose of learning '\n",
      "             'mid-level and high-level  features from complex , large-scale '\n",
      "             'tfMRI time series in an  unsupervised manner. The DCAE has been '\n",
      "             'applied and tested on  the publicly available human connectome '\n",
      "             'project (HCP) tfMRI  datasets, and promising results are '\n",
      "             'achieved.',\n",
      " 'keywords': ['Task fMRI', 'CNN', 'deep learning', 'unsupervised'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Multi-modal Latent Factor Exploration  in Typical Late-Onset Alzheimer’s Disease.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Multi-subject hierarchical inverse covariance modelling improves estimation of functional brain networks.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n",
      "WARNING:root:Literal required: CIDSystemInfo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'A Bayesian model for sparse, hierarchical, inver-covariance '\n",
      "             'estimation is presented, and applied to multi-subject functional '\n",
      "             'connectivity estimation in the human brain. It enables '\n",
      "             'simultaneous inference of the strength of connectivity between '\n",
      "             'brain regions at both subject and population level, and is '\n",
      "             'applicable to fMRI, MEG and EEG data. Two versions of the model '\n",
      "             'can encourage sparse connectivity, either using continuous '\n",
      "             'priors to suppress irrelevant connections, or using an explicit '\n",
      "             'description of the network structure to estimate the connection '\n",
      "             'probability between each pair of regions. A large evaluation of '\n",
      "             'this model, and thirteen methods that represent the state of the '\n",
      "             'art of inverse covariance modelling, is conducted using both '\n",
      "             'simulated and resting-state functional imaging datasets. Our '\n",
      "             'novel Bayesian approach has similar performance to the best '\n",
      "             \"extant alternative, Ng et al.'s Sparse Group Gaussian Graphical \"\n",
      "             'Model algorithm, which also is based on a hierarchical '\n",
      "             'structure. Using data from the Human Connectome Project, we show '\n",
      "             'that these hierarchical models are able to reduce the '\n",
      "             'measurement error in MEG beta-band functional networks by 10%, '\n",
      "             'producing concomitant increases in estimates of the genetic '\n",
      "             'inﬂuence on functional connectivity.',\n",
      " 'keywords': ['fMRI',\n",
      "              'MEG',\n",
      "              'Functional connectivity',\n",
      "              'Gaussian Graphical models',\n",
      "              'Hierarchical Bayesian models',\n",
      "              'Concentration graph',\n",
      "              'Precision model',\n",
      "              'Inverse covariance model',\n",
      "              'MCMC'],\n",
      " 'title': 'Multi-subject hierarchical inverse covariance modelling improves '\n",
      "          'estimation of functional brain networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Multi-task connectivity reveals flexible hubs for Adptivie Control.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Multivariate pattern analysis of MEG and EEG A comparison of.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Multivariate pattern analysis of magnetoencephalography (MEG) '\n",
      "             'and electroencephalography (EEG) data can reveal the rapid '\n",
      "             'neural dynamics underlying cognition. However, MEG and EEG have '\n",
      "             'systematic differences in sampling neural activity. This poses '\n",
      "             'the question to which degree such measurement differences '\n",
      "             'consistently bias the results of multivariate analysis applied '\n",
      "             'to MEG and EEG activation patterns. To investigate, we conducted '\n",
      "             'a concurrent MEG/EEG study while participants viewed images of '\n",
      "             'everyday objects. We applied multivariate classiﬁcation analyses '\n",
      "             'to MEG and EEG data, and compared the resulting time courses to '\n",
      "             'each other, and to fMRI data for an independent evaluation in '\n",
      "             'space. We found that both MEG and EEG revealed the millisecond '\n",
      "             'spatio- temporal dynamics of visual processing with largely '\n",
      "             'equivalent results. Beyond yielding convergent results, we found '\n",
      "             'that MEG and EEG also captured partly unique aspects of visual '\n",
      "             'representations. Those unique components emerged earlier in time '\n",
      "             'for MEG than for EEG. Identifying the sources of those unique '\n",
      "             'components with fMRI, we found the locus for both MEG and EEG in '\n",
      "             'high-level visual cortex, and in addition for MEG in low-level '\n",
      "             'visual cortex. Together, our results show that multivariate '\n",
      "             'analyses of MEG and EEG data offer a convergent and '\n",
      "             'complimentary view on neural processing, and motivate the wider '\n",
      "             'adoption of these methods in both MEG and EEG research.',\n",
      " 'keywords': ['MEG',\n",
      "              'EEG',\n",
      "              'Multivariate analysis',\n",
      "              'Pattern classiﬁcation',\n",
      "              'Representational similarity analysis',\n",
      "              'Object recognition'],\n",
      " 'title': 'Multivariate pattern analysis of MEG and EEG: A comparison of '\n",
      "          'representational structure in time and space'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Multiview-3D-DPM.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'As objects are inherently 3D, they have been modeled in 3D in '\n",
      "             'the early days of computer vision. Due to the ambiguities '\n",
      "             'arising from mapping 2D features to 3D models, 3D object '\n",
      "             'representations have been neglected and 2D feature-based models '\n",
      "             'are the predominant paradigm in object detection nowadays. While '\n",
      "             'such models have achieved outstanding bounding box detection '\n",
      "             'performance, they come with limited expressiveness, as they are '\n",
      "             'clearly limited in their capability of reasoning about 3D shape '\n",
      "             'or viewpoints. In this work, we bring the worlds of 3D and 2D '\n",
      "             'object representations closer, by building an object detector '\n",
      "             'which leverages the expressive power of 3D object '\n",
      "             'representations while at the same time can be robustly matched '\n",
      "             'to image evidence. To that end, we gradually extend the '\n",
      "             'successful deformable part model [1] to include viewpoint '\n",
      "             'information and part-level 3D geometry information, resulting in '\n",
      "             'several different models with different level of expressiveness. '\n",
      "             'We end up with a 3D object model, consisting of multiple object '\n",
      "             'parts represented in 3D and a continuous appearance model. We '\n",
      "             'experimentally verify that our models, while providing richer '\n",
      "             'object hypotheses than the 2D object models, provide '\n",
      "             'consistently better joint object localization and viewpoint '\n",
      "             'estimation than the state-of-the-art multi-view and 3D object '\n",
      "             'detectors on various benchmarks (KITTI [2], 3D object classes '\n",
      "             '[3], Pascal3D+ [4], Pascal VOC 2007 [5], EPFL multi-view cars '\n",
      "             '[6]).',\n",
      " 'keywords': ['Object detection',\n",
      "              '3D object models',\n",
      "              'deformable part models',\n",
      "              'structured output learning'],\n",
      " 'title': 'Multi-View and 3D Deformable Part Models'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\NeuroImage2017_FReM – Scalable and stable decoding with fast regularized ensemble of models.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Brain decoding relates behavior to brain activity through '\n",
      "             'predictive models. These are also used to identify brain regions '\n",
      "             'involved in the cognitive operations related to the observed '\n",
      "             'behavior. Training such multivariate models is a '\n",
      "             'high-dimensional statistical problem that calls for suitable '\n",
      "             'priors. State of the art priors –eg small total- variation– '\n",
      "             'enforce spatial structure on the maps to stabilize them and '\n",
      "             'improve prediction. However, they come with a hefty '\n",
      "             'computational cost. We build upon very fast dimension reduction '\n",
      "             'with spatial structure and model ensembling to achieve decoders '\n",
      "             'that are fast on large datasets and increase the stability of '\n",
      "             'the predictions and the maps. Our approach, fast regularized '\n",
      "             'ensemble of models (FReM), includes an implicit spatial '\n",
      "             'regularization by using a voxel grouping with a fast clustering '\n",
      "             'algorithm. In addition, it aggregates different estimators '\n",
      "             'obtained across splits of a cross-validation loop, each time '\n",
      "             'keeping the best possible model. Experiments on a large number '\n",
      "             'of brain imaging datasets show that our combination of voxel '\n",
      "             'clustering and model ensembling improves decoding maps stability '\n",
      "             'and reduces the variance of prediction accuracy. Importantly, '\n",
      "             'our method requires less samples than state-of-the-art methods '\n",
      "             'to achieve a given level of prediction accuracy. Finally, FreM '\n",
      "             'is much faster than other spatially-regularized methods and, in '\n",
      "             'addition, it can better exploit parallel computing resources.',\n",
      " 'keywords': ['fMRI', 'Supervised learning', 'Decoding', 'Bagging', 'MVPA'],\n",
      " 'title': 'FReM - Scalable and stable decoding with fast regularized ensemble '\n",
      "          'of models'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\NeuroImage2018_Extracting multidimensional stimulus-response correlations using hybrid encoding-decoding of neural activity.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'In neuroscience, stimulus-response relationships have '\n",
      "             'traditionally been analyzed using either encoding or decoding '\n",
      "             'models. Here we propose a hybrid approach that decomposes neural '\n",
      "             'activity into multiple components, each representing a portion '\n",
      "             'of the stimulus. The technique is implemented via canonical '\n",
      "             'correlation analysis (CCA) by temporally ﬁltering the stimulus '\n",
      "             '(encoding) and spatially ﬁltering the neural responses '\n",
      "             '(decoding) such that the resulting components are maximally '\n",
      "             'correlated. In contrast to existing methods, this approach '\n",
      "             'recovers multiple correlated stimulus-response pairs, and thus '\n",
      "             'affords a richer, multidimensional analysis of neural '\n",
      "             'representations. We ﬁrst validated the technique’s ability to '\n",
      "             'recover multiple stimulus-driven components using '\n",
      "             'electroencephalographic (EEG) data simulated with a ﬁnite '\n",
      "             'element model of the head. We then applied the technique to real '\n",
      "             'EEG responses to auditory and audiovisual narratives experienced '\n",
      "             'identically across subjects, as well as uniquely experienced '\n",
      "             'video game play. During narratives, both auditory and visual '\n",
      "             'stimulus-response correlations (SRC) were modulated by attention '\n",
      "             'and tracked inter-subject correlations. During video game play, '\n",
      "             'SRC varied with game difﬁculty and the presence of a dual task. '\n",
      "             'Interestingly, the strongest component extracted for visual and '\n",
      "             'auditory features of ﬁlm clips had nearly identical spatial '\n",
      "             'distributions, suggesting that the predominant encephalographic '\n",
      "             'response to naturalistic stimuli is supramodal. The diversity of '\n",
      "             'these ﬁndings demonstrates the utility of measuring '\n",
      "             'multidimensional SRC via hybrid encoding- decoding.',\n",
      " 'keywords': [],\n",
      " 'title': 'Extracting multidimensional stimulus-response correlations using '\n",
      "          'hybrid encoding-decoding of neural activity'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\NeuroImage2018_Pattern component modeling_ A flexible approach for understanding the representational structure of brain activity patterns.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Representational models specify how complex patterns of neural '\n",
      "             'activity relate to visual stimuli, motor actions, or abstract '\n",
      "             'thoughts. Here we review pattern component modeling (PCM), a '\n",
      "             'practical Bayesian approach for eval- uating such models. '\n",
      "             'Similar to encoding models, PCM evaluates the ability of models '\n",
      "             'to predict novel brain ac- tivity patterns. In contrast to '\n",
      "             'encoding models, however, the activity of individual voxels '\n",
      "             'across conditions (activity proﬁles) are not directly ﬁtted. '\n",
      "             'Rather, PCM integrates over all possible activity proﬁles and '\n",
      "             'computes the marginal likelihood of the data under the activity '\n",
      "             'proﬁle distribution speciﬁed by the representational model. By '\n",
      "             'using an analytical expression for the marginal likelihood, PCM '\n",
      "             'allows the ﬁtting of ﬂexible representational models, in which '\n",
      "             'the relative strength and form of the encoded feature spaces can '\n",
      "             'be estimated from the data. We present here a number of '\n",
      "             'different ways in which such ﬂexible representational models can '\n",
      "             'be speciﬁed, and how models of different complexity can be '\n",
      "             'compared. We then provide a number of practical examples from '\n",
      "             'our recent work in motor control, ranging from ﬁxed models to '\n",
      "             'more complex non-linear models of brain representations. The '\n",
      "             'code for the ﬁtting and cross-validation of representational '\n",
      "             'models is provided in an open-source software toolbox.',\n",
      " 'keywords': ['Multi-voxel pattern analysis',\n",
      "              'fMRI',\n",
      "              'Bayesian models',\n",
      "              'Motor representations'],\n",
      " 'title': 'Pattern component modeling: A flexible approach for understanding '\n",
      "          'the representational structure of brain activity patterns'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms-536994.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms-645980.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms122940.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms234413.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms678626.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nihms829712.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Wrong type: <PDFStream(683): raw=466, {'Filter': /FlateDecode, 'First': 46, 'Length': 466, 'N': 6, 'Type': /ObjStm}> required: <class 'dict'>\n",
      "WARNING:root:Cannot locate objid=679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\NIPS2018_IntroVAE_ Introspective Variational Autoencoders for Photographic Image Synthesis.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: <PDFObjRef:28>\n",
      "WARNING:root:Literal required: <PDFObjRef:30>\n",
      "WARNING:root:Literal required: <PDFObjRef:32>\n",
      "WARNING:root:Literal required: <PDFObjRef:34>\n",
      "WARNING:root:Unknown operator: 'qBX'\n",
      "WARNING:root:Unknown operator: '%'\n",
      "WARNING:root:Unknown operator: '%Note:'\n",
      "WARNING:root:Unknown operator: '%'\n",
      "WARNING:root:Unknown operator: '%Note:'\n",
      "WARNING:root:Unknown operator: '%'\n",
      "WARNING:root:Unknown operator: '%Note:'\n",
      "WARNING:root:Unknown operator: 'Qq1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\NIPS2018_Multimodal Generative Models for Scalable Weakly-Supervised Learning.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\nn0199_79.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\On_the_interpretation_of_weight_vectors_of_linear_.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The increase in spatiotemporal resolution of neuroimaging '\n",
      "             'devices is accompanied by a trend towards more powerful '\n",
      "             'multivariate analysis methods. Often it is desired to interpret '\n",
      "             'the outcome of these methods with respect to the cognitive '\n",
      "             'processes under study. Here we discuss which methods allow for '\n",
      "             'such interpretations, and provide guidelines for choosing an '\n",
      "             'appropriate analysis for a given experimental goal: For a '\n",
      "             'surgeon who needs to decide where to remove brain tissue it is '\n",
      "             'most important to determine the origin of cognitive functions '\n",
      "             'and associated neural processes. In contrast, when communicating '\n",
      "             'with paralyzed or comatose patients via brain–computer '\n",
      "             'interfaces, it is most important to accurately extract the '\n",
      "             'neural processes speciﬁc to a certain mental state. These '\n",
      "             'equally important but complementary objectives require different '\n",
      "             'analysis methods. Deter- mining the origin of neural processes '\n",
      "             'in time or space from the parameters of a data-driven model '\n",
      "             'requires what we call a forward model of the data; such a model '\n",
      "             'explains how the measured data was generated from the neural '\n",
      "             'sources. Examples are general linear models (GLMs). Methods for '\n",
      "             'the extraction of neural information from data can be considered '\n",
      "             'as backward models, as they attempt to reverse the data '\n",
      "             'generating process. Examples are multivariate classiﬁers. Here '\n",
      "             'we demonstrate that the parameters of forward models are '\n",
      "             'neurophysiologically in- terpretable in the sense that '\n",
      "             'signiﬁcant nonzero weights are only observed at channels the '\n",
      "             'activity of which is related to the brain process under study. '\n",
      "             'In contrast, the interpretation of backward model parameters can '\n",
      "             'lead to wrong conclusions regarding the spatial or temporal '\n",
      "             'origin of the neural signals of interest, since signiﬁ- cant '\n",
      "             'nonzero weights may also be observed at channels the activity of '\n",
      "             'which is statistically independent of the brain process under '\n",
      "             'study. As a remedy for the linear case, we propose a procedure '\n",
      "             'for transforming backward models into forward models. This '\n",
      "             'procedure enables the neurophysiological interpretation of the '\n",
      "             'parameters of linear backward models. We hope that this work '\n",
      "             'raises awareness for an often encountered problem and pro- vides '\n",
      "             'a theoretical basis for conducting better interpretable '\n",
      "             'multivariate neuroimaging analyses. © 2013 The Authors. '\n",
      "             'Published by Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['Neuroimaging',\n",
      "              'Multivariate',\n",
      "              'Univariate',\n",
      "              'fMRI',\n",
      "              'EEG',\n",
      "              'Forward/backward models',\n",
      "              'Generative/discriminative models',\n",
      "              'Encoding',\n",
      "              'Decoding',\n",
      "              'Activation patterns',\n",
      "              'Extraction ﬁlters',\n",
      "              'Interpretability',\n",
      "              'Regularization',\n",
      "              'Sparsity'],\n",
      " 'title': 'On the interpretation of weight vectors of linear models in '\n",
      "          'multivariate neuroimaging'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Optimal information networks Application for data-driven integrated health in populations.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Optimizing deep video representation to match brain activity.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Ou2015_Article_CharacterizingAndDifferentiati.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=231\n",
      "WARNING:root:Cannot locate objid=507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Functional connectivity measured from resting state fMRI '\n",
      "             '(R-fMRI) data has been widely used to examine the brain’s '\n",
      "             'functional activities and has been recently used to characterize '\n",
      "             'and differentiate brain conditions. However, the dynamical '\n",
      "             'transition patterns of the brain’s functional states have been '\n",
      "             'less explored. In this work, we propose a novel computational '\n",
      "             'framework to quantitatively characterize the brain state '\n",
      "             'dynamics via hidden Markov models (HMMs) learned from the '\n",
      "             'observations of temporally dynamic functional connectomics, '\n",
      "             'denoted as functional connectome states. The framework has been '\n",
      "             'applied to the R-fMRI dataset including 44 post-traumatic stress '\n",
      "             'disorder (PTSD) patients and 51 normal control (NC) subjects. '\n",
      "             'Experimental results show that both PTSD and NC brains were '\n",
      "             'undergoing remarkable changes in resting state and mainly '\n",
      "             'transiting amongst a few brain states. Interestingly, further '\n",
      "             'prediction with the best-matched HMM demonstrates that PTSD '\n",
      "             'would enter into, but could not disengage from, a negative mood '\n",
      "             'state. Importantly, 84 % of PTSD',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\R T Schirrmeister HBM17.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': ': Deep learning with convolutional neural networks (deep '\n",
      "             'ConvNets) has revolutionized computer vision through end-to-end '\n",
      "             'learning, that is, learning from the raw data. There is '\n",
      "             'increasing interest in using deep ConvNets for end-to-end EEG '\n",
      "             'analysis, but a better understanding of how to design and train '\n",
      "             'ConvNets for end-to-end EEG decoding and how to visualize the '\n",
      "             'informative EEG features the ConvNets learn is still needed. '\n",
      "             'Here, we studied deep ConvNets with a range of different '\n",
      "             'architectures, designed for decoding imagined or executed tasks '\n",
      "             'from raw EEG. Our results show that recent advances from the '\n",
      "             'machine learning ﬁeld, including batch normalization and '\n",
      "             'exponential linear units, together with a cropped training '\n",
      "             'strategy, boosted the deep ConvNets decoding performance, '\n",
      "             'reaching at least as good performance as the widely used ﬁlter '\n",
      "             'bank common spatial patterns (FBCSP) algorithm (mean decoding '\n",
      "             'accuracies 82.1% FBCSP, 84.0% deep ConvNets). While FBCSP is '\n",
      "             'designed to use spectral power modulations, the features used by '\n",
      "             'ConvNets are not ﬁxed a priori. Our novel methods for '\n",
      "             'visualizing the learned features demonstrated that ConvNets '\n",
      "             'indeed learned to use spectral power modulations in the alpha, '\n",
      "             'beta, and high gamma frequencies, and proved useful for '\n",
      "             'spatially',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Recognition of Occluded Objects.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Representational similarity encoding for fMRI Pattern-based synthesis to.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Patterns of neural activity are systematically elicited as the '\n",
      "             'brain experiences categorical stimuli and a major chal- lenge is '\n",
      "             'to understand what these patterns represent. Two inﬂuential '\n",
      "             'approaches, hitherto treated as separate analyses, have targeted '\n",
      "             'this problem by using model-representations of stimuli to '\n",
      "             'interpret the corresponding neural activity patterns. '\n",
      "             'Stimulus-model-based-encoding synthesizes neural activity '\n",
      "             'patterns by ﬁrst training weights to map between stimulus-model '\n",
      "             'features and voxels. This allows novel model-stimuli to be '\n",
      "             'mapped into voxel space, and hence the strength of the model to '\n",
      "             'be assessed by comparing predicted against observed neural '\n",
      "             'activity. Representational Similarity Analysis (RSA) assesses '\n",
      "             'models by testing how well the grand struc- ture of '\n",
      "             'pattern-similarities measured between all pairs of model-stimuli '\n",
      "             'aligns with the same structure comput- ed from neural activity '\n",
      "             'patterns. RSA does not require model ﬁtting, but also does not '\n",
      "             'allow synthesis of neural activity patterns, thereby limiting '\n",
      "             'its applicability. We introduce a new approach, representational '\n",
      "             'similarity- encoding, that builds on the strengths of RSA and '\n",
      "             'robustly enables stimulus-model-based neural encoding with- out '\n",
      "             'model ﬁtting. The approach therefore sidesteps problems '\n",
      "             'associated with overﬁtting that notoriously con- front any '\n",
      "             'approach requiring parameter estimation (and is consequently low '\n",
      "             'cost computationally), and importantly enables encoding analyses '\n",
      "             'to be incorporated within the wider Representational Similarity '\n",
      "             'Analysis framework. We illustrate this new approach by using it '\n",
      "             'to synthesize and decode fMRI patterns representing the meanings '\n",
      "             'of words, and discuss its potential biological relevance to '\n",
      "             'encoding in semantic memory. Our new similarity-based encoding '\n",
      "             'approach unites the two previously disparate methods of encoding '\n",
      "             'models and RSA, capturing the strengths of both, and enabling '\n",
      "             'similarity-based synthesis of predicted fMRI patterns. © 2015 '\n",
      "             'Elsevier Inc. All rights reserved.',\n",
      " 'keywords': ['Representational Similarity Analysis',\n",
      "              'Encoding',\n",
      "              'Decoding',\n",
      "              'Semantic model',\n",
      "              'Semantic memory',\n",
      "              'fMRI'],\n",
      " 'title': 'Representational similarity encoding for fMRI: Pattern-based '\n",
      "          'synthesis to predict brain activity using '\n",
      "          'stimulus-model-similarities'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Rivet2009a.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'A brain-computer interface (BCI) is a communication system which '\n",
      "             'allows to control a computer or any other devices thanks to the '\n",
      "             'brain activity. The BCI described in this paper is based on the '\n",
      "             'P300 speller BCI paradigm introduced by Farwell and Donchin [1]. '\n",
      "             'An unsupervised algorithm is proposed to enhance P300 evoked '\n",
      "             'potentials by estimating spatial ﬁlters; the raw EEG signals are '\n",
      "             'then projected into the estimated signal subspace. Data recorded '\n",
      "             'on three subjects were used to evaluate the proposed method. The '\n",
      "             'results, which are presented using a Bayesian linear '\n",
      "             'discriminant analysis (BLDA) classiﬁer [2], show that the '\n",
      "             'proposed method is efﬁcient and accurate. Index TermsBrain '\n",
      "             'computer interface, P300-speller, xDAWN algorithm, spatial '\n",
      "             'enhancement.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\s41467-018-03657-3.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\s41593-018-0200-7.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\s41598-018-22160-9.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\s41598-018-28865-1.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Scene complexity modulates degree of feedback activity during object detection in natural scenes.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Serre_etal_PBR07.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'The primate visual system rapidly and effortlessly recognizes a '\n",
      "             'large number of diverse objects in cluttered, natural scenes. In '\n",
      "             'particular, it can easily categorize images or parts of them, '\n",
      "             'for instance as an ofﬁce scene or a face within that scene, and '\n",
      "             'identify a speciﬁc object. This remarkable ability is '\n",
      "             'evolutionarily important since it allows us to dis- tinguish '\n",
      "             'friend from foe and identify food targets in complex, crowded '\n",
      "             'scenes. Despite the ease with which we see, visual recognition — '\n",
      "             'one of the key issues addressed in computer vision — is quite '\n",
      "             'difﬁcult for computers. The problem of object',\n",
      " 'keywords': [],\n",
      " 'title': 'doi:10.1016/S0079-6123\\\\(06\\\\)65004-8'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\similarity based fusion MEG fMRI.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Spatial attention enhances cortical tracking of quasi-rhythmic visual stimuli.pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'Spatial attention enhances cortical tracking of quasi-rhythmic '\n",
      "          'visual stimuli'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='AQKOUH+CMSY8'>, 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Despite growing interest in multi-voxel pattern analysis (MVPA) '\n",
      "             'methods for fMRI, a major problem remains —that of generating '\n",
      "             'estimates in rapid event-related (ER) designs, where the BOLD '\n",
      "             'responses of temporally adjacent events will overlap. While this '\n",
      "             'problem has been investigated for methods that reduce each event '\n",
      "             'to a single parameter per voxel (Mumford et al., 2012), most of '\n",
      "             'these methods make strong parametric assump- tions about the '\n",
      "             'shape of the hemodynamic response, and require exact knowledge '\n",
      "             'of the temporal proﬁle of the underlying neural activity. A '\n",
      "             'second class of methods uses multiple parameters per event (per '\n",
      "             'voxel) to capture temporal information more faithfully. In '\n",
      "             'addition to enabling a more accurate estimate of ER re- sponses, '\n",
      "             'this allows for the extension of the standard classiﬁcation '\n",
      "             'paradigm into the temporal domain (e.g., Mourão-Miranda et al., '\n",
      "             '2007). However, existing methods in this class were developed '\n",
      "             'for use with block and slow ER data, and there has not yet been '\n",
      "             'an exploration of how to adapt such methods to data collected '\n",
      "             'using rapid ER designs. Here, we demonstrate that the use of '\n",
      "             'multiple parameters preserves or im- proves classiﬁcation '\n",
      "             'accuracy, while additionally providing information on the '\n",
      "             'evolution of class discrimina- tion. Additionally, we explore an '\n",
      "             'alternative to the method of Mourão-Miranda et al. tailored to '\n",
      "             'use in rapid ER designs that yields equivalent classiﬁcation '\n",
      "             'accuracies, but is better at unmixing responses to temporally '\n",
      "             'adjacent events. The current work paves the way for wider '\n",
      "             'adoption of spatiotemporal classiﬁcation analyses, and greater '\n",
      "             'use of MVPA with rapid ER designs.',\n",
      " 'keywords': ['Functional magnetic resonance imaging',\n",
      "              'Classiﬁcation analysis',\n",
      "              'MVPA',\n",
      "              'Rapid event-related design'],\n",
      " 'title': 'Spatiotemporal activity estimation for multivoxel pattern analysis '\n",
      "          'with rapid event-related designs'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Stack Sparse AutoEncoder Detector for Automatic Identification Epilepsy.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': 'High-frequency oscillations (HFOs) are spontaneous '\n",
      "             'magnetoencephalography (MEG) patterns that have been '\n",
      "             'acknowledged as a putative biomarker to identify epileptic foci. '\n",
      "             'Correct detection of HFOs in the MEG signals is crucial for '\n",
      "             'accurate and timely clinical evaluation. Since the visual '\n",
      "             'examination of HFOs is time-consuming, error-prone and with poor '\n",
      "             'inter-reviewer reliability, an automatic HFOs detector is highly '\n",
      "             'desirable in clinical practice. However, existing approaches for '\n",
      "             'HFOs detection may not be applicable for MEG signals with noisy '\n",
      "             'background activity. Therefore, we employ the stacked sparse '\n",
      "             'autoencoder (SSAE)and propose an SSAE-based MEG HFOs (SMO) '\n",
      "             'detector to facilitate the clinical detection of HFOs. To the '\n",
      "             'best of our knowledge, this is the ﬁrst attempt to conduct HFOs '\n",
      "             'detection in MEG using deep learning methods. After conﬁguration '\n",
      "             'optimization, our proposed SMO detector outperformed other '\n",
      "             'classic peer models by achieving 89.9% in accuracy, 88.2% in '\n",
      "             'sensitivity, and 91.6% in speciﬁcity. Furthermore, we have '\n",
      "             'tested the performance consistency of our model using various '\n",
      "             'validation schemes. The distribution of performance metrics '\n",
      "             'demonstrate that our model can achieve steady performance.',\n",
      " 'keywords': ['high-frequency oscillations',\n",
      "              'MEG',\n",
      "              'SSAE',\n",
      "              'brain',\n",
      "              'deep learning model',\n",
      "              'detector'],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Stimulus-Driven Population Activity Patterns in Macaque Primary Visual Cortex.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Task-specific vision models explain task-specific areas of visual cortex (1).pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Task-specific vision models explain task-specific areas of visual cortex.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\theory of cortical function.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Top-down effects in the brain.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '1. The basic idea: all is contextual',\n",
      " 'keywords': [],\n",
      " 'title': 'Top-down effects in the brain'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Toward Universal Lingustic Encoding.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\TowardIntegrationDNN-Neuroscience.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Transfer learning of deep neural network representations for fMRI decoding.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Visual pathways from the perspective of cost functions and multi-task deep neural networks (1).pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': 'Vision research has been shaped by the seminal insight that we '\n",
      "             'can understand the higher-tier visual cortex from the '\n",
      "             'perspective of multiple functional pathways with different '\n",
      "             'goals. In this paper, we try to give a computational account of '\n",
      "             'the functional organization of this system by reasoning from the '\n",
      "             'perspective of multi-task deep neural networks. Machine learning '\n",
      "             'has shown that tasks become easier to solve when they are '\n",
      "             'decomposed into subtasks with their own cost function. We '\n",
      "             'hypothesize that the visual system optimizes multiple cost '\n",
      "             'functions of unrelated tasks and this causes the emergence of a '\n",
      "             'ventral pathway dedicated to vision for perception, and a dorsal '\n",
      "             'pathway dedicated to vision for action. To evaluate the '\n",
      "             'functional organization in multi-task deep neural networks, we '\n",
      "             'propose a method that measures the contribution of a unit '\n",
      "             'towards each task, applying it to two networks that have been '\n",
      "             'trained on either two related or two unrelated tasks, using an '\n",
      "             'identical stimulus set. Results show that the network trained on '\n",
      "             'the unrelated tasks shows a decreasing degree of feature '\n",
      "             'representation sharing towards higher-tier layers while the '\n",
      "             'network trained on related tasks uniformly shows high degree of '\n",
      "             'sharing. We conjecture that the method we propose can be used to '\n",
      "             'analyze the anatomical and functional organization of the visual '\n",
      "             'system and beyond. We predict that the degree to which tasks are '\n",
      "             'related is a good descriptor of the degree to which they share '\n",
      "             'downstream cortical-units.',\n",
      " 'keywords': ['Dual-pathway',\n",
      "              'Deep learning',\n",
      "              'Cost functions',\n",
      "              'Representations',\n",
      "              'Visual processing'],\n",
      " 'title': 'Visual pathways from the perspective of cost functions and '\n",
      "          'multi-task deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Visual pathways from the perspective of cost functions and multi-task deep neural networks.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Vision research has been shaped by the seminal insight that we '\n",
      "             'can understand the higher-tier visual cortex from the '\n",
      "             'perspective of multiple functional pathways with different '\n",
      "             'goals. In this paper, we try to give a computational account of '\n",
      "             'the functional organization of this system by reasoning from the '\n",
      "             'perspective of multi-task deep neural networks. Machine learning '\n",
      "             'has shown that tasks become easier to solve when they are '\n",
      "             'decomposed into subtasks with their own cost function. We '\n",
      "             'hypothesize that the visual system optimizes multiple cost '\n",
      "             'functions of unrelated tasks and this causes the emergence of a '\n",
      "             'ventral pathway dedicated to vision for perception, and a dorsal '\n",
      "             'pathway dedicated to vision for action. To evaluate the '\n",
      "             'functional organization in multi-task deep neural networks, we '\n",
      "             'propose a method that measures the contribution of a unit '\n",
      "             'towards each task, applying it to two networks that have been '\n",
      "             'trained on either two related or two unrelated tasks, using an '\n",
      "             'identical stimulus set. Results show that the network trained on '\n",
      "             'the unrelated tasks shows a decreasing degree of feature '\n",
      "             'representation sharing towards higher-tier layers while the '\n",
      "             'network trained on related tasks uniformly shows high degree of '\n",
      "             'sharing. We conjecture that the method we propose can be used to '\n",
      "             'analyze the anatomical and functional organization of the visual '\n",
      "             'system and beyond. We predict that the degree to which tasks are '\n",
      "             'related is a good descriptor of the degree to which they share '\n",
      "             'downstream cortical-units.',\n",
      " 'keywords': ['Dual-pathway',\n",
      "              'Deep learning',\n",
      "              'Cost functions',\n",
      "              'Representations',\n",
      "              'Visual processing'],\n",
      " 'title': 'Visual pathways from the perspective of cost functions and '\n",
      "          'multi-task deep neural networks'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\Wen et al_CC_2016_Neural Encoding and Decoding with Deep Learning for Dynamic Natural Vision.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\What is Changing when Decoding visual information movies iEEG (1).pdf\n",
      "[-- It is an elsevier paper. --]\n",
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'What is changing when: Decoding visual information in movies from '\n",
      "          'human intracranial recordings'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\What is Changing when Decoding visual information movies iEEG (2).pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Literal required: begin\n",
      "WARNING:root:Literal required: begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'keywords': [],\n",
      " 'title': 'What is changing when: Decoding visual information in movies from '\n",
      "          'human intracranial recordings'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\What When Where Visual Word Recog-TICS2014.pdf\n",
      "[-- It is an IEEE paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.converter:undefined: <PDFType1Font: basefont='CMSY7'>, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\zeilerECCV2014.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '. Large Convolutional Network models have recently demonstrated '\n",
      "             'impressive classiﬁcation performance on the ImageNet benchmark '\n",
      "             'Krizhevsky et al. [18]. However there is no clear understanding '\n",
      "             'of why they perform so well, or how they might be improved. In '\n",
      "             'this paper we explore both issues. We introduce a novel '\n",
      "             'visualization technique that gives insight into the function of '\n",
      "             'intermediate feature layers and the operation of the classiﬁer. '\n",
      "             'Used in a diagnostic role, these visualizations allow us to ﬁnd '\n",
      "             'model architectures that outperform Krizhevsky et al. on the '\n",
      "             'ImageNet classiﬁcation benchmark. We also perform an ablation '\n",
      "             'study to discover the performance contribution from diﬀerent '\n",
      "             'model layers. We show our ImageNet model generalizes well to '\n",
      "             'other datasets: when the softmax classiﬁer is retrained, it '\n",
      "             'convincingly beats the current state-ofthe-art results on '\n",
      "             'Caltech-101 and Caltech-256 datasets.',\n",
      " 'keywords': [],\n",
      " 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\zpq10607.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\！A primer on encoding models in sensory neuroscience.pdf\n",
      "[-- It is an elsevier paper. --]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'A principal goal in sensory neuroscience is to understand how '\n",
      "             'properties of our environment are reflected in neural activity '\n",
      "             'patterns. Recent advances in computational modeling provide '\n",
      "             'increasingly accurate predictions of how neural populations '\n",
      "             'across the brain respond to complex naturalistic stimuli. The '\n",
      "             'em- ployed computational models, referred to as encoding models, '\n",
      "             'explicitly transform complex stimuli into observed neural '\n",
      "             'responses. This rapidly developing field is becoming '\n",
      "             'increasingly important in sensory neuroscience as it provides '\n",
      "             'detailed insights into the functional organization of neural '\n",
      "             'representations. The present work starts by discussing the '\n",
      "             'theoretical underpinnings of encoding models. Next, various ap- '\n",
      "             'plications of encoding models are reviewed. Finally, potential '\n",
      "             'research directions that may shape future work in this area of '\n",
      "             'research are described.',\n",
      " 'keywords': ['Population receptive field',\n",
      "              'Encoding',\n",
      "              'Decoding',\n",
      "              'Sensory neuroscience'],\n",
      " 'title': 'A primer on encoding models in sensory neuroscience'}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\！NeuroEncodingandDecodingwithDL-DynamicNaturalVision.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n",
      "--------------------------------------------------------------------------------\n",
      "C:\\Users\\liste\\OneDrive\\Documents\\schorlar\\！Zweig_InterpoNet_a_Brain_CVPR_2017_paper.pdf\n",
      "[-- It is an IEEE paper. --]\n",
      "{'abstract': '', 'keywords': [], 'title': ''}\n"
     ]
    }
   ],
   "source": [
    "for pdf_path in all_pdfs('C:\\\\Users\\\\liste\\\\OneDrive\\\\Documents\\\\schorlar'):\n",
    "    print('-'* 80)\n",
    "    print(pdf_path)\n",
    "    info = pdf_info(pdf_path)\n",
    "    if info:\n",
    "        pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
